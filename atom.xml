<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.vertexcover.io</id>
    <title>Blog - Vertexcover Blog</title>
    <updated>2025-09-02T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.vertexcover.io"/>
    <subtitle>Blog - Vertexcover Blog</subtitle>
    <icon>https://blog.vertexcover.io/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[How We Do Evals & Observability for Agentic Systems]]></title>
        <id>https://blog.vertexcover.io/strot-ai-observability-evaluation-system</id>
        <link href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system"/>
        <updated>2025-09-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[LLM agentic systems fail in subtle ways. At Vertexcover Labs, we use a 5-part evaluation approach‚Äîpowered by a structured logging foundation:]]></summary>
        <content type="html"><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>LLM agentic systems fail in subtle ways. At Vertexcover Labs, we use a 5-part evaluation approach‚Äîpowered by a structured logging foundation:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Custom reporting/observability app to inspect the step-by-step agent flow (screenshots, LLM traces, code samples, step context, JSON/text blocks, costs).</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Component/agent-level tests (like unit tests) to isolate/fix one step without re-running the whole agent.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">End-to-end evals that validate the final product output while also comparing each stage to explain failures.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Eval reporting dashboard (Airtable or similar) showing run status with linked "run ‚Üí steps" tables for fast triage.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Easy promotion of failing production runs into test cases (just use the run_id).</li></ol><p><strong>Foundation:</strong> a structured logging layer that makes all of the above trivial to build and maintain.</p></div></div>
<!-- -->
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-evals--observability-are-hard-for-llmagent-systems">Why Evals &amp; Observability Are Hard for LLM/Agent Systems<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#why-evals--observability-are-hard-for-llmagent-systems" class="hash-link" aria-label="Direct link to Why Evals &amp; Observability Are Hard for LLM/Agent Systems" title="Direct link to Why Evals &amp; Observability Are Hard for LLM/Agent Systems">‚Äã</a></h2>
<p>Everyone agrees evals &amp; obs are critical. Few teams have a practical pattern that works across domains. The pain points we kept hitting (and solved):</p>
<p><strong>üé≤ LLMs are non-deterministic</strong><br>
<!-- -->Small prompt shifts, model updates, or temperature changes can flip outcomes. You need repeatable tests and live monitors per call.</p>
<p><strong>üîó Deeply chained workflows</strong><br>
<!-- -->Planning ‚Üí tool calls ‚Üí retries ‚Üí post-processing. A bad first decision can ripple invisibly. Only looking at the final result hides root causes, but product quality still depends on the final result.</p>
<p><strong>‚è±Ô∏è Full-run latency &amp; cost</strong><br>
<!-- -->Running agents end-to-end for every tweak is slow and expensive. We need component isolation and captured inputs to iterate quickly.</p>
<p><strong>üîç Debugging requires rich context</strong><br>
<!-- -->Off-the-shelf APM doesn't understand domain-specific failures like "selected wrong data source", "missed edge case in extraction logic", or "hallucinated field mappings". We need pipeline-aware traces: visual state captures, complete LLM interactions, generated artifacts, execution paths, and granular cost attribution.</p>
<p><strong>üìâ Evals decay as use cases evolve</strong><br>
<!-- -->Your perfect eval suite from Q1 becomes incomplete by Q3. New customer patterns emerge, edge cases multiply, and existing tests miss real-world failures. You need frictionless eval creation from production data‚Äîone command to turn today's failure into tomorrow's regression test, without manual test writing.</p>
<p>We see these issues across all our agentic projects. Below is how we solve them in general, using our OSS project Strot as a running example.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="context-strot-example-system">Context: Strot (Example System)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#context-strot-example-system" class="hash-link" aria-label="Direct link to Context: Strot (Example System)" title="Direct link to Context: Strot (Example System)">‚Äã</a></h2>
<p><a href="https://github.com/vertexcover-io/strot" target="_blank" rel="noopener noreferrer">Strot</a> reverse-engineers websites to discover internal APIs and extract structured data. The pipeline has three AI components:</p>
<table><thead><tr><th>Component</th><th>What It Does</th><th>Example Failure</th></tr></thead><tbody><tr><td><strong>Request Detection</strong></td><td>Identify the network call loading target data</td><td>Picks non-related network call</td></tr><tr><td><strong>Parameter Analysis</strong></td><td>Detect pagination and dynamic filters</td><td>Misses cursor param, breaks pagination</td></tr><tr><td><strong>Structured Extraction</strong></td><td>Generate Python to parse responses into schema</td><td>Wrong JSON key mapping</td></tr></tbody></table>
<p>Each can fail differently across thousands of site patterns.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="our-solution-41-stages">Our Solution (4+1 Stages)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#our-solution-41-stages" class="hash-link" aria-label="Direct link to Our Solution (4+1 Stages)" title="Direct link to Our Solution (4+1 Stages)">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-make-debugging-fast--visual-custom-nextjs-reporting-app">1) Make Debugging Fast &amp; Visual (Custom Next.js Reporting App)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#1-make-debugging-fast--visual-custom-nextjs-reporting-app" class="hash-link" aria-label="Direct link to 1) Make Debugging Fast &amp; Visual (Custom Next.js Reporting App)" title="Direct link to 1) Make Debugging Fast &amp; Visual (Custom Next.js Reporting App)">‚Äã</a></h3>
<div style="background-color:rgba(9, 105, 218, 0.1);border:1px solid rgba(9, 105, 218, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #0969da;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">üíæ</span><strong style="color:#0969da;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Implementation Note<!-- -->: <!-- -->Pipeline-Aware Debug UI</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p><strong>What we built:</strong> A pipeline-aware debug UI that shows every step in a run:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Browser screenshots per step (so you see the exact DOM/context the LLM "saw")</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">LLM prompt/response traces with token counts &amp; costs</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Artifacts like generated code and validation results</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Run timeline + per-step cost/time + rollups</li></ol><p><strong>Why custom:</strong> General APM lacks LLM context and domain objects like "network request candidates," "pagination keys," etc. Our UI renders code blocks, JSON blocks, and text blocks differently so you can scan fast.</p><p><strong>What it unlocks:</strong></p><ul style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:disc;list-style-type:disc;list-style-position:outside"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Diagnose in seconds ("wrong request chosen")</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Optimize budgets ("this step is the cost hotspot")</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">No waiting for full pipeline completion‚Äîwatch in flight</li></ul></div></div>
<!-- -->
<div style="margin:20px 0"><img src="https://blog.vertexcover.io/assets/images/observability-dashboard-e04deb7cd8c1a8f3b0d7f87ec26f9536.gif" alt="Observability Dashboard" style="width:100%;max-width:100%;height:auto;border-radius:8px;box-shadow:0 4px 12px rgba(0, 0, 0, 0.1)"></div>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-component-level-unit-testing-agent-lego-bricks">2) Component-Level Unit Testing (Agent "Lego Bricks")<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#2-component-level-unit-testing-agent-lego-bricks" class="hash-link" aria-label="Direct link to 2) Component-Level Unit Testing (Agent &quot;Lego Bricks&quot;)" title="Direct link to 2) Component-Level Unit Testing (Agent &quot;Lego Bricks&quot;)">‚Äã</a></h3>
<p>Running the full agent to test a single change is slow and pricey. We treat each component as a unit:</p>
<ul style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:disc;list-style-type:disc;list-style-position:outside"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Provide captured inputs to just that component</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Support "replay this step from an existing run" (auto-plucks the right inputs via run_id)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Validate outputs against expectations (pagination keys, dynamic filters, parse schema, etc.)</li></ul>
<p>This is akin to unit tests for agents: ship fixes in minutes, not hours.</p>
<p><strong>CLI example:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">echo '[{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "request": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "url": "https://api.example.com/products",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "queries": {"page": "2", "limit": "50"},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "post_data": {"sort": "price", "filter": "new"}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_pagination_keys": ["page", "limit"],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_dynamic_keys": ["sort", "filter"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}]' | uv run stroteval</span><br></span></code></pre></div></div>
<p><img decoding="async" loading="lazy" alt="Parameter Detection View" src="https://blog.vertexcover.io/assets/images/observability-parameter-detection-view-1bdff9ab4dc789aaa7423ad75543d135.png" width="1718" height="736" class="img_ev3q"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-end-to-end-eval-product-level-confidence">3) End-to-End Eval (Product-Level Confidence)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#3-end-to-end-eval-product-level-confidence" class="hash-link" aria-label="Direct link to 3) End-to-End Eval (Product-Level Confidence)" title="Direct link to 3) End-to-End Eval (Product-Level Confidence)">‚Äã</a></h3>
<p>The product cares about the final output. Our E2E eval suite runs the full pipeline and checks:</p>
<ul style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:disc;list-style-type:disc;list-style-position:outside"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Correct source endpoint</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Pagination/dynamic keys</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Entity counts &amp; schema parse correctness</li></ul>
<p>Crucially, we also compare intermediate stages so failures are explainable ("endpoint correct, pagination wrong").</p>
<p><strong>CLI example:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">echo '[{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "job_id": "existing-job-uuid",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_source": "https://api.example.com/reviews",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_pagination_keys": ["cursor", "limit"],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_entity_count": 243</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "site_url": "https://example.com/category/abc",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "query": "Listed products with name and prices",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_source": "https://api.example.com/products",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_pagination_keys": ["limit", "offset"],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_entity_count": 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}]' | uv run stroteval</span><br></span></code></pre></div></div>
<p>We run this suite on every deployment to catch system-level regressions before they reach users.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-airtable-dashboards-explorable-for-the-whole-team">4) Airtable Dashboards (Explorable for the Whole Team)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#4-airtable-dashboards-explorable-for-the-whole-team" class="hash-link" aria-label="Direct link to 4) Airtable Dashboards (Explorable for the Whole Team)" title="Direct link to 4) Airtable Dashboards (Explorable for the Whole Team)">‚Äã</a></h3>
<p>We push eval results to two linked tables:</p>
<table><thead><tr><th>Table</th><th>Contents</th><th>Purpose</th></tr></thead><tbody><tr><td><strong>Runs / Aggregates</strong></td><td>Pass rates by component/site/time; cost/time trends</td><td>High-level health monitoring</td></tr><tr><td><strong>Step Details</strong></td><td>One record per step with inputs, outputs, matches, screenshots, costs (linked to its run)</td><td>Deep debugging and analysis</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Airtable Analysis Report" src="https://blog.vertexcover.io/assets/images/airtable-analysis-report-ff597a14e50c71b5b9005b7815c49ad5.gif" width="1912" height="937" class="img_ev3q"></p>
<p><strong>Why Airtable?</strong> Fast charts, human-friendly filtering, collab-ready, and it mirrors our step-by-step mental model.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="5-production-failures--new-tests-the-feedback-loop">5) Production Failures ‚Üí New Tests (The Feedback Loop)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#5-production-failures--new-tests-the-feedback-loop" class="hash-link" aria-label="Direct link to 5) Production Failures ‚Üí New Tests (The Feedback Loop)" title="Direct link to 5) Production Failures ‚Üí New Tests (The Feedback Loop)">‚Äã</a></h3>
<p>Any run that fails is already fully recorded via structured logs and run_id. Turning it into a test is trivial:</p>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Grab run_id ‚Üí auto-hydrate inputs for the failing component</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Save as a component test (today manual, automation is trivial from the same logs)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">The suite becomes a bug graveyard ‚Äî nothing escapes twice</li></ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-foundation-structured-logging--distributed-tracing">The Foundation: Structured Logging + Distributed Tracing<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#the-foundation-structured-logging--distributed-tracing" class="hash-link" aria-label="Direct link to The Foundation: Structured Logging + Distributed Tracing" title="Direct link to The Foundation: Structured Logging + Distributed Tracing">‚Äã</a></h2>
<div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">üîç</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->The Secret: Structured Logging Architecture</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">‚ñº</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="results-across-strot--similar-projects">Results (Across Strot &amp; Similar Projects)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#results-across-strot--similar-projects" class="hash-link" aria-label="Direct link to Results (Across Strot &amp; Similar Projects)" title="Direct link to Results (Across Strot &amp; Similar Projects)">‚Äã</a></h2>
<div style="background-color:rgba(191, 135, 0, 0.1);border:1px solid rgba(191, 135, 0, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #bf8700;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">‚ö°</span><strong style="color:#bf8700;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Performance Insight<!-- -->: <!-- -->Impact Metrics</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">95% success across 50+ site architectures</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">10√ó faster debugging via visual traces &amp; step replays</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">3√ó faster iteration thanks to component isolation</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Zero regressions once full coverage landed</li></ol></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways">‚Äã</a></h2>
<p>Building effective observability and evaluation for agentic systems requires a holistic approach:</p>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Structure logs once</strong> ‚Äî Proper logging infrastructure is the foundation (observability, evals, and debugging)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Make debugging visual</strong> ‚Äî Custom app to inspect step-by-step agent flow (screenshots, LLM traces, code samples, step context, JSON/text blocks, costs)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Test in layers</strong> ‚Äî component-level tests for rapid iteration, E2E evals for product confidence</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Build reporting dashboards</strong> An easy way to view results of e2e evals with ability to drill down into each step</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Close the feedback loop</strong> ‚Äî easy conversion of production failures into component and E2E regression tests</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Keep interfaces simple</strong> ‚Äî CLI tools for running evals, web dashboards for exploring results</li></ol>
<p>The framework transforms AI development from "hope it works" to "know it works."</p>
<hr>
<p>üîó <strong>Code</strong>: <a href="https://github.com/vertexcover-io/strot" target="_blank" rel="noopener noreferrer">github.com/vertexcover-io/strot</a><br>
<!-- -->üìÑ <strong>Docs</strong>: <a href="https://github.com/vertexcover-io/strot#-evaluation" target="_blank" rel="noopener noreferrer">Evaluation Guide</a></p>]]></content>
        <author>
            <name>Harsh Verma</name>
            <uri>https://github.com/synacktraa</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speed up Docker Builds on Github actions]]></title>
        <id>https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions</id>
        <link href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions"/>
        <updated>2025-08-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Tricks to speed up docker builds]]></summary>
        <content type="html"><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Turn on BuildKit &amp; Buildx everywhere</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Reorder Dockerfile: copy package files first, then rest of code</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Use cache-mounts with buildkit-cache-dance action</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Pick the right cache backend (inline for speed, registry for large images)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Add tmpfs + unsafe-io flags for package installs</li></ol><table><thead><tr><th>Scenario</th><th>Avg. wall-clock</th></tr></thead><tbody><tr><td>No caching</td><td><strong>1 h 10 m</strong></td></tr><tr><td>Layer-cache hit</td><td><strong>6 m</strong></td></tr><tr><td>Layer-cache miss (deps change)</td><td><strong>52 m</strong></td></tr><tr><td>Cache-mount + Cache-Dance</td><td><strong>8 m</strong></td></tr></tbody></table><p>Stop rebuilding the world on every pull-request‚Äîturn on these flags and ship faster.</p></div></div>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-this-matters">Why this matters<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#why-this-matters" class="hash-link" aria-label="Direct link to Why this matters" title="Direct link to Why this matters">‚Äã</a></h3>
<blockquote>
<p>70 min ‚ûú 6 min (deps unchanged) or 8 min (deps changed).</p>
<p>Those are the real numbers we saw after switching our Node + Python monorepo to the techniques below.</p>
</blockquote>
<p>Slow builds waste CI minutes, break focus, and block deploys.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-turn-on-buildkit--buildx-everywhere">1. Turn on BuildKit &amp; Buildx everywhere<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#1-turn-on-buildkit--buildx-everywhere" class="hash-link" aria-label="Direct link to 1. Turn on BuildKit &amp; Buildx everywhere" title="Direct link to 1. Turn on BuildKit &amp; Buildx everywhere">‚Äã</a></h2>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># .github/workflows/build.yml</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">uses</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> docker/setup</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">buildx</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">action@v3   </span><span class="token comment" style="color:#999988;font-style:italic"># spins up an isolated BuildKit builder</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">run</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> echo "DOCKER_BUILDKIT=1" </span><span class="token punctuation" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">&gt;</span><span class="token plain"> $GITHUB_ENV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>BuildKit unlocks layer caching, cache-mounts, <code>RUN --mount</code>, and multi-platform bake (<a href="https://docs.docker.com/build/ci/github-actions/cache/" target="_blank" rel="noopener noreferrer">BuildKit documentation</a>).</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-trim-the-build-context">2. Trim the build context<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#2-trim-the-build-context" class="hash-link" aria-label="Direct link to 2. Trim the build context" title="Direct link to 2. Trim the build context">‚Äã</a></h2>
<p>Add a <code>.dockerignore</code> that excludes <code>node_modules/</code>, <code>docs/</code>, test data, and build artefacts. The runner uploads the entire context before <strong>any</strong> Docker layer executes; shrinking 500 MB of junk can save 30-90 s (<a href="https://docs.docker.com/build/cache/optimize/" target="_blank" rel="noopener noreferrer">build optimization guide</a>).</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-re-order-your-dockerfile">3. Re-order your Dockerfile<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#3-re-order-your-dockerfile" class="hash-link" aria-label="Direct link to 3. Re-order your Dockerfile" title="Direct link to 3. Re-order your Dockerfile">‚Äã</a></h2>
<div class="language-Dockerfile language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># syntax=docker/dockerfile:1.7</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM node:20-slim AS deps</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WORKDIR /app</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 1Ô∏è‚É£ copy only manifests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY package.json yarn.lock ./</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RUN --mount=type=cache,target=/root/.cache/yarn \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    yarn install --frozen-lockfile    # re-runs only when the lock-file changes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2Ô∏è‚É£ now copy the rest</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>Because the dependency layer rarely changes, 60+ minutes of <code>yarn install</code> drops to &lt; 6 minutes the next time a PR arrives.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-choose-the-right-layer-cache-backend">4. Choose the <em>right</em> layer-cache backend<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#4-choose-the-right-layer-cache-backend" class="hash-link" aria-label="Direct link to 4-choose-the-right-layer-cache-backend" title="Direct link to 4-choose-the-right-layer-cache-backend">‚Äã</a></h2>
<table><thead><tr><th>Exporter</th><th>What‚Äôs stored</th><th>Cold restore on GH runner</th><th>Best when</th></tr></thead><tbody><tr><td><strong><code>type=inline</code></strong></td><td>cache <em>metadata</em> embedded in the image</td><td>&lt; 1 s (only tiny config pulled)</td><td>You already push the image anyway</td></tr><tr><td><strong><code>type=registry</code></strong></td><td>full layers in a <code>&lt;image&gt;-buildcache</code> tag</td><td>5-30 s (downloads blobs)</td><td>Huge images, need <code>mode=max</code> granularity</td></tr><tr><td><strong><code>type=gha</code></strong></td><td>tarball in GitHub Actions Cache (10 GB limit)</td><td>1-5 s (&lt; 500 MB)</td><td>No private registry, branch-scoped caches</td></tr></tbody></table>
<p><em>Inline feels snappiest</em> because BuildKit needs only the image manifest; layer blobs are fetched lazily. Note, though, that inline supports only <code>mode=min</code>. For ARG/secret-heavy pipelines, flip to <code>registry</code> (<a href="https://docs.docker.com/build/cache/backends/inline/" target="_blank" rel="noopener noreferrer">inline cache guide</a>, <a href="https://docs.docker.com/build/cache/backends/" target="_blank" rel="noopener noreferrer">cache backends overview</a>, <a href="https://docs.docker.com/build/cache/backends/gha/" target="_blank" rel="noopener noreferrer">GitHub Actions cache</a>).</p>
<p><strong>Example call</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker buildx build \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --push -t ghcr.io/acme/web:sha-$GITHUB_SHA \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --cache-from type=registry,ref=ghcr.io/acme/web:buildcache \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --cache-to   type=inline .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-cache-mounts--the-buildkit-cache-dance">5. Cache-mounts + the ‚ÄúBuildKit Cache Dance‚Äù<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#5-cache-mounts--the-buildkit-cache-dance" class="hash-link" aria-label="Direct link to 5. Cache-mounts + the ‚ÄúBuildKit Cache Dance‚Äù" title="Direct link to 5. Cache-mounts + the ‚ÄúBuildKit Cache Dance‚Äù">‚Äã</a></h2>
<div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">RUN --mount=type=cache,target=/var/cache/apt     \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --mount=type=cache,target=/root/.cache/pip   \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pip install -r requirements.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p><code>type=cache</code> keeps bulky package folders <strong>outside</strong> the image graph, so later layer changes don‚Äôt obliterate them. On GitHub-hosted runners those volumes disappear after each job‚Äîunless you use <strong>buildkit-cache-dance</strong> to export/import them between runs:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">uses</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> reproducible</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">containers/buildkit</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">cache</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">dance@v2</span><br></span></code></pre></div></div>
<p>Result: <em>52 min ‚ûú 8 min</em> even when <code>package.json</code> <em>does</em> change (<a href="https://github.com/reproducible-containers/buildkit-cache-dance" target="_blank" rel="noopener noreferrer">buildkit-cache-dance repo</a>, <a href="https://github.com/moby/buildkit/issues/1673" target="_blank" rel="noopener noreferrer">BuildKit cache issue discussion</a>).</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-tmpfs--unsafe-io---90-s-package-installs">6. tmpfs + ‚Äúunsafe-io‚Äù = &lt; 90 s package installs<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#6-tmpfs--unsafe-io---90-s-package-installs" class="hash-link" aria-label="Direct link to 6. tmpfs + ‚Äúunsafe-io‚Äù = < 90 s package installs" title="Direct link to 6. tmpfs + ‚Äúunsafe-io‚Äù = < 90 s package installs">‚Äã</a></h2>
<div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">RUN --mount=type=tmpfs,target=/var/lib/apt/lists  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --mount=type=cache,target=/var/cache/apt      \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    apt-get -o DPkg::Options::="--force-unsafe-io" \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update &amp;&amp; apt-get install -y git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item"><span><code>tmpfs</code> keeps apt's index in RAM‚Äîzero disk writes.</span></li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><span><code>-force-unsafe-io</code> turns off every fsync in <code>dpkg</code>, a safe bet in throw-away CI VMs. Ubuntu's base images already apply a partial version, but passing the flag still yields 15-30% extra speed.</span></li></ol>
<p>(<a href="https://docs.docker.com/reference/dockerfile/" target="_blank" rel="noopener noreferrer">Dockerfile RUN reference</a>, <a href="https://www.reddit.com/r/debian/comments/1dz4jxk/how_can_you_speed_up_apt/" target="_blank" rel="noopener noreferrer">APT speed optimization discussion</a>, <a href="https://gist.github.com/reegnz/990d0b01b5f5e8670f78257875d8daa8" target="_blank" rel="noopener noreferrer">unsafe-io examples</a>).</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-other-micro-wins">7. Other micro-wins<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#7-other-micro-wins" class="hash-link" aria-label="Direct link to 7. Other micro-wins" title="Direct link to 7. Other micro-wins">‚Äã</a></h2>
<ul>
<li><strong>Pin base images by digest</strong> to avoid surprise cache busts.</li>
<li><strong><code>buildx bake</code></strong> builds amd64+arm64 (or dev+prod variants) in parallel while sharing one cache (<a href="https://docs.docker.com/guides/bake/" target="_blank" rel="noopener noreferrer">buildx bake guide</a>).</li>
<li><strong>Garbage-collect</strong> with <code>buildx prune --filter keep-storage=20GB</code> (<a href="https://docs.docker.com/build/ci/github-actions/cache/" target="_blank" rel="noopener noreferrer">cache management guide</a>).</li>
<li><strong>Self-hosted SSD runners</strong> keep the entire BuildKit store between workflows‚Äîzero network latency.</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">‚Äã</a></h2>
<ul style="padding-left:20px;margin:16px 0;line-height:1.6"><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/backends/inline/" target="_blank" rel="noopener noreferrer">Inline cache documentation</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/backends/" target="_blank" rel="noopener noreferrer">Cache backends overview</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/backends/gha/" target="_blank" rel="noopener noreferrer">GitHub Actions cache backend</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/optimize/" target="_blank" rel="noopener noreferrer">Build cache optimization guide</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://github.com/reproducible-containers/buildkit-cache-dance" target="_blank" rel="noopener noreferrer">BuildKit Cache Dance repository</a> - GitHub</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/reference/dockerfile/" target="_blank" rel="noopener noreferrer">Dockerfile RUN --mount reference</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://www.reddit.com/r/debian/comments/1dz4jxk/how_can_you_speed_up_apt/" target="_blank" rel="noopener noreferrer">APT speed optimization discussion</a> - Reddit</p></li><li style="margin-bottom:8px"><p><a href="https://gist.github.com/reegnz/990d0b01b5f5e8670f78257875d8daa8" target="_blank" rel="noopener noreferrer">DPKG unsafe-io examples</a> - GitHub Gist</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/guides/bake/" target="_blank" rel="noopener noreferrer">Buildx bake guide</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/ci/github-actions/cache/" target="_blank" rel="noopener noreferrer">Cache management on GitHub Actions</a> - Docker Docs</p></li></ul>
<hr>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Video Rendering Pipeline for an AI-Driven Text-to-Video Platform]]></title>
        <id>https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform</id>
        <link href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform"/>
        <updated>2025-08-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Video Rendering Pipeline for an AI-Driven Text-to-Video Platform]]></summary>
        <content type="html"><![CDATA[<p>Replacing dual React-ffmpeg architecture with unified browser-based solution, achieving 100,000 daily video renders with consistent preview-output matching and halved development effort.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="context">Context<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context">‚Äã</a></h2>
<p>A leading AI company offers a cloud-based video editor, its core product, enabling users to effortlessly convert text into video with human avatars. The editor supports a wide range of features, from backgrounds, media integration, and text overlays to animations, transitions, fonts, styling, and scene management.</p>
<p>Video generation operates as a pipeline: users begin by crafting a video using the browser-based tool, previewing their creation in real-time. Once satisfied, the video undergoes a render pipeline that culminates in the production of a full HD video, ensuring the final output mirrors the preview's fidelity. At its foundation, the frontend editor employs React, while the backend relies on a custom ffmpeg video renderer.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="problem">Problem<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#problem" class="hash-link" aria-label="Direct link to Problem" title="Direct link to Problem">‚Äã</a></h2>
<p>The company's video editor relied on a dual system: a React-based preview in the browser and an ffmpeg-driven backend for final video rendering. This architecture presented multiple challenges:</p>
<ul>
<li>
<p><strong>Complexity of ffmpeg</strong>: Using ffmpeg programmatically proved intricate due to its inherent complexities.</p>
</li>
<li>
<p><strong>Mismatch Between Preview and Final Render</strong>: The separation of technologies (React for preview and ffmpeg for rendering) occasionally led to inconsistencies between the video preview and the final output.</p>
</li>
<li>
<p><strong>Duplication of Effort</strong>: Introducing any new feature demanded double the effort: once for the preview in React and once more for the final render using ffmpeg. Moreover, ensuring consistency between these two stages added to the workload.</p>
</li>
<li>
<p><strong>Limitations with ffmpeg</strong>: The use of ffmpeg imposed constraints on integrating advanced video editing features.</p>
</li>
</ul>
<p>Furthermore, the ideal solution needed to meet specific criteria:</p>
<ul>
<li>Video generation time should align with the video's actual duration.</li>
<li>The cost of rendering should not exceed 1Rs per minute of video.</li>
<li>The solution should be feasible for relatively swift development and integration.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-and-solution">Challenges and Solution<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#challenges-and-solution" class="hash-link" aria-label="Direct link to Challenges and Solution" title="Direct link to Challenges and Solution">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-browser-based-solutions">Evaluating Browser-Based Solutions<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#evaluating-browser-based-solutions" class="hash-link" aria-label="Direct link to Evaluating Browser-Based Solutions" title="Direct link to Evaluating Browser-Based Solutions">‚Äã</a></h3>
<p>Drawing from my prior experience with video rendering pipelines, it was evident that a browser-centric solution could address our functional requirements. However, constraints related to cost and development time necessitated further exploration.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="library-exploration-for-time-efficiency">Library Exploration for Time-Efficiency<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#library-exploration-for-time-efficiency" class="hash-link" aria-label="Direct link to Library Exploration for Time-Efficiency" title="Direct link to Library Exploration for Time-Efficiency">‚Äã</a></h3>
<p>An open-source library promising the conversion of React components to video emerged as a viable solution for rapid deployment. Preliminary experiments ensured its compatibility with our feature set. An in-depth examination of the library's source code was undertaken to gauge its maintainability, ease of potential forking, and readiness for production scenarios. Direct discussions with the library's author and the wider community bolstered our confidence in its capabilities.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarking-library-performance-on-lambda">Benchmarking Library Performance on Lambda<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#benchmarking-library-performance-on-lambda" class="hash-link" aria-label="Direct link to Benchmarking Library Performance on Lambda" title="Direct link to Benchmarking Library Performance on Lambda">‚Äã</a></h3>
<p>The library was designed to operate on AWS Lambda. A series of benchmarks provided insights into its performance metrics, both in terms of rendering time and cost implications.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cost-and-timing-optimization-with-prototype-benchmarking">Cost and Timing Optimization with Prototype Benchmarking<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#cost-and-timing-optimization-with-prototype-benchmarking" class="hash-link" aria-label="Direct link to Cost and Timing Optimization with Prototype Benchmarking" title="Direct link to Cost and Timing Optimization with Prototype Benchmarking">‚Äã</a></h3>
<p>While the library met our immediate requirements, it presented cost-related challenges for the future, inherently rendering at a rate of 1fps. Recognizing this, I built a simplified clone of the open-source library to conduct focused benchmarking. The tests indicated that by leveraging the library's approach, we could achieve up to 4 FPS. The primary limitation was identified as the screenshot capture time, which took approximately 200ms per frame. This understanding offered clarity on the potential to optimize and align with the company's future cost and performance goals.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="addressing-the-vp8-format-bottleneck">Addressing the VP8 Format Bottleneck<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#addressing-the-vp8-format-bottleneck" class="hash-link" aria-label="Direct link to Addressing the VP8 Format Bottleneck" title="Direct link to Addressing the VP8 Format Bottleneck">‚Äã</a></h3>
<p>The human avatar component of our rendering pipeline employed the VP8 video format for transparency support. While the chosen open-source platform accommodated VP8, it did so with suboptimal speeds. After experimenting with ffmpeg's WebAssembly version to disintegrate the video into frame sequences, we decided to restructure the text-to-video stage. Instead of producing videos, it was reconfigured to generate images directly, yielding twin advantages in performance and cost.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-ffmpeg-integration">Custom ffmpeg Integration<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#custom-ffmpeg-integration" class="hash-link" aria-label="Direct link to Custom ffmpeg Integration" title="Direct link to Custom ffmpeg Integration">‚Äã</a></h3>
<p>Our use case demanded specific ffmpeg flags and a customized ffmpeg version ‚Äì elements not supported natively by the library. To bridge this gap, I employed pnpm patching and automated the building of a custom ffmpeg version from its source.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-reusability-for-consistency">Code Reusability for Consistency<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#code-reusability-for-consistency" class="hash-link" aria-label="Direct link to Code Reusability for Consistency" title="Direct link to Code Reusability for Consistency">‚Äã</a></h3>
<p>A design approach was adopted where the developed code functioned as a reusable library. This allowed its integration into both the frontend for previews and the backend for final video rendering, ensuring uniformity across stages.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="animation-and-transition-integration">Animation and Transition Integration<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#animation-and-transition-integration" class="hash-link" aria-label="Direct link to Animation and Transition Integration" title="Direct link to Animation and Transition Integration">‚Äã</a></h3>
<p>The final development phase involved the addition of animation and scene transition capabilities to the platform.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="impact">Impact<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#impact" class="hash-link" aria-label="Direct link to Impact" title="Direct link to Impact">‚Äã</a></h2>
<ul>
<li>
<p><strong>Stable Production Implementation</strong>: The solution has been integrated into production and operates with minimal disruptions. It is written in 100% typescript with ~90% test coverage.</p>
</li>
<li>
<p><strong>Consistent Previews and Renders</strong>: The disparity between previews and final video renders, previously a pain point, has been eradicated, ensuring consistent user expectations.</p>
</li>
<li>
<p><strong>Swift Feature Integration</strong>: The new system facilitated the rapid introduction of enhancements like custom fonts, animations, and scene transitions, effectively halving the time and effort previously required for such additions.</p>
</li>
<li>
<p><strong>Seamless Scaling</strong>: With the implemented improvements, the platform now comfortably handles the rendering of up to 100,000 videos daily without necessitating additional adjustments or overhead.</p>
</li>
</ul>]]></content>
        <category label="Infrastructure" term="Infrastructure"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[ML Infra design for the GPU Poor]]></title>
        <id>https://blog.vertexcover.io/ml-infra-for-the-gpu-poor</id>
        <link href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor"/>
        <updated>2025-07-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[ML Infra design for the GPU Poor]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="taming-the-beast-how-to-design-a-queueing-system-for-gpu-intensive-workloads">Taming the Beast: How to Design a Queueing System for GPU-Intensive Workloads<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#taming-the-beast-how-to-design-a-queueing-system-for-gpu-intensive-workloads" class="hash-link" aria-label="Direct link to Taming the Beast: How to Design a Queueing System for GPU-Intensive Workloads" title="Direct link to Taming the Beast: How to Design a Queueing System for GPU-Intensive Workloads">‚Äã</a></h2>
<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>When designing for scale, the limiting factor is the GPU availability. So all rate limits / queueing must be designed around GPU availability.</p></div></div>
<!-- -->
<p><strong>A guide for the aspiring software engineer on managing demand when your most critical resource is scarce.</strong></p>
<p>Imagine you're building a revolutionary video generation service. Your platform is a hit, but you have a problem‚Äîa good problem, but a problem nonetheless. You have three types of customers, all knocking on your door at once:</p>
<ul>
<li><strong>B2C Customers:</strong> Individuals using your web app to create short, fun videos. They expect results in seconds.</li>
<li><strong>B2B Giants:</strong> Large enterprise clients who want to process massive workloads of tens of thousands of videos via your API.</li>
</ul>
<p>Here‚Äôs the catch: the heart of your operation, the GPU, is a fixed and expensive resource. Unlike CPU and memory, which are elastic and can be scaled on demand, your GPU capacity is limited. One B2B giant's request could monopolize your entire system, leaving your B2C users staring at a loading spinner for hours.</p>
<p>How do you design a system that ingests all these requests, keeps every customer type happy, and doesn't crumble under the pressure of this GPU bottleneck? The answer lies in the mathematical study of waiting lines: <strong>Queueing Theory</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-counter-intuitive-truth-about-being-busy">The Counter-Intuitive Truth About Being Busy<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#the-counter-intuitive-truth-about-being-busy" class="hash-link" aria-label="Direct link to The Counter-Intuitive Truth About Being Busy" title="Direct link to The Counter-Intuitive Truth About Being Busy">‚Äã</a></h3>
<p>Before we design our system, we must understand a fundamental insight from queueing theory: <strong>wait times skyrocket as utilization exceeds 80%</strong>.</p>
<p>In simple terms, queueing theory uses a few key variables:</p>
<ul>
<li><strong>Arrival Rate (Œª - Lambda):</strong> How quickly tasks enter the queue.</li>
<li><strong>Service Rate (Œº - Mu):</strong> How quickly a server can process tasks.</li>
<li><strong>Utilization (œÅ - Rho):</strong> How busy a server is (Œª/Œº).</li>
</ul>
<div class="w-full bg-gradient-to-br from-gray-50 via-blue-50 to-purple-50 p-4 md:p-8"><div class="absolute inset-0 overflow-hidden pointer-events-none"><div class="absolute -inset-10 opacity-10"><div class="absolute top-1/4 left-1/4 w-64 h-64 bg-purple-300 rounded-full mix-blend-multiply filter blur-3xl animate-pulse"></div><div class="absolute top-3/4 right-1/4 w-64 h-64 bg-blue-300 rounded-full mix-blend-multiply filter blur-3xl animate-pulse delay-1000"></div><div class="absolute bottom-1/4 left-1/2 w-64 h-64 bg-indigo-300 rounded-full mix-blend-multiply filter blur-3xl animate-pulse delay-500"></div></div></div><div class="relative max-w-6xl mx-auto"><div class="backdrop-blur-xl bg-white bg-opacity-40 rounded-3xl border border-white border-opacity-30 shadow-2xl p-4 md:p-8 mb-6 md:mb-8 relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-tr from-white opacity-30 via-transparent to-transparent opacity-50 rounded-3xl"></div><h1 class="text-2xl md:text-4xl font-bold text-gray-800 mb-6 md:mb-8 text-center relative z-10">Queue Wait Time vs. System Utilization</h1><div class="relative z-10 flex justify-center overflow-x-auto"><svg width="520" height="280" viewBox="0 0 520 280" class="min-w-[520px] md:min-w-0 w-full max-w-2xl"><defs><linearGradient id="curveGradient" x1="0%" y1="0%" x2="100%" y2="0%"><stop offset="0%" stop-color="#10b981"></stop><stop offset="70%" stop-color="#f59e0b"></stop><stop offset="95%" stop-color="#ef4444"></stop></linearGradient><filter id="glow"><feGaussianBlur stdDeviation="2.5" result="coloredBlur"></feGaussianBlur><feMerge><feMergeNode in="coloredBlur"></feMergeNode><feMergeNode in="SourceGraphic"></feMergeNode></feMerge></filter></defs><line x1="60" y1="40" x2="60" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="148" y1="40" x2="148" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="236" y1="40" x2="236" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="324" y1="40" x2="324" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="412" y1="40" x2="412" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="500" y1="40" x2="500" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="240" x2="500" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="197.89473684210526" x2="500" y2="197.89473684210526" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="145.26315789473685" x2="500" y2="145.26315789473685" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="92.63157894736844" x2="500" y2="92.63157894736844" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="40" x2="500" y2="40" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><path d="M 60 240 L 64.356 239.8947474736736 L 68.712 239.7873688506105 L 73.068 239.67779905292448 L 77.424 239.56597031938446 L 81.78 239.45181206567182 L 86.136 239.33525073581254 L 90.492 239.2162096441275 L 94.84800000000001 239.09460880698705 L 99.20400000000001 238.97036476359412 L 103.56 238.8433903849524 L 107.916 238.71359467010024 L 112.27199999999999 238.58088252860932 L 116.62800000000001 238.44515454825518 L 120.98400000000001 238.306306746667 L 125.34 238.16423030565255 L 129.69600000000003 238.01881128677206 L 134.05200000000002 237.86993032659802 L 138.40800000000002 237.71746230994864 L 142.764 237.5612760192142 L 147.12 237.401233757711 L 151.476 237.23719094479034 L 155.832 237.06899568020023 L 160.188 236.89648827494088 L 164.54399999999998 236.719500745568 L 168.9 236.53785626857842 L 173.25600000000003 236.35136859115198 L 177.61200000000002 236.15984139412268 L 181.96800000000002 235.96306760259807 L 186.32399999999998 235.76082863913888 L 190.68 235.55289361383544 L 195.036 235.33901844497262 L 199.39200000000002 235.11894490324173 L 203.748 234.8923995716307 L 208.104 234.65909271218445 L 212.45999999999998 234.4187170297588 L 216.816 234.1709463216774 L 221.172 233.91543400081395 L 225.528 233.65181147803784 L 229.884 233.37968638814826 L 234.24 233.09864064133845 L 238.596 232.80822827983948 L 242.952 232.50797311663274 L 247.308 232.19736612993393 L 251.664 231.8758625834608 L 256.02 231.54287883821365 L 260.376 231.1977888165143 L 264.73199999999997 230.8399200732334 L 269.08799999999997 230.46854942233634 L 273.44399999999996 230.08289805889748 L 277.8 229.68212610734759 L 282.156 229.26532651564278 L 286.51200000000006 228.83151820193518 L 290.86800000000005 228.37963834475732 L 295.22400000000005 227.90853368918644 L 299.58 227.416950719279 L 303.93600000000004 226.90352452045732 L 308.292 226.36676612347947 L 312.64799999999997 225.8050480828657 L 317.00399999999996 225.21658799559611 L 321.36 224.599429608504 L 325.716 223.95142109249392 L 330.072 223.27018997519693 L 334.428 222.55311411667623 L 338.78400000000005 221.79728797977475 L 343.14 220.9994832804311 L 347.496 220.1561028942813 L 351.852 219.2631266315477 L 356.208 218.31604715583327 L 360.56399999999996 217.30979389148163 L 364.91999999999996 216.23864220812618 L 369.276 215.09610444826305 L 373.632 213.87479841665444 L 377.988 212.5662876990529 L 382.344 211.1608865094674 L 386.7 209.64741951967298 L 391.056 208.0129240710824 L 395.412 206.24227797090538 L 399.768 204.31773023427752 L 404.124 202.21830390570275 L 408.48 199.91902834008096 L 412.836 197.38994128430616 L 417.192 194.59477599418312 L 421.548 191.48921096909407 L 425.904 188.01850231278908 L 430.26 184.1142287896397 L 434.616 179.6897357795566 L 438.972 174.6336280499374 L 443.328 168.80026152337368 L 447.68399999999997 161.99548492762602 L 452.04 153.9546112988894 L 456.396 144.3071857241489 L 460.752 132.51829124380453 L 465.10800000000006 117.7858896927058 L 469.464 98.85029576823908 L 473.82 73.61344537815125 L 478.176 40 L 482.532 40 L 486.888 40 L 491.24399999999997 40 L 495.6 40" fill="none" stroke="url(#curveGradient)" stroke-width="4" filter="url(#glow)" style="stroke-dasharray:1000;stroke-dashoffset:1000;transition:stroke-dashoffset 2s ease-in-out"></path><g transform="translate(60, 240)"><circle r="6" fill="#10b981" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">0%</text></g><g transform="translate(148, 237.3684210526316)"><circle r="6" fill="#10b981" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">20%</text></g><g transform="translate(280, 229.47368421052633)"><circle r="6" fill="#10b981" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">50%</text></g><g transform="translate(412, 197.89473684210526)"><circle r="6" fill="#f59e0b" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">80%</text></g><g transform="translate(478, 40.00000000000017)"><circle r="6" fill="#ef4444" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">95%</text></g><text x="280" y="275" fill="#374151" text-anchor="middle" class="text-sm font-medium">System Utilization (œÅ)</text><text x="10" y="140" fill="#374151" text-anchor="middle" class="text-sm font-medium" transform="rotate(-90 10 140)">Avg. Wait Time</text><text x="52" y="244" fill="#6b7280" text-anchor="end" class="text-xs">1<!-- -->x</text><text x="52" y="201.89473684210526" fill="#6b7280" text-anchor="end" class="text-xs">5<!-- -->x</text><text x="52" y="149.26315789473685" fill="#6b7280" text-anchor="end" class="text-xs">10<!-- -->x</text><text x="52" y="96.63157894736844" fill="#6b7280" text-anchor="end" class="text-xs">15<!-- -->x</text><text x="52" y="44" fill="#6b7280" text-anchor="end" class="text-xs">20<!-- -->x</text><text x="60" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">0%</text><text x="148" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">20%</text><text x="236" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">40%</text><text x="324" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">60%</text><text x="412" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">80%</text><text x="500" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">100%</text></svg></div></div><div class="grid grid-cols-1 lg:grid-cols-3 gap-4 md:gap-6"><div class="lg:col-span-2 backdrop-blur-xl bg-white bg-opacity-40 rounded-2xl border border-white border-opacity-30 shadow-xl p-4 md:p-6 relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-br from-white opacity-20 via-transparent to-transparent opacity-30 rounded-2xl"></div><div class="relative z-10"><h3 class="text-lg md:text-xl font-bold text-gray-800 mb-4">Key Insight</h3><p class="text-gray-700 mb-4 text-sm md:text-base">As system load (utilization) nears its maximum capacity (100%), the time a new task has to wait in the queue increases <span class="text-red-600 font-bold">exponentially</span>, not linearly.</p><div class="space-y-2 md:space-y-3"><div class="flex items-center justify-between p-3 backdrop-blur-sm bg-white bg-opacity-30 rounded-lg border border-white border-opacity-20"><div class="flex items-center"><div class="w-3 h-3 rounded-full bg-emerald-500 mr-3"></div><span class="text-gray-800 text-sm md:text-base">Safe Zone (Under 80%)</span></div><span class="text-gray-600 font-medium text-sm md:text-base">Predictable &amp; Fast</span></div><div class="flex items-center justify-between p-3 backdrop-blur-sm bg-white bg-opacity-30 rounded-lg border border-white border-opacity-20"><div class="flex items-center"><div class="w-3 h-3 rounded-full bg-amber-500 mr-3"></div><span class="text-gray-800 text-sm md:text-base">Danger Zone (80-95%)</span></div><span class="text-gray-600 font-medium text-sm md:text-base">Wait times skyrocket</span></div><div class="flex items-center justify-between p-3 backdrop-blur-sm bg-white bg-opacity-30 rounded-lg border border-white border-opacity-20"><div class="flex items-center"><div class="w-3 h-3 rounded-full bg-red-500 mr-3"></div><span class="text-gray-800 text-sm md:text-base">Collapse (Above 95%)</span></div><span class="text-gray-600 font-medium text-sm md:text-base">System becomes unstable</span></div></div></div></div><div class="backdrop-blur-xl bg-white bg-opacity-40 rounded-2xl border border-white border-opacity-30 shadow-xl p-4 md:p-6 relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-tl from-blue-500 opacity-10 via-transparent to-transparent opacity-50 rounded-2xl"></div><div class="relative z-10"><div class="flex items-center mb-4"><div class="w-10 h-10 rounded-full bg-blue-500/80 flex items-center justify-center mr-3 border-2 border-white/50"><span class="text-white font-bold text-xl">üí°</span></div><h3 class="text-lg md:text-xl font-bold text-gray-800">Design Rule</h3></div><p class="text-gray-700 text-sm md:text-base">To maintain a stable and predictable system, design your auto-scaling and rate-limiting to keep average utilization below the <b class="text-blue-700">~80% "knee"</b> of the curve.</p></div></div></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-architects-solution-from-one-big-line-to-a-multi-lane-highway">The Architect's Solution: From One Big Line to a Multi-Lane Highway<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#the-architects-solution-from-one-big-line-to-a-multi-lane-highway" class="hash-link" aria-label="Direct link to The Architect's Solution: From One Big Line to a Multi-Lane Highway" title="Direct link to The Architect's Solution: From One Big Line to a Multi-Lane Highway">‚Äã</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-the-foundational-shift-the-video-minute-as-the-true-unit-of-work">1. The Foundational Shift: The "Video-Minute" as the True Unit of Work<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#1-the-foundational-shift-the-video-minute-as-the-true-unit-of-work" class="hash-link" aria-label="Direct link to 1. The Foundational Shift: The &quot;Video-Minute&quot; as the True Unit of Work" title="Direct link to 1. The Foundational Shift: The &quot;Video-Minute&quot; as the True Unit of Work">‚Äã</a></h4>
<p>The system was re-architected around the concept of a "video-minute." Instead of measuring queue length by the number of jobs, it was measured by the total duration of all videos waiting to be processed. This immediately provided a far more accurate picture of the outstanding load on the GPU fleet.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-architecture-the-two-lane-highway">2. Architecture: The Two-Lane Highway<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#2-architecture-the-two-lane-highway" class="hash-link" aria-label="Direct link to 2. Architecture: The Two-Lane Highway" title="Direct link to 2. Architecture: The Two-Lane Highway">‚Äã</a></h4>
<p>The core idea of separating UI and batch users was validated and implemented.
Action: Two completely parallel infrastructures were created, each with its own dedicated queue and GPU fleet. This prevented any possibility of a "noisy neighbor" from the batch API world affecting the premium UI user experience. The UI queue was fed by a small, reserved pool of GPUs, while the batch queue was serviced by an auto-scaling fleet.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-smart-scaling-beyond-simple-queue-length">3. Smart Scaling: Beyond Simple Queue Length<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#3-smart-scaling-beyond-simple-queue-length" class="hash-link" aria-label="Direct link to 3. Smart Scaling: Beyond Simple Queue Length" title="Direct link to 3. Smart Scaling: Beyond Simple Queue Length">‚Äã</a></h4>
<div class="w-full bg-gradient-to-br from-gray-50 via-indigo-50 to-blue-50 p-4 md:p-8"><div class="relative max-w-6xl mx-auto"><div class="backdrop-blur-xl bg-white bg-opacity-40 rounded-3xl border border-white border-opacity-30 shadow-2xl p-4 md:p-8 mb-6 md:mb-8"><h1 class="text-2xl md:text-4xl font-bold text-gray-800 mb-2 text-center">The GPU Scaling Decision</h1><p class="text-center text-gray-600 mb-8">When is a cold start worth the cost?</p><div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-8 px-4"><div><label for="cold-start-slider" class="block text-sm font-medium text-gray-700">GPU Cold Start Time: <span class="font-bold text-indigo-600">3<!-- --> min</span></label><input id="cold-start-slider" type="range" min="2" max="5" step="0.5" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-indigo-600" value="3"></div><div><label for="queue-length-slider" class="block text-sm font-medium text-gray-700">Queued Work: <span class="font-bold text-teal-600">8<!-- --> video-minutes</span></label><input id="queue-length-slider" type="range" min="0" max="20" step="1" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-teal-600" value="8"></div></div><div class="flex flex-col gap-8"><div class="flex justify-center"><div class="relative z-10 flex-shrink-0"><svg width="520" height="300" viewBox="0 0 520 300" class="min-w-[520px] md:min-w-0"><line x1="60" y1="40" x2="60" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="170" y1="40" x2="170" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="280" y1="40" x2="280" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="390" y1="40" x2="390" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="500" y1="40" x2="500" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="250" x2="500" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="197.5" x2="500" y2="197.5" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="145" x2="500" y2="145" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="92.5" x2="500" y2="92.5" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="40" x2="500" y2="40" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="250" x2="500" y2="250" stroke="#6b7280" stroke-width="2"></line><line x1="60" y1="40" x2="60" y2="250" stroke="#6b7280" stroke-width="2"></line><g><line x1="60" y1="250" x2="60" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="60" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">0</text></g><g><line x1="170" y1="250" x2="170" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="170" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">5</text></g><g><line x1="280" y1="250" x2="280" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="280" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">10</text></g><g><line x1="390" y1="250" x2="390" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="390" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">15</text></g><g><line x1="500" y1="250" x2="500" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="500" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">20</text></g><g><line x1="55" y1="250" x2="60" y2="250" stroke="#6b7280" stroke-width="1"></line><text x="50" y="254" text-anchor="end" class="text-xs fill-gray-600 font-medium">0</text></g><g><line x1="55" y1="197.5" x2="60" y2="197.5" stroke="#6b7280" stroke-width="1"></line><text x="50" y="201.5" text-anchor="end" class="text-xs fill-gray-600 font-medium">5</text></g><g><line x1="55" y1="145" x2="60" y2="145" stroke="#6b7280" stroke-width="1"></line><text x="50" y="149" text-anchor="end" class="text-xs fill-gray-600 font-medium">10</text></g><g><line x1="55" y1="92.5" x2="60" y2="92.5" stroke="#6b7280" stroke-width="1"></line><text x="50" y="96.5" text-anchor="end" class="text-xs fill-gray-600 font-medium">15</text></g><g><line x1="55" y1="40" x2="60" y2="40" stroke="#6b7280" stroke-width="1"></line><text x="50" y="44" text-anchor="end" class="text-xs fill-gray-600 font-medium">20</text></g><line x1="192" y1="40" x2="192" y2="250" stroke="#1e40af" stroke-width="2" stroke-dasharray="5 5"></line><path d="M 60 250 L 500 40" stroke="#f59e0b" stroke-width="3" fill="none" stroke-dasharray="6 4"></path><path d="M 60 218.5 L 500 113.5" stroke="#14b8a6" stroke-width="3" fill="none"></path><circle cx="192" cy="187" r="6" fill="#1e40af" stroke="white" stroke-width="2"></circle><text x="192" y="175" text-anchor="middle" class="text-xs font-bold fill-blue-800">Breakeven</text><text x="192" y="207" text-anchor="middle" class="text-xs font-bold fill-blue-800">6.0</text><line x1="236" y1="40" x2="236" y2="250" stroke="#4f46e5" stroke-width="2" stroke-dasharray="3 3"></line><circle cx="236" cy="166" r="5" fill="#f59e0b" stroke="white" stroke-width="2"></circle><circle cx="236" cy="176.5" r="5" fill="#14b8a6" stroke="white" stroke-width="2"></circle><text x="236" y="32" text-anchor="middle" class="text-xs font-bold fill-indigo-700">8</text><text x="280" y="290" text-anchor="middle" class="text-sm font-medium fill-gray-600">Video-Minutes in Queue</text><text x="15" y="145" text-anchor="middle" transform="rotate(-90 15 145)" class="text-sm font-medium fill-gray-600">Time to Complete (min)</text></svg></div></div><div class="max-w-4xl mx-auto w-full"><div class="p-6 bg-white/60 rounded-2xl border border-white/30 shadow-lg backdrop-blur-sm"><h3 class="text-xl font-bold text-gray-800 mb-6 text-center">Calculated Outcome</h3><div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6"><div class="flex items-center justify-between p-4 bg-amber-100/70 rounded-xl border border-amber-200/50"><span class="font-medium text-amber-800 text-lg">Time if you WAIT:</span><span class="font-bold text-2xl text-amber-900">8.0<!-- --> min</span></div><div class="flex items-center justify-between p-4 bg-teal-100/70 rounded-xl border border-teal-200/50"><span class="font-medium text-teal-800 text-lg">Time if you SCALE:</span><span class="font-bold text-2xl text-teal-900">7.0<!-- --> min</span></div></div><div class="grid grid-cols-1 lg:grid-cols-2 gap-6 items-center"><div class="flex justify-center lg:justify-start"><div class="px-8 py-4 rounded-xl text-center shadow-md min-w-[200px] bg-gradient-to-r from-teal-500 to-teal-600"><span class="text-white font-bold text-2xl tracking-wider drop-shadow-sm">SCALE NOW</span></div></div><div class="text-center lg:text-left"><h4 class="font-semibold text-gray-700 flex items-center justify-center lg:justify-start gap-2 mb-3">üí° Key Insight:</h4><p class="text-sm text-gray-600 leading-relaxed mb-3">It only makes sense to provision a new GPU when the queue length is more than <b class="text-indigo-700">twice the cold start time</b>.</p><div class="inline-block p-3 bg-indigo-50/70 rounded-lg border border-indigo-200/50"><p class="font-bold text-lg text-indigo-800">Breakeven at <!-- -->6.0<!-- --> video-minutes</p></div></div></div></div></div><div class="flex justify-center"><div class="p-4 bg-white/60 rounded-xl border border-white/30 shadow-md backdrop-blur-sm"><div class="flex items-center justify-center gap-8"><div class="flex items-center gap-3"><div class="w-4 h-4 bg-amber-500 rounded border-2 border-amber-600"></div><span class="text-sm font-medium text-gray-700">Wait (Don't Scale)</span></div><div class="flex items-center gap-3"><div class="w-4 h-4 bg-teal-500 rounded border-2 border-teal-600"></div><span class="text-sm font-medium text-gray-700">Scale Now</span></div></div></div></div></div></div></div></div>
<p>Yes, we should auto-scale the GPU, but how much? There are few places we can look for data to make informed choice.</p>
<ul>
<li>Historical Learning: The scaling logic was made parametric to learn from historical provisioning times, helping it make smarter predictions about when to initiate scaling.</li>
<li>Metric-Driven Scaling: The auto-scaler was triggered based on "video-minutes".</li>
<li>Cold Start problem: There is 2-4 minute cold-start time for GPUs. So, provisioning a GPU only makes sense if the <code>video-minutes</code> to be processed are <code>X</code> times of cold start time. That way, frequent GPU provisioning does not lead inefficient compute. It's economically inefficient to provision a new GPU that takes 3 minutes to start, only to process a 2-minute video.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-predictability-through-pragmatism-working-backwards-from-limits">4. Predictability Through Pragmatism: Working backwards from limits<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#4-predictability-through-pragmatism-working-backwards-from-limits" class="hash-link" aria-label="Direct link to 4. Predictability Through Pragmatism: Working backwards from limits" title="Direct link to 4. Predictability Through Pragmatism: Working backwards from limits">‚Äã</a></h4>
<p>The team acknowledged a hard truth: their ability to autoscale was not infinite. Based on historical data and cloud provider limits, they identified a realistic maximum number of GPUs they could reliably provision.
The fixed maximum capacity (Max GPUs * video-minutes per GPU) became the system's total throughput budget. This budget was then divided among the maximum number of potential concurrent batch users.
Result: This calculation yielded a crucial metric: the maximum video-minutes per minute that could be allocated to a single user. This became the foundation for providing realistic SLAs.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="5-the-slas-per-tenant-throttling-and-dynamic-etas">5. The SLAs: Per-Tenant Throttling and Dynamic ETAs<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#5-the-slas-per-tenant-throttling-and-dynamic-etas" class="hash-link" aria-label="Direct link to 5. The SLAs: Per-Tenant Throttling and Dynamic ETAs" title="Direct link to 5. The SLAs: Per-Tenant Throttling and Dynamic ETAs">‚Äã</a></h4>
<p>This per-user capacity allocation was not just a theoretical number; it was enforced at the ingestion layer.
Action: A user-aware rate limiter was placed at the front of the batch queue. If a user was allocated a capacity of "1 video-minute per minute", this gatekeeper would only release that amount of work from that user's batch into the main queue each minute.
Accurate SLAs: This system allowed for incredibly predictable SLAs. If a user with a 1 video-minute/minute capacity submitted a batch of 100 jobs totaling 200 video-minutes, the system could confidently return an ETA of ~200 minutes plus a safety buffer, because it knew exactly how fast that user's jobs would be fed to the processors.</p>]]></content>
        <category label="Infrastructure" term="Infrastructure"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Strot - The API Scraper]]></title>
        <id>https://blog.vertexcover.io/strot-is-a-api-scraper</id>
        <link href="https://blog.vertexcover.io/strot-is-a-api-scraper"/>
        <updated>2025-07-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Strot (Sanskrit meaning source) is an AI agent which scrapes web api:]]></summary>
        <content type="html"><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>Strot (Sanskrit meaning source) is an AI agent which scrapes web api:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Instead of scraping the dom, identifies the right api call.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Fast, reliable, complete data scraping for listing data is possible via API scraping. </li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Strot figures the api call so you don't have to.</li></ol></div></div>
<p><a href="https://github.com/vertexcover-io/strot" target="_blank" rel="noopener noreferrer">Try out Strot!</a></p>
<!-- -->
<div style="position:relative;width:100%;padding-bottom:56.25%;height:0"><iframe src="https://www.youtube.com/embed/OCL3rWG9mDs" title="Strot - The API Scraper Demo" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="position:absolute;top:0;left:0;width:100%;height:100%;border:none"></iframe></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-if--">What if ... ?<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#what-if--" class="hash-link" aria-label="Direct link to What if ... ?" title="Direct link to What if ... ?">‚Äã</a></h2>
<p>When working with clients, we figured that they frequently need to scrape listing data like reviews and product listings. The DOM Scraping solutions don't give complete data.</p>
<p>When is comes to scraping reviews, things CAN BE slightly different than running playwright scripts. That's the idea we started with!</p>
<p>It stems from the insights on browsing shopify. Since, shopify has plugin ecosystem, a lot of reviews come from plugins. They give the reviews in html / json form via api that the page renders.
Since, reviews - if they are worthwhile - would be in 100s for a given product, it would be very unlikely that someone with good web-dev practices will send all of them on one shot. There MUST be a second call (pagination) that requests for further reviews for the given product.</p>
<p>What if ... we could scrape listing data via intercepting AJAX calls that are made from the browser itself?</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-genesis">The Genesis<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#the-genesis" class="hash-link" aria-label="Direct link to The Genesis" title="Direct link to The Genesis">‚Äã</a></h2>
<p>Hence, an experiment is born - called <code>strot</code>. In sanskrit it means source. We are trying to get to the ajax calls that gets us listing data.</p>
<p>The review scraping problem sits at a unique position. There are always MANY reviews which either causes cost ballooning no matter which existing approach you take.</p>
<p>Strot is the only project which can scrape the data available as api call - at all - using natural language.</p>
<div style="overflow-x:auto;margin:20px 0"><table style="width:100%;border-collapse:collapse;font-size:14px;border:1px solid var(--comparison-border)"><thead><tr style="background-color:var(--comparison-header-bg)"><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">Feature</th><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">Playwright</th><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">LLM Scraper</th><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">Strot (Ours)</th></tr></thead><tbody><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Cost</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">Infrastructure costs for automation</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Pay per page + LLM inference</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">One-time API discovery</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Maintenance</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">High - UI changes break scripts</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">Medium - prompt engineering needed</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Low - APIs rarely change</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Intelligence Required</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">High - manual scraper</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">High - per page analysis</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">One-time - for API discovery</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Scalability</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Poor - loads full pages</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Expensive - each page costs $</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Excellent - pagination via API</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Setup Complexity</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">Medium - browser automation</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Low - plug and play</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Low - plug and play</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Uniqueness</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Common approach</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Common approach</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Unique to us</td></tr></tbody></table></div>
<p>So, IF we could find the ajax call ‚Üí we only have to spend time figuring out the API call. and voila! You can simply call API - this is cheapest, fastest, most reliable approach of all.</p>
<p>And the unique to us. Hence, we took a bite.</p>
<p>But the challenge is which api call is most relevnt for scraping reviews ?
we solve this by capturing screenshot, visually analysing if review is preseng in the screenshot. Then we find a matching ajax call that has a similar content. Voila!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-challenges-of-current-approaches">The challenges of current approaches<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#the-challenges-of-current-approaches" class="hash-link" aria-label="Direct link to The challenges of current approaches" title="Direct link to The challenges of current approaches">‚Äã</a></h2>
<p>Each traditional approach faces fundamental limitations that compound at scale:</p>
<div style="background-color:rgba(207, 34, 46, 0.1);border:1px solid rgba(207, 34, 46, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #cf222e;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">üêõ</span><strong style="color:#cf222e;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Edge Case<!-- -->: <!-- -->The Listing Data has Volume Problem</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Most products with worthwhile reviews have 100-10,000+ reviews. Traditional approaches cost:</p><ul>
<li><strong>Playwright</strong>: 100 reviews √ó 3 pages √ó 10s load time = 30+ minutes</li>
<li><strong>LLM Scraper</strong>: 100 reviews √ó $0.10 per page = $10+ per product</li>
<li><strong>Manual API</strong>: 100 reviews √ó 15min engineer time = $200+ per product</li>
</ul><p>Strot's approach: 100 reviews √ó 0.1s API call = 10 seconds total.</p></div></div>
<h1>Technical Details</h1>
<div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">üîç</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->System Architecture &amp; Technical Approach</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">‚ñº</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div>
<div style="background-color:rgba(26, 127, 55, 0.1);border:1px solid rgba(26, 127, 55, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #1a7f37;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">üèóÔ∏è</span><strong style="color:#1a7f37;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Architecture Detail<!-- -->: <!-- -->Why AJAX Interception vs DOM Scraping</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Traditional DOM scraping faces several fundamental limitations:</p><ul>
<li><strong>Rate Limiting</strong>: Websites throttle based on page loads, not API calls</li>
<li><strong>Bot Detection</strong>: Full page loads trigger anti-bot measures (Cloudflare, etc.)</li>
<li><strong>Resource Overhead</strong>: Loading entire DOM + assets vs lightweight JSON responses</li>
<li><strong>Maintenance Burden</strong>: CSS selectors break with UI changes, APIs rarely change</li>
</ul><p>AJAX interception bypasses these by operating at the data layer, not presentation layer.</p></div></div>
<div style="background-color:rgba(9, 105, 218, 0.1);border:1px solid rgba(9, 105, 218, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #0969da;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">üíæ</span><strong style="color:#0969da;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Implementation Note<!-- -->: <!-- -->AJAX Call Matching Algorithm</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Our matching algorithm works in stages:</p><ol>
<li><strong>Content Extraction</strong>: Extract review text from screenshots using OCR + Vision LLM</li>
<li><strong>API Response Analysis</strong>: Parse all captured AJAX responses for text content</li>
<li><strong>Fuzzy String Matching</strong>: Use algorithms like Levenshtein distance, Jaccard similarity</li>
<li><strong>Confidence Scoring</strong>:<!-- -->
<ul>
<li>Text overlap ratio (&gt;90% = high confidence)</li>
<li>JSON structure analysis (nested objects, review-like fields)</li>
<li>Response size correlation with visible review count</li>
</ul>
</li>
</ol><p><strong>Edge Case Handling</strong>:</p><ul>
<li>Paginated responses (partial matches expected)</li>
<li>Localized content (different languages)</li>
<li>Dynamic timestamps/IDs (filter out volatile fields)</li>
</ul></div></div>
<div style="background-color:rgba(191, 135, 0, 0.1);border:1px solid rgba(191, 135, 0, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #bf8700;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">‚ö°</span><strong style="color:#bf8700;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Performance Insight<!-- -->: <!-- -->Why Screenshot Analysis vs Pure Network Analysis</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Since we have to do the hard part of finding the right AJAX call ONLY once, it means that we can use augmentation from vision understanding to make it more accurate.</p><p>This helps by:</p><ul>
<li>Confirms which API calls actually render user-visible content.</li>
<li>Handles cases where multiple API calls contain review data</li>
<li>Eliminates false positives from internal/admin API calls</li>
</ul></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-codegen">The codegen<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#the-codegen" class="hash-link" aria-label="Direct link to The codegen" title="Direct link to The codegen">‚Äã</a></h3>
<p>We internally represent all the relevant information as json. This helps us to generate http client in any language of choice. Calling this API endpoint in succession will give all the reviews.</p>
<div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">üîç</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->Code Generation Pipeline &amp; Implementation</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">‚ñº</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div>
<div style="margin:48px 0;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:32px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04)"><div style="margin-bottom:32px"><div style="display:flex;align-items:center;margin-bottom:8px"><div style="width:4px;height:32px;background-color:var(--ifm-color-primary, #2e8555);border-radius:2px;margin-right:16px"></div><h2 style="font-size:1.8rem;font-weight:700;margin:0;background:linear-gradient(135deg, var(--ifm-color-primary, #2e8555), var(--ifm-color-primary-light, #33925d));-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text">Iteratively Improving via Error Analysis and Evals</h2></div><div style="height:1px;background:linear-gradient(90deg, var(--ifm-color-primary, #2e8555) 0%, transparent 100%);width:100%;opacity:0.3"></div></div><div style="line-height:1.7"><p>Evals were central to us while building this. We had three tiered system for evals that served us well.</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Does the analysis identify the right ajax call?</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Is the pagination strategy detection done correctly?</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Is the http api (codegen) able to get all the reviews?</li></ol><div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">üîç</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->Comprehensive Evaluation System Architecture</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">‚ñº</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div><div style="margin-bottom:32px;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:24px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04);transition:all 0.2s ease-in-out"><h4 style="font-size:1.3rem;font-weight:700;margin-bottom:16px;color:var(--ifm-color-primary, #2e8555)">Error Analysis</h4><div style="font-size:1rem;line-height:1.7"><p>This was the most consuming element for us until we vibe-coded initial version of this dashboard to see the logs as data.</p><div style="background-color:rgba(9, 105, 218, 0.1);border:1px solid rgba(9, 105, 218, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #0969da;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">üíæ</span><strong style="color:#0969da;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Implementation Note<!-- -->: <!-- -->Observability Dashboard</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Our observability dashboard processes shows data from:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Application logs (structured JSON)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">LLM API call traces (OpenAI/Anthropic)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Playwright screenshots</li></ol><p>This helps to do the error analysis and improve the system iteratively.</p></div></div><p>Here is a quick peek over the dashboard we made to do the error analysis:</p><p>This shows us the cost and token usage:</p><a href="https://blog.vertexcover.io/img/strot-dashboard-analysis.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-analysis.png" alt="Strot dashboard cost and token analysis" style="cursor:pointer"></a><p>This shows us the step by step observability into what is happening:</p><a href="https://blog.vertexcover.io/img/strot-dashboard-step.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-step.png" alt="Strot dashboard step by step analysis" style="cursor:pointer"></a></div></div><div style="margin-bottom:32px;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:24px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04);transition:all 0.2s ease-in-out"><h4 style="font-size:1.3rem;font-weight:700;margin-bottom:16px;color:var(--ifm-color-primary, #2e8555)">Pagination</h4><div style="font-size:1rem;line-height:1.7"><a href="https://blog.vertexcover.io/img/strot-dashboard-pagination.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-pagination.png" alt="Strot dashboard pagination" style="cursor:pointer"></a></div></div><div style="margin-bottom:32px;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:24px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04);transition:all 0.2s ease-in-out"><h4 style="font-size:1.3rem;font-weight:700;margin-bottom:16px;color:var(--ifm-color-primary, #2e8555)">Codegen</h4><div style="font-size:1rem;line-height:1.7"><a href="https://blog.vertexcover.io/img/strot-dashboard-codegen.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-codegen.png" alt="Strot dashboard codegen" style="cursor:pointer"></a></div></div></div></div>
<p>We are also learning. This was our attempt at scraping the webpage and using the visual understanding of image models to get to the reviews faster. if you feel this can be improved, feel free to share those with us on <a href="https://github.com/vertexcover-io/strot/issues" target="_blank" rel="noopener noreferrer">github-issues</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="roadmap">Roadmap<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#roadmap" class="hash-link" aria-label="Direct link to Roadmap" title="Direct link to Roadmap">‚Äã</a></h2>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">We are already on a path to make this a generic scraper. Currently, our evals sets show the tracking progress on various websites. It will be released soon.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">if you would like us to host this as a service for you, we are more than happy to. Come chat with us at [contact email]</li></ol>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching Claude Code to Work Independently]]></title>
        <id>https://blog.vertexcover.io/claude-code-context-engineering-v2</id>
        <link href="https://blog.vertexcover.io/claude-code-context-engineering-v2"/>
        <updated>2025-07-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Problem: You're trapped micromanaging Claude Code instead of building]]></summary>
        <content type="html"><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p><strong>Problem:</strong> You're trapped micromanaging Claude Code instead of building</p><p><strong>Solution:</strong> Train Claude Code once, then let it work autonomously</p><p><strong>How:</strong> Strategic context engineering: CLAUDE.md files, systematic workflows, and learning capture</p><p><strong>Result:</strong> Claude Code becomes your autonomous teammate</p></div></div>
<p>Here is <a href="https://gist.github.com/tripathi456/bfaf9add4b70bff131cd574c2f93cfac" target="_blank" rel="noopener noreferrer">CLAUDE.md</a></p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-0-just-moved-from-cursor-to-claude-code">Day 0: Just moved from cursor to claude code<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-0-just-moved-from-cursor-to-claude-code" class="hash-link" aria-label="Direct link to Day 0: Just moved from cursor to claude code" title="Direct link to Day 0: Just moved from cursor to claude code">‚Äã</a></h2>
<p><em>It's 11 PM on a Tuesday. My token budget just hit zero. Claude Code is asking me the same question for the fourth time: "What coding style does this project use?" I've spent 6 hours being a glorified copy-paste machine, explaining the same context over and over.</em></p>
<p><em>Sound familiar?</em></p>
<p>That night, I realized something critical: <strong>Claude Code is teachable</strong>. But I was the worst teacher on Earth.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-1-fighting-claude-code-the-problem">Day 1: Fighting Claude Code (The Problem)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-1-fighting-claude-code-the-problem" class="hash-link" aria-label="Direct link to Day 1: Fighting Claude Code (The Problem)" title="Direct link to Day 1: Fighting Claude Code (The Problem)">‚Äã</a></h2>
<p>Every conversation was Groundhog Day:</p>
<ul>
<li>"What's our testing framework again?"</li>
<li>"How do we name files in this project?"</li>
<li>"What's the deployment process?"</li>
</ul>
<p>I was Claude Code's personal Wikipedia. <strong>This had to change.</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-2-the-teaching-template-the-mentor">Day 2: The Teaching Template (The Mentor)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-2-the-teaching-template-the-mentor" class="hash-link" aria-label="Direct link to Day 2: The Teaching Template (The Mentor)" title="Direct link to Day 2: The Teaching Template (The Mentor)">‚Äã</a></h2>
<blockquote>
<p>What if Claude Code could remember your project like a team member who's been there for years?</p>
</blockquote>
<p>Instead of explaining everything every time, I wrote a template. The gist is:</p>
<div class="language-md codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-md codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> Communication: Be concise, reference past learnings from docs/work/</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> File Naming: YYYY-MM-DD-[001]-[category]-[summary].md  </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> Never code without checking docs/work/ for similar past solutions</span><br></span></code></pre></div></div>
<p>That's it. <strong>This eliminated hours of repetitive context.</strong></p>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>See the prompt ‚Üí</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-md codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-md codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> Project: [Your Project Name]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Tech Stack &amp; Tooling</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Language</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Python 3.11+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Package Manager</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: </span><span class="token code-snippet code keyword" style="color:#00009f">`uv`</span><span class="token plain"> (use </span><span class="token code-snippet code keyword" style="color:#00009f">`uv add &lt;dependency&gt;`</span><span class="token plain">, </span><span class="token code-snippet code keyword" style="color:#00009f">`uv run &lt;script&gt;`</span><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Testing</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: pytest with coverage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Linting</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: ruff + mypy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Systematic File Naming</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Format: </span><span class="token code-snippet code keyword" style="color:#00009f">`YYYY-MM-DD-[001-999]-[category]-[four-word-summary].md`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Folder: </span><span class="token code-snippet code keyword" style="color:#00009f">`docs/work/`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Categories: </span><span class="token code-snippet code keyword" style="color:#00009f">`bug`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`feature`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`task`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`research`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`learnings`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Examples:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token code-snippet code keyword" style="color:#00009f">`2025-07-18-001-feature-user-authentication-system.md`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token code-snippet code keyword" style="color:#00009f">`2025-07-18-002-bug-database-connection-timeout.md`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Communication Style</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Concise</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: No fluff, direct responses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Evidence-based</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Show, don't just tell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Contextual</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Reference past learnings from </span><span class="token code-snippet code keyword" style="color:#00009f">`docs/work/`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Planning Protocol</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">1.</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Context Gathering</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Check </span><span class="token code-snippet code keyword" style="color:#00009f">`docs/work/`</span><span class="token plain"> for relevant past decisions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">2.</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Assumption Documentation</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Explicit assumptions in plan files</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">3.</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Execution Gate</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Only proceed after planning is complete</span><br></span></code></pre></div></div></div></div></div>
<p><strong>The transformation was instant.</strong> Claude Code started referencing past decisions, avoiding repeated mistakes, and building on previous work. <strong>It finally felt like working with a teammate.</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-3-the-learning-moment---30-context---the-training">Day 3: The Learning Moment - 30% context - (The Training)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-3-the-learning-moment---30-context---the-training" class="hash-link" aria-label="Direct link to Day 3: The Learning Moment - 30% context - (The Training)" title="Direct link to Day 3: The Learning Moment - 30% context - (The Training)">‚Äã</a></h2>
<blockquote>
<p>What if Claude Code could learn from every mistake and never repeat it?</p>
</blockquote>
<p>When your context hits 30%, you have one chance to crystallize everything learned. Miss it, and you go back to day 1.</p>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>See the prompt ‚Üí</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-md codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-md codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">When context drops below 30%: </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">1.</span><span class="token plain"> Document every decision made</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">2.</span><span class="token plain"> List what failed (with code snippets)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">3.</span><span class="token plain"> Note what worked brilliantly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">4.</span><span class="token plain"> Write handoff notes for next session</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Use the </span><span class="token code-snippet code keyword" style="color:#00009f">`Systematic File Naming`</span><span class="token plain"> given above.</span><br></span></code></pre></div></div></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-4-the-autonomous-engineer-the-victory">Day 4: The Autonomous Engineer (The Victory)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-4-the-autonomous-engineer-the-victory" class="hash-link" aria-label="Direct link to Day 4: The Autonomous Engineer (The Victory)" title="Direct link to Day 4: The Autonomous Engineer (The Victory)">‚Äã</a></h2>
<p>I saw this tweet - <a href="https://x.com/_svs_/status/1928753160337637726" target="_blank" rel="noopener noreferrer">@svs used Claude Code as an MCP client to write an MCP server</a>.</p>
<p>Something magical discovered: <strong>When put in verifiable workflows, Claude Code started working much better!</strong>:</p>
<ul>
<li>Write code ‚Üí Run tests ‚Üí Fix failures ‚Üí Repeat</li>
<li>Build feature ‚Üí Deploy to staging ‚Üí Check logs ‚Üí Iterate</li>
<li>Analyze data ‚Üí Generate insights ‚Üí Verify against sources ‚Üí Summarize</li>
</ul>
<p><strong>I wasn't micromanaging anymore. I was collaborating.</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="stories-from-other-folks">Stories from other folks<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#stories-from-other-folks" class="hash-link" aria-label="Direct link to Stories from other folks" title="Direct link to Stories from other folks">‚Äã</a></h2>
<p>Met awesome folks at <a href="https://hasgeek.com/fifthelephant/2025/" target="_blank" rel="noopener noreferrer">Fifth Elephant Conference</a> where we shared claude code learnings.</p>
<div class="relative bg-emerald-50 bg-opacity-30 dark:bg-emerald-950 dark:bg-opacity-10 rounded-xl p-6 my-8 border-2 border-emerald-200 dark:border-emerald-800"><div class="absolute top-0 right-0 w-12 h-12 overflow-hidden"><div class="absolute top-0 right-0 w-0 h-0 border-l-12 border-b-12 border-l-transparent border-b-emerald-200 dark:border-b-emerald-800"></div></div><div class="flex items-center gap-3 mb-4"><div class="flex-shrink-0 w-10 h-10 bg-emerald-100 dark:bg-emerald-900 dark:bg-opacity-30 rounded-full flex items-center justify-center"><svg class="w-5 h-5 text-emerald-600 dark:text-emerald-400" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg></div><div><div class="text-xs font-medium text-emerald-700 dark:text-emerald-300 uppercase tracking-wide">Pro Tips from</div><a href="https://www.linkedin.com/in/codingnirvana/" target="_blank" rel="noopener noreferrer" class="text-lg font-semibold text-emerald-900 dark:text-emerald-100 hover:text-emerald-700 dark:hover:text-emerald-300 transition-colors">Rajesh</a></div></div><div class="border-l-4 border-emerald-300 dark:border-emerald-700 pl-4 text-gray-700 dark:text-gray-300"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-token-budget-hack-that-doubled-my-productivity">The Token Budget Hack That Doubled My Productivity<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#the-token-budget-hack-that-doubled-my-productivity" class="hash-link" aria-label="Direct link to The Token Budget Hack That Doubled My Productivity" title="Direct link to The Token Budget Hack That Doubled My Productivity">‚Äã</a></h3><p>Rajesh was burning through tokens like crazy at his startup. Then he discovered something weird about Claude's <a href="https://support.anthropic.com/en/articles/11145838-using-claude-code-with-your-pro-or-max-plan" target="_blank" rel="noopener noreferrer">5-hour windows</a>.</p><p><strong>His discovery:</strong> Start sessions at 7 AM instead of 9 AM.</p><p>Why? The overlapping windows create a "double token zone" during peak hours:</p><p><strong>Before:</strong> 9am-2pm, 2pm-7pm (standard)<br>
<strong>After:</strong> 7am-12pm, 12pm-5pm, 5pm-10pm (overlapping)</p><p><strong>Result:</strong> Between 9am-5pm = <strong>double tokens available</strong></p><img src="https://blog.vertexcover.io/img/timeline.svg"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-csv-strategy-that-saved-hours">The CSV Strategy That Saved Hours<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#the-csv-strategy-that-saved-hours" class="hash-link" aria-label="Direct link to The CSV Strategy That Saved Hours" title="Direct link to The CSV Strategy That Saved Hours">‚Äã</a></h3><p>Rajesh's team was dealing with lots of data analysis requests. CSV files everywhere. Claude kept hitting context limits trying to process raw data.</p><p><strong>The breakthrough:</strong> Stop feeding Claude data. Feed it scripts.</p><p><strong>Old way:</strong> "Here's a 10MB CSV, analyze it"<br>
<strong>New way:</strong> "Write a script to analyze this CSV type, then run it"</p><p><strong>Why it works:</strong> Scripts are tiny. Results are focused. Claude guides itself using its own analysis output.</p></div></div>
<div class="relative bg-emerald-50 bg-opacity-30 dark:bg-emerald-950 dark:bg-opacity-10 rounded-xl p-6 my-8 border-2 border-emerald-200 dark:border-emerald-800"><div class="absolute top-0 right-0 w-12 h-12 overflow-hidden"><div class="absolute top-0 right-0 w-0 h-0 border-l-12 border-b-12 border-l-transparent border-b-emerald-200 dark:border-b-emerald-800"></div></div><div class="flex items-center gap-3 mb-4"><div class="flex-shrink-0 w-10 h-10 bg-emerald-100 dark:bg-emerald-900 dark:bg-opacity-30 rounded-full flex items-center justify-center"><svg class="w-5 h-5 text-emerald-600 dark:text-emerald-400" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg></div><div><div class="text-xs font-medium text-emerald-700 dark:text-emerald-300 uppercase tracking-wide">Pro Tips from</div><a href="https://www.shelfradar.ai/" target="_blank" rel="noopener noreferrer" class="text-lg font-semibold text-emerald-900 dark:text-emerald-100 hover:text-emerald-700 dark:hover:text-emerald-300 transition-colors">Ashwant</a></div></div><div class="border-l-4 border-emerald-300 dark:border-emerald-700 pl-4 text-gray-700 dark:text-gray-300"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-accidental-discovery-that-changed-everything">The Accidental Discovery That Changed Everything<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#the-accidental-discovery-that-changed-everything" class="hash-link" aria-label="Direct link to The Accidental Discovery That Changed Everything" title="Direct link to The Accidental Discovery That Changed Everything">‚Äã</a></h3><p>Ashwant was debugging a frustrating session. In a moment of rage, he accidentally hit ESC four times.</p><p><strong>What happened next blew his mind.</strong></p><p>Claude Code showed him a prompt history he'd never seen before. Every conversation. Every context. <strong>Time travel for developers.</strong></p><p><strong>The magic combo:</strong> ESC + ESC + ESC + ESC = Prompt history navigation</p><p><strong>Game changer:</strong> You can resurrect any previous session state instantly.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="claude-code-as-your-database-whisperer">Claude Code as Your Database Whisperer<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#claude-code-as-your-database-whisperer" class="hash-link" aria-label="Direct link to Claude Code as Your Database Whisperer" title="Direct link to Claude Code as Your Database Whisperer">‚Äã</a></h3><p>At ShelfRadar, Ashwant deployed Claude Code as their internal SQL agent.</p><p><strong>The setup:</strong> Claude Code + database schema = autonomous query optimizer</p><p><strong>The result:</strong></p><ul>
<li>Ad-hoc queries refined automatically</li>
<li>Schema changes don't break queries</li>
<li>Claude evolves with your database</li>
</ul></div></div>
<p><strong>The question isn't whether Claude Code is teachable.</strong><br>
<strong>The question is: Are you ready to become its teacher?</strong></p>
<p>Update 1: Claude code introduced hooks. Here is a short collection of hooks that I find useful for my workflow.</p>
<ol>
<li>bash script to notify the end of claude code turns.</li>
</ol>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Full bash script ‚Üí</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Read hook input data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INPUT=$(cat)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SESSION_DIR=$(basename "$(pwd)")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Extract message from transcript if available</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TRANSCRIPT_PATH=$(echo "$INPUT" | jq -r '.transcript_path')</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ -f "$TRANSCRIPT_PATH" ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  MSG=$(tail -10 "$TRANSCRIPT_PATH" |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    jq -r 'select(.message.role == "assistant") | .message.content[0].text' |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tail -1 | tr '\n' ' ' | cut -c1-60)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  MSG=${MSG:-"Task completed"}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  MSG="Task completed"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Show Linux desktop notification (requires notify-send)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">notify-send "Claude Code ($SESSION_DIR) Done" "$MSG"</span><br></span></code></pre></div></div></div></div></div>
<div class="relative bg-blue-50 bg-opacity-30 dark:bg-blue-950 dark:bg-opacity-10 rounded-xl p-6 my-8 border-2 border-blue-200 dark:border-blue-800"><div class="flex items-center gap-3 mb-4"><div class="flex-shrink-0 w-10 h-10 bg-blue-100 dark:bg-blue-900 dark:bg-opacity-30 rounded-full flex items-center justify-center"><svg class="w-5 h-5 text-blue-600 dark:text-blue-400" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg></div><div><h3 class="text-lg font-semibold text-blue-900 dark:text-blue-100 m-0">Useful Claude Code Hooks &amp; Scripts</h3></div></div><div class="space-y-4"><div class="space-y-3"><h4 class="text-sm font-semibold text-gray-900 dark:text-gray-100 mb-2">Related Links</h4><div class="space-y-2"><div class="border-l-4 border-blue-300 dark:border-blue-700 pl-4"><a href="https://gist.github.com/glennmatlin/fadc41edc3bb9ff68ff9cfa5d6b8aca7" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200 font-medium transition-colors">Making Claude use uv instead of pip</a><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Script for making Claude use uv package manager instead of pip</p></div><div class="border-l-4 border-blue-300 dark:border-blue-700 pl-4"><a href="https://conductor.build/" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200 font-medium transition-colors">Running multiple Claude Code sessions in parallel</a><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Using git worktrees for parallel Claude Code sessions</p></div><div class="border-l-4 border-blue-300 dark:border-blue-700 pl-4"><a href="https://www.reddit.com/r/ClaudeAI/comments/1loodjn/claude_code_now_supports_hooks/" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200 font-medium transition-colors">Claude Code Hooks Discussion</a><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Reddit discussion about Claude Code hooks support</p></div></div></div></div></div>
<hr>
<p><em>This revolution moves fast. By the time you read this, someone's already teaching Claude Code to do things we haven't imagined yet.</em></p>
<p><strong>Further Reading:</strong></p>
<ul>
<li><a href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus" target="_blank" rel="noopener noreferrer">Context Engineering by Manus</a></li>
<li><a href="https://southbridge-research.notion.site/claude-code-an-agentic-cleanroom-analysis" target="_blank" rel="noopener noreferrer">Hrishi's Claude Code Analysis</a></li>
<li><a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents" target="_blank" rel="noopener noreferrer">Claude Code Sub-Agents Documentation</a></li>
<li><a href="https://docs.anthropic.com/en/docs/claude-code/hooks-guide" target="_blank" rel="noopener noreferrer">Claude Code Hooks Guide</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="are-your-developers-working-for-claude-code-or-is-claude-code-working-for-them">Are Your Developers Working FOR Claude Code? Or Is Claude Code Working FOR Them?<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#are-your-developers-working-for-claude-code-or-is-claude-code-working-for-them" class="hash-link" aria-label="Direct link to Are Your Developers Working FOR Claude Code? Or Is Claude Code Working FOR Them?" title="Direct link to Are Your Developers Working FOR Claude Code? Or Is Claude Code Working FOR Them?">‚Äã</a></h2>
<p>Right now, your engineers spend 30% of their AI time being Claude's personal assistants - explaining context, re-describing architecture, and hand-holding every request. <strong>Meanwhile, Anthropic's teams reduced research time by 80% and debug 3x faster</strong> because Claude Code works FOR them.</p>
<p><strong>The Reality Check:</strong> Your team bought the most powerful coding AI ever built, then turned themselves into its unpaid interns.</p>
<p><strong>The Transformation:</strong> Stop being Claude's employee. Make Claude Code your team's autonomous coding partner that knows your codebase better than your junior developers.</p>
<p><strong>Flip the Script: Make Claude Code Work FOR Your Team</strong></p>
<p>Transform your developers from AI babysitters into AI commanders:</p>
<ul>
<li>Setting up CLAUDE.md files that eliminate context re-explaining</li>
<li>Building verifiable workflows that turn debugging from hours to minutes</li>
<li>Token optimization strategies that double your effective usage</li>
<li>Advanced automation that makes Claude Code your team's autonomous teammate</li>
</ul>
<p><em>Read how <a href="https://www.anthropic.com/news/how-anthropic-teams-use-claude-code" target="_blank" rel="noopener noreferrer">Anthropic's teams achieve these results</a> and learn to implement the same strategies for your startup.</em></p>
<div style="text-align:center;margin:2em 0;padding:1.5em;background:linear-gradient(135deg, #667eea 0%, #764ba2 100%);border-radius:12px;box-shadow:0 8px 32px rgba(102, 126, 234, 0.3);transform:translateY(0);transition:all 0.3s ease"><a href="https://calendly.com/abhishek-vertexcover/claude-code" target="_blank" rel="noopener noreferrer" style="display:inline-block;background:white;color:#4c51bf;padding:16px 32px;border-radius:8px;text-decoration:none;font-weight:bold;font-size:1.1em;box-shadow:0 4px 16px rgba(0,0,0,0.1);transition:all 0.2s ease">Book Your 30-Minute Consultation Call</a><p style="color:white;margin:1em 0 0 0;font-size:0.95em;opacity:0.9">Transform from Claude Code user to Claude Code teacher. Your future autonomous development workflow starts with one conversation.</p></div>]]></content>
        <author>
            <name>Abhishek Tripathi</name>
            <uri>https://github.com/TwistingTwists</uri>
        </author>
        <category label="Context Engineering" term="Context Engineering"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI for End-to-End Tests (Mobile too!) with Auto Healing]]></title>
        <id>https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile</id>
        <link href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile"/>
        <updated>2025-07-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[AI for End-to-End Tests (Mobile too!)]]></summary>
        <content type="html"><![CDATA[<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-agent-for-end-to-end-testing-to-deliver-flawless-digital-experiences">AI Agent for End-to-End Testing to Deliver Flawless Digital Experiences<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#ai-agent-for-end-to-end-testing-to-deliver-flawless-digital-experiences" class="hash-link" aria-label="Direct link to AI Agent for End-to-End Testing to Deliver Flawless Digital Experiences" title="Direct link to AI Agent for End-to-End Testing to Deliver Flawless Digital Experiences">‚Äã</a></h3>
<hr>
<p>What if Ai Agent could write tests for your codebase? End-to-end? and for mobile too? and it auto heals / auto-adjusts when your codebase changes?</p>
<p>We share nuggets we learnt while building an AI Agent to solve one of the most persistent challenges in software development: making UI test automation accessible, reliable, and scalable across platforms and devices.</p>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-problem">The Problem<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#the-problem" class="hash-link" aria-label="Direct link to The Problem" title="Direct link to The Problem">‚Äã</a></h3>
<p>Test automation has historically been:</p>
<ul>
<li><strong>Too technical</strong>: requiring code expertise</li>
<li><strong>Time-consuming</strong>: for authoring and maintaining scripts</li>
<li><strong>Platform-limited</strong>: with fragmented support for web vs. mobile</li>
<li><strong>Fragile</strong>: breaking with minor UI changes or incomplete user flows</li>
</ul>
<p>Existing tools were not built for the demands of today's fast-moving, multi-platform development cycles. They struggled particularly with hybrid apps, dynamic interfaces, and gesture-driven experiences.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-solution-ai-agent">The Solution: AI Agent<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#the-solution-ai-agent" class="hash-link" aria-label="Direct link to The Solution: AI Agent" title="Direct link to The Solution: AI Agent">‚Äã</a></h3>
<p>AI agent designed from the ground up as an intelligent, prompt-driven automation system with key capabilities:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="natural-language-to-automation-code">Natural Language to Automation Code<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#natural-language-to-automation-code" class="hash-link" aria-label="Direct link to Natural Language to Automation Code" title="Direct link to Natural Language to Automation Code">‚Äã</a></h3>
<p>Users describe test scenarios in plain English. It translates them into precise, executable test scripts‚Äîincluding test data, validations, and edge cases.</p>
<p><img decoding="async" loading="lazy" alt="flow-diagram" src="https://blog.vertexcover.io/assets/images/flow-diagram-b9d7f678148f33fff9a88c8de46b1e3e.png" width="3840" height="1242" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="web--mobile-app-testing">Web &amp; Mobile App Testing<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#web--mobile-app-testing" class="hash-link" aria-label="Direct link to Web &amp; Mobile App Testing" title="Direct link to Web &amp; Mobile App Testing">‚Äã</a></h3>
<p>Supports both web (Selenium, Playwright) and mobile (Appium) frameworks, making it one of the few solutions that bridges the gap between platforms seamlessly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="multi-language-support">Multi-Language Support<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#multi-language-support" class="hash-link" aria-label="Direct link to Multi-Language Support" title="Direct link to Multi-Language Support">‚Äã</a></h3>
<p>Generates scripts in Java, Python, JavaScript, and other frameworks‚Äîtailored to the team's existing tech stack.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="smart-debugging">Smart Debugging<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#smart-debugging" class="hash-link" aria-label="Direct link to Smart Debugging" title="Direct link to Smart Debugging">‚Äã</a></h3>
<p>Executes each script line in real-time as it's generated, identifying and correcting issues on the fly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cross-device-execution">Cross-Device Execution<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#cross-device-execution" class="hash-link" aria-label="Direct link to Cross-Device Execution" title="Direct link to Cross-Device Execution">‚Äã</a></h3>
<p>Run tests instantly across 5,000+ combinations of real browsers and devices (when connected to cloud infrastructure).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="self-healing-automation">Self-Healing Automation<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#self-healing-automation" class="hash-link" aria-label="Direct link to Self-Healing Automation" title="Direct link to Self-Healing Automation">‚Äã</a></h3>
<p>Detects and updates selectors and steps automatically as the application evolves, eliminating the need for manual maintenance.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="core-technical-challenges-solved">Core Technical Challenges Solved<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#core-technical-challenges-solved" class="hash-link" aria-label="Direct link to Core Technical Challenges Solved" title="Direct link to Core Technical Challenges Solved">‚Äã</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ui-automation-for-flutter-web-and-hybrid-mobile-apps">UI Automation for Flutter Web and Hybrid Mobile Apps<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#ui-automation-for-flutter-web-and-hybrid-mobile-apps" class="hash-link" aria-label="Direct link to UI Automation for Flutter Web and Hybrid Mobile Apps" title="Direct link to UI Automation for Flutter Web and Hybrid Mobile Apps">‚Äã</a></h3>
<p>Most automation tools break down on platforms like Flutter Web, where the UI is rendered inside a <code>&lt;canvas&gt;</code> instead of standard HTML elements, and on hybrid apps without accessible DOM trees.</p>
<p><strong>Our agent solved this by enabling interaction with non-standard UIs using a combination of visual, contextual, and heuristic techniques</strong>‚Äîdelivering true end-to-end automation where no other solution worked.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="accurate-and-reusable-script-generation">Accurate and Reusable Script Generation<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#accurate-and-reusable-script-generation" class="hash-link" aria-label="Direct link to Accurate and Reusable Script Generation" title="Direct link to Accurate and Reusable Script Generation">‚Äã</a></h3>
<p>Running LLMs for every test execution is expensive and error-prone.</p>
<p>This AI Agent implemented a <strong>novel templating and generation system</strong> that decouples script generation from execution. This allowed:</p>
<ul>
<li>Complete and correct scripts on the first pass</li>
<li>Reusability across test runs and frameworks</li>
<li>Fast, low-cost, scalable test creation</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="complex-gestures-and-ui-behaviors">Complex Gestures and UI Behaviors<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#complex-gestures-and-ui-behaviors" class="hash-link" aria-label="Direct link to Complex Gestures and UI Behaviors" title="Direct link to Complex Gestures and UI Behaviors">‚Äã</a></h3>
<p>Simulating gestures like pinch, zoom, drag-and-drop, or multi-touch is notoriously hard‚Äîespecially in custom components.</p>
<p>This agent provided <strong>fine-grained control</strong> over gesture simulation, going beyond the abstractions of typical libraries, enabling accurate testing of sliders, carousels, maps, and more.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mapping-natural-language-to-ui-actions-reliably">Mapping Natural Language to UI Actions Reliably<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#mapping-natural-language-to-ui-actions-reliably" class="hash-link" aria-label="Direct link to Mapping Natural Language to UI Actions Reliably" title="Direct link to Mapping Natural Language to UI Actions Reliably">‚Äã</a></h3>
<p>Natural language like ‚ÄúClick the Pay button‚Äù can be ambiguous‚Äîespecially in large, dynamic UIs.</p>
<p><strong>Being very smart, it combined multiple modalities‚ÄîDOM structure, visual layout, and semantic cues</strong>‚Äîto reliably identify elements even when conventional locators failed. This enabled it to handle vague prompts and incomplete context with high precision.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="stability-in-dynamic--incomplete-user-flows">Stability in Dynamic &amp; Incomplete User Flows<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#stability-in-dynamic--incomplete-user-flows" class="hash-link" aria-label="Direct link to Stability in Dynamic &amp; Incomplete User Flows" title="Direct link to Stability in Dynamic &amp; Incomplete User Flows">‚Äã</a></h3>
<p>In real-world apps, pop-ups appear unexpectedly, elements load asynchronously, and flows can be interrupted.</p>
<p>It was was designed to <strong>recover intelligently</strong> from such cases using retry logic, timeout strategies, and partial flow handling. This brought production-grade resilience to end-to-end test execution.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scalable-evaluation--debugging-infrastructure">Scalable Evaluation &amp; Debugging Infrastructure<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#scalable-evaluation--debugging-infrastructure" class="hash-link" aria-label="Direct link to Scalable Evaluation &amp; Debugging Infrastructure" title="Direct link to Scalable Evaluation &amp; Debugging Infrastructure">‚Äã</a></h3>
<p>A major limitation of LLM-based systems is the lack of robust evaluation.</p>
<p>AI Agent addressed this by building a <strong>custom evaluation framework</strong> that:</p>
<ul>
<li>Validated script correctness at each step</li>
<li>Enabled partial re-execution of scripts</li>
<li>Provided fine-grained feedback for model improvement</li>
</ul>
<p>This drastically accelerated iteration speed and allowed for deeper validation of system accuracy.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">‚Äã</a></h3>
<p>AI Agent redefines what's possible in test automation. By combining the reasoning power of LLMs with robust engineering for execution, gesture control, and UI resilience, it makes test automation accessible to non-engineers while retaining power for experts.</p>
<p>From tackling the hardest UI platforms like Flutter Web to enabling precise, reusable test generation and execution at scale, our custom AI agent is a leap forward in the world of quality engineering.</p>
<p>It's not just a tool‚Äîit's a full-stack AI agent that understands, adapts, and evolves with your application.</p>]]></content>
        <category label="AI Agents" term="AI Agents"/>
        <category label="End-to-End Test" term="End-to-End Test"/>
    </entry>
</feed>