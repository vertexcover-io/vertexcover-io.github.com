---
slug: "strot-is-a-api-scraper"
title: "Strot - The API Scraper"
date: 2025-07-28T00:00:00+00:00
draft: false 
---

import ComparisonTable from '../src/components/ComparisonTable';
import NumberedList from '../src/components/NumberedList';
import TLDR from '../src/components/TLDR';
import HierarchySection from '../src/components/HierarchySection';
import SubSection from '../src/components/SubSection';
import DeepDive from '../src/components/DeepDive';
import TechnicalCard from '../src/components/TechnicalCard';
import YouTubeEmbed from '../src/components/YouTubeEmbed';


<TLDR>
Strot (Sanskrit meaning source) is an AI agent which scrapes web api:

<NumberedList items={[
  "Instead of scraping the dom, identifies the right api call.",
  "Fast, reliable, complete data scraping for listing data is possible via API scraping. ",
  "Strot figures the api call so you don't have to."
]} />
</TLDR>

[Try out Strot!](https://github.com/vertexcover-io/strot)

{/* truncate */}


<YouTubeEmbed videoId="OCL3rWG9mDs" title="Strot - The API Scraper Demo" />

## What if ... ?

When working with clients, we figured that they frequently need to scrape listing data like reviews and product listings. The DOM Scraping solutions don't give complete data.

When is comes to scraping reviews, things CAN BE slightly different than running playwright scripts. That's the idea we started with! 

It stems from the insights on browsing shopify. Since, shopify has plugin ecosystem, a lot of reviews come from plugins. They give the reviews in html / json form via api that the page renders. 
Since, reviews - if they are worthwhile - would be in 100s for a given product, it would be very unlikely that someone with good web-dev practices will send all of them on one shot. There MUST be a second call (pagination) that requests for further reviews for the given product. 

What if ... we could scrape listing data via intercepting AJAX calls that are made from the browser itself? 


## The Genesis 

Hence, an experiment is born - called `strot`. In sanskrit it means source. We are trying to get to the ajax calls that gets us listing data. 

The review scraping problem sits at a unique position. There are always MANY reviews which either causes cost ballooning no matter which existing approach you take.

Strot is the only project which can scrape the data available as api call - at all - using natural language.


<ComparisonTable 
  data={[
    {
      feature: 'Cost',
      playwright: { text: 'Infrastructure costs for automation', score: 'medium' },
      llmScraper: { text: 'Pay per page + LLM inference', score: 'poor' },
      strot: { text: 'One-time API discovery', score: 'good' }
    },
    {
      feature: 'Maintenance',
      playwright: { text: 'High - UI changes break scripts', score: 'poor' },
      llmScraper: { text: 'Medium - prompt engineering needed', score: 'medium' },
      strot: { text: 'Low - APIs rarely change', score: 'good' }
    },
    {
      feature: 'Intelligence Required',
      playwright: { text: 'High - manual scraper', score: 'poor' },
      llmScraper: { text: 'High - per page analysis', score: 'poor' },
      strot: { text: 'One-time - for API discovery', score: 'medium' }
    },
    {
      feature: 'Scalability',
      playwright: { text: 'Poor - loads full pages', score: 'poor' },
      llmScraper: { text: 'Expensive - each page costs $', score: 'poor' },
      strot: { text: 'Excellent - pagination via API', score: 'good' }
    },
    {
      feature: 'Setup Complexity',
      playwright: { text: 'Medium - browser automation', score: 'medium' },
      llmScraper: { text: 'Low - plug and play', score: 'good' },
      strot: { text: 'Low - plug and play', score: 'good' }
    },
    {
      feature: 'Uniqueness',
      playwright: { text: 'Common approach', score: 'poor' },
      llmScraper: { text: 'Common approach', score: 'poor' },
      strot: { text: 'Unique to us', score: 'good' }
    }
  ]}
  columns={['playwright', 'llmScraper', 'strot']}
  columnHeaders={['Playwright', 'LLM Scraper', 'Strot (Ours)']}
/>

So, IF we could find the ajax call → we only have to spend time figuring out the API call. and voila! You can simply call API - this is cheapest, fastest, most reliable approach of all. 

And the unique to us. Hence, we took a bite. 

But the challenge is which api call is most relevnt for scraping reviews ? 
we solve this by capturing screenshot, visually analysing if review is preseng in the screenshot. Then we find a matching ajax call that has a similar content. Voila! 


## The challenges of current approaches 

Each traditional approach faces fundamental limitations that compound at scale:

<TechnicalCard type="edge-case" title="The Listing Data has Volume Problem">

Most products with worthwhile reviews have 100-10,000+ reviews. Traditional approaches cost:

- **Playwright**: 100 reviews × 3 pages × 10s load time = 30+ minutes
- **LLM Scraper**: 100 reviews × $0.10 per page = $10+ per product
- **Manual API**: 100 reviews × 15min engineer time = $200+ per product

Strot's approach: 100 reviews × 0.1s API call = 10 seconds total.

</TechnicalCard>


# Technical Details 


<DeepDive title="System Architecture & Technical Approach">

Strot's architecture consists of three main components working in sequence:

**1. HAR File Analysis Pipeline**
- Captures network traffic using browser automation (Playwright/Puppeteer)
- Filters AJAX/XHR requests that match review-related patterns
- Builds a candidates list of potential review API endpoints

**2. Visual-Content Correlation Engine**
- Takes screenshot of the page showing reviews
- Uses vision models (Claude-4-sonnet) to extract review text from screenshots
- Performs fuzzy matching between screenshot content and API response data

**3. Pagination Strategy Detection**
- Analyzes request parameters to identify pagination patterns
- Common patterns: `page`, `offset`, `cursor`, `after`, `next_token`
- Reverse engineers pagination logic from multiple API calls

</DeepDive>

<TechnicalCard type="architecture" title="Why AJAX Interception vs DOM Scraping">

Traditional DOM scraping faces several fundamental limitations:

- **Rate Limiting**: Websites throttle based on page loads, not API calls
- **Bot Detection**: Full page loads trigger anti-bot measures (Cloudflare, etc.)
- **Resource Overhead**: Loading entire DOM + assets vs lightweight JSON responses
- **Maintenance Burden**: CSS selectors break with UI changes, APIs rarely change

AJAX interception bypasses these by operating at the data layer, not presentation layer.

</TechnicalCard> 

<TechnicalCard type="implementation" title="AJAX Call Matching Algorithm">

Our matching algorithm works in stages:

1. **Content Extraction**: Extract review text from screenshots using OCR + Vision LLM
2. **API Response Analysis**: Parse all captured AJAX responses for text content
3. **Fuzzy String Matching**: Use algorithms like Levenshtein distance, Jaccard similarity
4. **Confidence Scoring**: 
   - Text overlap ratio (>90% = high confidence)
   - JSON structure analysis (nested objects, review-like fields)
   - Response size correlation with visible review count

**Edge Case Handling**: 
- Paginated responses (partial matches expected)
- Localized content (different languages)
- Dynamic timestamps/IDs (filter out volatile fields)

</TechnicalCard>

<TechnicalCard type="performance" title="Why Screenshot Analysis vs Pure Network Analysis">

Since we have to do the hard part of finding the right AJAX call ONLY once, it means that we can use augmentation from vision understanding to make it more accurate. 

This helps by:
- Confirms which API calls actually render user-visible content. 
- Handles cases where multiple API calls contain review data
- Eliminates false positives from internal/admin API calls

</TechnicalCard>


### The codegen 

We internally represent all the relevant information as json. This helps us to generate http client in any language of choice. Calling this API endpoint in succession will give all the reviews.

<DeepDive title="Code Generation Pipeline & Implementation">

Our codegen system transforms discovered API patterns into production-ready code:

**1. API Pattern Extraction**
```json
{
  "endpoint": "https://example.com/api/reviews",
  "method": "POST",
  "headers": {
    "content-type": "application/json",
    "x-requested-with": "XMLHttpRequest"
  },
  "pagination": {
    "type": "offset",
    "param": "offset",
    "limit_param": "limit",
    "max_per_request": 20
  }
}
```

**2. Language-Specific Generation**
- **Python**: Uses `requests`. Can use `rnet` if want to bypass TLS fingerprinting.
- **Node.js**: `axios` with async/await patterns
- **cURL**: Direct shell commands with proper escaping

</DeepDive>

<HierarchySection title="Iteratively Improving via Error Analysis and Evals">

Evals were central to us while building this. We had three tiered system for evals that served us well.

<NumberedList items={[
  "Does the analysis identify the right ajax call?",
  "Is the pagination strategy detection done correctly?",
  "Is the http api (codegen) able to get all the reviews?"
]} />

<DeepDive title="Comprehensive Evaluation System Architecture">

Our evaluation system operates at three levels with automated scoring:

**Level 1: AJAX Call Detection**
- **Ground Truth**: Manual verification of correct API endpoints (part of **golden dataset** for evals)
- **Automated Checks**:
  - Response contains review-like JSON structure (text, rating, author)
  - Content overlap with screenshot text >85%

**Level 2: Pagination Strategy**
- **Test Suite**: Tested pagination patterns (cursor, limit, offset) across major e-commerce sites
- **Validation Logic**:
  - Do we hit natural boundaries (page N returns empty/error)?

**Level 3: End-to-End Codegen**
- **Integration Tests**: Generated code fetches reviews from 10 test products
- **Quality Metrics**:
  - Duplicate detection (same review across pages)
  - Data completeness (rating, text, date, author)

</DeepDive>

<SubSection title="Error Analysis">

This was the most consuming element for us until we vibe-coded initial version of this dashboard to see the logs as data.

<TechnicalCard type="implementation" title="Observability Dashboard">

Our observability dashboard processes shows data from:


<NumberedList items={[
  "Application logs (structured JSON)",
  "LLM API call traces (OpenAI/Anthropic)",
  "Playwright screenshots"
]} />


This helps to do the error analysis and improve the system iteratively.
</TechnicalCard>

Here is a quick peek over the dashboard we made to do the error analysis:

This shows us the cost and token usage:
<a href="/img/strot-dashboard-analysis.png" target="_blank" rel="noopener noreferrer">
  <img src="/img/strot-dashboard-analysis.png" alt="Strot dashboard cost and token analysis" style={{cursor: 'pointer'}} />
</a>

This shows us the step by step observability into what is happening:
<a href="/img/strot-dashboard-step.png" target="_blank" rel="noopener noreferrer">
  <img src="/img/strot-dashboard-step.png" alt="Strot dashboard step by step analysis" style={{cursor: 'pointer'}} />
</a>


</SubSection>

<SubSection title="Pagination">

<a href="/img/strot-dashboard-pagination.png" target="_blank" rel="noopener noreferrer">
  <img src="/img/strot-dashboard-pagination.png" alt="Strot dashboard pagination" style={{cursor: 'pointer'}} />
</a>

</SubSection>
 
<SubSection title="Codegen">

<a href="/img/strot-dashboard-codegen.png" target="_blank" rel="noopener noreferrer">
  <img src="/img/strot-dashboard-codegen.png" alt="Strot dashboard codegen" style={{cursor: 'pointer'}} />
</a>

</SubSection>

</HierarchySection>


We are also learning. This was our attempt at scraping the webpage and using the visual understanding of image models to get to the reviews faster. if you feel this can be improved, feel free to share those with us on [github-issues](https://github.com/vertexcover-io/strot/issues).


## Roadmap 

<NumberedList items={[
  "We are already on a path to make this a generic scraper. Currently, our evals sets show the tracking progress on various websites. It will be released soon.",
  "if you would like us to host this as a service for you, we are more than happy to. Come chat with us at [contact email]"
]} />
