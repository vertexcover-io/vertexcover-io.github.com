<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">Video Rendering Pipeline for an AI-Driven Text-to-Video Platform | Blog - Vertexcover</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://blog.vertexcover.io/img/vertexcover.png"><meta data-rh="true" name="twitter:image" content="https://blog.vertexcover.io/img/vertexcover.png"><meta data-rh="true" property="og:url" content="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Video Rendering Pipeline for an AI-Driven Text-to-Video Platform | Blog - Vertexcover"><meta data-rh="true" name="description" content="Video Rendering Pipeline for an AI-Driven Text-to-Video Platform"><meta data-rh="true" property="og:description" content="Video Rendering Pipeline for an AI-Driven Text-to-Video Platform"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-08-06T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Infrastructure"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform"><link data-rh="true" rel="alternate" href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform" hreflang="en"><link data-rh="true" rel="alternate" href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform","mainEntityOfPage":"https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform","url":"https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform","headline":"Video Rendering Pipeline for an AI-Driven Text-to-Video Platform","name":"Video Rendering Pipeline for an AI-Driven Text-to-Video Platform","description":"Video Rendering Pipeline for an AI-Driven Text-to-Video Platform","datePublished":"2025-08-06T00:00:00.000Z","author":[],"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://blog.vertexcover.io/","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Blog - Vertexcover RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Blog - Vertexcover Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JS91KNQLR"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0JS91KNQLR",{})</script>




<link rel="alternate" type="application/rss+xml" href="/learnings/rss.xml" title="Blog - Vertexcover RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/learnings/atom.xml" title="Blog - Vertexcover Atom Feed">
<meta name="generator" content="vertex cover"><link rel="stylesheet" href="/assets/css/styles.9909b52a.css">
<script src="/assets/js/runtime~main.7cc124f9.js" defer="defer"></script>
<script src="/assets/js/main.351d6c55.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Vertexcover Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Vertexcover Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Vertexcover</b></a><a class="navbar__item navbar__link" href="/">Blog</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a class="navbar__item navbar__link" href="/learnings">Learnings</a><a class="navbar__item navbar__link" href="/about-us">About Us</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/vertexcover-io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/why-nodejs-python-avoid-linux-aio">Why Node.js and Python Don&#x27;t Use Linux&#x27;s Native Async I/O API</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/linkedin-scraper-mcp-integration">Building a LinkedIn Scraper (and Turning It Into an MCP Integration)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/strot-ai-observability-evaluation-system">How We Do Evals &amp; Observability for Agentic Systems</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/speed-up-docker-builds-on-github-actions">Speed up Docker Builds on Github actions</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform">Video Rendering Pipeline for an AI-Driven Text-to-Video Platform</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/ml-infra-for-the-gpu-poor">ML Infra design for the GPU Poor</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/strot-is-a-api-scraper">Strot - The API Scraper</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/claude-code-context-engineering-v2">Teaching Claude Code to Work Independently</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/ai-agent-end-to-end-automated-tests-mobile">AI for End-to-End Tests (Mobile too!) with Auto Healing</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">Video Rendering Pipeline for an AI-Driven Text-to-Video Platform</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-08-06T00:00:00.000Z">August 6, 2025</time> · <!-- -->5 min read</div></header><div id="__blog-post-container" class="markdown"><p>Replacing dual React-ffmpeg architecture with unified browser-based solution, achieving 100,000 daily video renders with consistent preview-output matching and halved development effort.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="context">Context<a href="#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context" translate="no">​</a></h2>
<p>A leading AI company offers a cloud-based video editor, its core product, enabling users to effortlessly convert text into video with human avatars. The editor supports a wide range of features, from backgrounds, media integration, and text overlays to animations, transitions, fonts, styling, and scene management.</p>
<p>Video generation operates as a pipeline: users begin by crafting a video using the browser-based tool, previewing their creation in real-time. Once satisfied, the video undergoes a render pipeline that culminates in the production of a full HD video, ensuring the final output mirrors the preview&#x27;s fidelity. At its foundation, the frontend editor employs React, while the backend relies on a custom ffmpeg video renderer.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="problem">Problem<a href="#problem" class="hash-link" aria-label="Direct link to Problem" title="Direct link to Problem" translate="no">​</a></h2>
<p>The company&#x27;s video editor relied on a dual system: a React-based preview in the browser and an ffmpeg-driven backend for final video rendering. This architecture presented multiple challenges:</p>
<ul>
<li>
<p><strong>Complexity of ffmpeg</strong>: Using ffmpeg programmatically proved intricate due to its inherent complexities.</p>
</li>
<li>
<p><strong>Mismatch Between Preview and Final Render</strong>: The separation of technologies (React for preview and ffmpeg for rendering) occasionally led to inconsistencies between the video preview and the final output.</p>
</li>
<li>
<p><strong>Duplication of Effort</strong>: Introducing any new feature demanded double the effort: once for the preview in React and once more for the final render using ffmpeg. Moreover, ensuring consistency between these two stages added to the workload.</p>
</li>
<li>
<p><strong>Limitations with ffmpeg</strong>: The use of ffmpeg imposed constraints on integrating advanced video editing features.</p>
</li>
</ul>
<p>Furthermore, the ideal solution needed to meet specific criteria:</p>
<ul>
<li>Video generation time should align with the video&#x27;s actual duration.</li>
<li>The cost of rendering should not exceed 1Rs per minute of video.</li>
<li>The solution should be feasible for relatively swift development and integration.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-and-solution">Challenges and Solution<a href="#challenges-and-solution" class="hash-link" aria-label="Direct link to Challenges and Solution" title="Direct link to Challenges and Solution" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-browser-based-solutions">Evaluating Browser-Based Solutions<a href="#evaluating-browser-based-solutions" class="hash-link" aria-label="Direct link to Evaluating Browser-Based Solutions" title="Direct link to Evaluating Browser-Based Solutions" translate="no">​</a></h3>
<p>Drawing from my prior experience with video rendering pipelines, it was evident that a browser-centric solution could address our functional requirements. However, constraints related to cost and development time necessitated further exploration.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="library-exploration-for-time-efficiency">Library Exploration for Time-Efficiency<a href="#library-exploration-for-time-efficiency" class="hash-link" aria-label="Direct link to Library Exploration for Time-Efficiency" title="Direct link to Library Exploration for Time-Efficiency" translate="no">​</a></h3>
<p>An open-source library promising the conversion of React components to video emerged as a viable solution for rapid deployment. Preliminary experiments ensured its compatibility with our feature set. An in-depth examination of the library&#x27;s source code was undertaken to gauge its maintainability, ease of potential forking, and readiness for production scenarios. Direct discussions with the library&#x27;s author and the wider community bolstered our confidence in its capabilities.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarking-library-performance-on-lambda">Benchmarking Library Performance on Lambda<a href="#benchmarking-library-performance-on-lambda" class="hash-link" aria-label="Direct link to Benchmarking Library Performance on Lambda" title="Direct link to Benchmarking Library Performance on Lambda" translate="no">​</a></h3>
<p>The library was designed to operate on AWS Lambda. A series of benchmarks provided insights into its performance metrics, both in terms of rendering time and cost implications.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cost-and-timing-optimization-with-prototype-benchmarking">Cost and Timing Optimization with Prototype Benchmarking<a href="#cost-and-timing-optimization-with-prototype-benchmarking" class="hash-link" aria-label="Direct link to Cost and Timing Optimization with Prototype Benchmarking" title="Direct link to Cost and Timing Optimization with Prototype Benchmarking" translate="no">​</a></h3>
<p>While the library met our immediate requirements, it presented cost-related challenges for the future, inherently rendering at a rate of 1fps. Recognizing this, I built a simplified clone of the open-source library to conduct focused benchmarking. The tests indicated that by leveraging the library&#x27;s approach, we could achieve up to 4 FPS. The primary limitation was identified as the screenshot capture time, which took approximately 200ms per frame. This understanding offered clarity on the potential to optimize and align with the company&#x27;s future cost and performance goals.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="addressing-the-vp8-format-bottleneck">Addressing the VP8 Format Bottleneck<a href="#addressing-the-vp8-format-bottleneck" class="hash-link" aria-label="Direct link to Addressing the VP8 Format Bottleneck" title="Direct link to Addressing the VP8 Format Bottleneck" translate="no">​</a></h3>
<p>The human avatar component of our rendering pipeline employed the VP8 video format for transparency support. While the chosen open-source platform accommodated VP8, it did so with suboptimal speeds. After experimenting with ffmpeg&#x27;s WebAssembly version to disintegrate the video into frame sequences, we decided to restructure the text-to-video stage. Instead of producing videos, it was reconfigured to generate images directly, yielding twin advantages in performance and cost.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-ffmpeg-integration">Custom ffmpeg Integration<a href="#custom-ffmpeg-integration" class="hash-link" aria-label="Direct link to Custom ffmpeg Integration" title="Direct link to Custom ffmpeg Integration" translate="no">​</a></h3>
<p>Our use case demanded specific ffmpeg flags and a customized ffmpeg version – elements not supported natively by the library. To bridge this gap, I employed pnpm patching and automated the building of a custom ffmpeg version from its source.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-reusability-for-consistency">Code Reusability for Consistency<a href="#code-reusability-for-consistency" class="hash-link" aria-label="Direct link to Code Reusability for Consistency" title="Direct link to Code Reusability for Consistency" translate="no">​</a></h3>
<p>A design approach was adopted where the developed code functioned as a reusable library. This allowed its integration into both the frontend for previews and the backend for final video rendering, ensuring uniformity across stages.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="animation-and-transition-integration">Animation and Transition Integration<a href="#animation-and-transition-integration" class="hash-link" aria-label="Direct link to Animation and Transition Integration" title="Direct link to Animation and Transition Integration" translate="no">​</a></h3>
<p>The final development phase involved the addition of animation and scene transition capabilities to the platform.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="impact">Impact<a href="#impact" class="hash-link" aria-label="Direct link to Impact" title="Direct link to Impact" translate="no">​</a></h2>
<ul>
<li>
<p><strong>Stable Production Implementation</strong>: The solution has been integrated into production and operates with minimal disruptions. It is written in 100% typescript with ~90% test coverage.</p>
</li>
<li>
<p><strong>Consistent Previews and Renders</strong>: The disparity between previews and final video renders, previously a pain point, has been eradicated, ensuring consistent user expectations.</p>
</li>
<li>
<p><strong>Swift Feature Integration</strong>: The new system facilitated the rapid introduction of enhancements like custom fonts, animations, and scene transitions, effectively halving the time and effort previously required for such additions.</p>
</li>
<li>
<p><strong>Seamless Scaling</strong>: With the implemented improvements, the platform now comfortably handles the rendering of up to 100,000 videos daily without necessitating additional adjustments or overhead.</p>
</li>
</ul></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" title="Infrastructure" class="tag_zVej tagRegular_sFm0" href="/tags/infra">Infrastructure</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/speed-up-docker-builds-on-github-actions"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Speed up Docker Builds on Github actions</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ml-infra-for-the-gpu-poor"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">ML Infra design for the GPU Poor</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#context" class="table-of-contents__link toc-highlight">Context</a></li><li><a href="#problem" class="table-of-contents__link toc-highlight">Problem</a></li><li><a href="#challenges-and-solution" class="table-of-contents__link toc-highlight">Challenges and Solution</a><ul><li><a href="#evaluating-browser-based-solutions" class="table-of-contents__link toc-highlight">Evaluating Browser-Based Solutions</a></li><li><a href="#library-exploration-for-time-efficiency" class="table-of-contents__link toc-highlight">Library Exploration for Time-Efficiency</a></li><li><a href="#benchmarking-library-performance-on-lambda" class="table-of-contents__link toc-highlight">Benchmarking Library Performance on Lambda</a></li><li><a href="#cost-and-timing-optimization-with-prototype-benchmarking" class="table-of-contents__link toc-highlight">Cost and Timing Optimization with Prototype Benchmarking</a></li><li><a href="#addressing-the-vp8-format-bottleneck" class="table-of-contents__link toc-highlight">Addressing the VP8 Format Bottleneck</a></li><li><a href="#custom-ffmpeg-integration" class="table-of-contents__link toc-highlight">Custom ffmpeg Integration</a></li><li><a href="#code-reusability-for-consistency" class="table-of-contents__link toc-highlight">Code Reusability for Consistency</a></li><li><a href="#animation-and-transition-integration" class="table-of-contents__link toc-highlight">Animation and Transition Integration</a></li></ul></li><li><a href="#impact" class="table-of-contents__link toc-highlight">Impact</a></li></ul></div></div></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/vertexcover-io" target="_blank" rel="noopener noreferrer" class="footer__link-item footer-github-link" aria-label="GitHub repository">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Codeshelf, Inc.</div></div></div></footer></div>
</body>
</html>