<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.vertexcover.io/learnings</id>
    <title>Blog - Vertexcover Blog</title>
    <updated>2025-10-22T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.vertexcover.io/learnings"/>
    <subtitle>Blog - Vertexcover Blog</subtitle>
    <icon>https://blog.vertexcover.io/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Weekly learnings: Week2]]></title>
        <id>https://blog.vertexcover.io/learnings/2025-10-ranjan-week2</id>
        <link href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2"/>
        <updated>2025-10-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Developed a comprehensive benchmarking framework for comparing container image formats (regular vs eStargz) for large LLM workloads using containerd and stargz-snapshotter.]]></summary>
        <content type="html"><![CDATA[<p>Developed a comprehensive benchmarking framework for comparing container image formats (regular vs eStargz) for large LLM workloads using containerd and stargz-snapshotter.</p>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-findings">Key Findings<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#key-findings" class="hash-link" aria-label="Direct link to Key Findings" title="Direct link to Key Findings" translate="no">​</a></h3>
<p><strong>Lazy pulling with eStargz provides dramatic startup improvements:</strong></p>
<ul>
<li><strong>150x faster pull times</strong> (9.2s → 0.06s)</li>
<li><strong>13.9x faster cold starts</strong> (9.4s → 0.67s)</li>
<li><strong>Zero disk storage overhead</strong></li>
</ul>
<p><strong>But reveals a critical trade-off for data-intensive workloads:</strong></p>
<ul>
<li><strong>1.5-2x slower total completion</strong> when accessing &gt;30% of image data</li>
<li>Stress test (8GB sequential read): Overlayfs 45-54s vs Stargz 79-88s</li>
<li><strong>Working set size determines which approach is faster</strong></li>
</ul>
<p><strong>Bottom line:</strong> Lazy pulling optimizes for startup latency (ideal for inference/serving), while eager loading optimizes for total completion time (better for training/batch processing).</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-results">Key Results<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#key-results" class="hash-link" aria-label="Direct link to Key Results" title="Direct link to Key Results" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cold-start-performance-small-working-set---2gb-image">Cold Start Performance (Small Working Set - 2GB Image)<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#cold-start-performance-small-working-set---2gb-image" class="hash-link" aria-label="Direct link to Cold Start Performance (Small Working Set - 2GB Image)" title="Direct link to Cold Start Performance (Small Working Set - 2GB Image)" translate="no">​</a></h3>
<table><thead><tr><th>Metric</th><th>Regular Pull</th><th>Lazy Pull (eStargz)</th><th>Improvement</th></tr></thead><tbody><tr><td><strong>Pull time</strong></td><td>9.178s</td><td>0.061s</td><td><strong>150x faster</strong></td></tr><tr><td><strong>Container start + ready</strong></td><td>199ms</td><td>587ms</td><td>Slower (on-demand fetch)</td></tr><tr><td><strong>Total cold start</strong></td><td>9.401s</td><td>0.675s</td><td><strong>13.9x faster</strong></td></tr><tr><td><strong>Data downloaded at pull</strong></td><td>2.0 GB</td><td>~9 KB</td><td><strong>99.9% reduction</strong></td></tr><tr><td><strong>Disk usage after pull</strong></td><td>2.0 GB cached</td><td>0 bytes</td><td><strong>100% savings</strong></td></tr></tbody></table>
<p><strong>Scenario</strong>: Application with small working set (~1-5% of image accessed)</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="total-workload-completion-large-working-set---8gb-image-️">Total Workload Completion (Large Working Set - 8GB Image) ⚠️<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#total-workload-completion-large-working-set---8gb-image-%EF%B8%8F" class="hash-link" aria-label="Direct link to Total Workload Completion (Large Working Set - 8GB Image) ⚠️" title="Direct link to Total Workload Completion (Large Working Set - 8GB Image) ⚠️" translate="no">​</a></h3>
<p><strong>CRITICAL TRADE-OFF</strong>: When workloads access significant portions of the image, lazy pulling is <strong>SLOWER</strong> for total completion time.</p>
<p><strong>Stress Test Results</strong> (sequential read of 8GB data):</p>
<table><thead><tr><th>Mode</th><th>Registry</th><th>File Pattern</th><th>Total Time</th><th>vs Overlayfs</th></tr></thead><tbody><tr><td><strong>Overlayfs</strong></td><td>localhost</td><td>many-small</td><td>52s</td><td>baseline</td></tr><tr><td><strong>Overlayfs</strong></td><td>localhost</td><td>few-large</td><td>54s</td><td>baseline</td></tr><tr><td><strong>Overlayfs</strong></td><td>172.17.0.2</td><td>many-small</td><td>45s</td><td>baseline</td></tr><tr><td><strong>Overlayfs</strong></td><td>172.17.0.2</td><td>few-large</td><td>45s</td><td>baseline</td></tr><tr><td><strong>Stargz</strong></td><td>localhost</td><td>many-small</td><td><strong>88s</strong></td><td><strong>1.7x slower</strong> ❌</td></tr><tr><td><strong>Stargz</strong></td><td>localhost</td><td>few-large</td><td><strong>79s</strong></td><td><strong>1.5x slower</strong> ❌</td></tr><tr><td><strong>Stargz</strong></td><td>172.17.0.2</td><td>many-small</td><td><strong>82s</strong></td><td><strong>1.8x slower</strong> ❌</td></tr><tr><td><strong>Stargz</strong></td><td>172.17.0.2</td><td>few-large</td><td><strong>83s</strong></td><td><strong>1.8x slower</strong> ❌</td></tr></tbody></table>
<p><strong>Why Lazy Pulling is Slower for Data-Intensive Workloads:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Overlayfs (eager loading):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Bulk download: 45-53s (parallel, full bandwidth)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Workload execution: Fast (all data local on SSD)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ────────────────────────────────────</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Total: 45-54s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Stargz (lazy loading):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Metadata pull: &amp;lt;1s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Workload execution: 78-87s (many serialized HTTP range requests)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ────────────────────────────────────</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Total: 79-88s (1.5-2x SLOWER!)</span><br></span></code></pre></div></div>
<p><strong>Performance Breakdown:</strong></p>
<ul>
<li><strong>Pull phase</strong>: Stargz wins (150x faster) ✅</li>
<li><strong>Execution phase</strong>: Overlayfs wins (on-demand HTTP requests slower than local disk) ✅</li>
<li><strong>Total time</strong>: Depends on working set size and access pattern</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-insights">Key Insights<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#key-insights" class="hash-link" aria-label="Direct link to Key Insights" title="Direct link to Key Insights" translate="no">​</a></h3>
<ol>
<li>
<p><strong>Cold start time ≠ Total completion time</strong></p>
<ul>
<li>Lazy pulling optimizes startup latency</li>
<li>BUT penalizes total workload completion when data access is substantial</li>
</ul>
</li>
<li>
<p><strong>Working set size is critical</strong></p>
<ul>
<li>Small working set (&lt;10%): Lazy pulling wins dramatically (13.9x faster)</li>
<li>Large working set (&gt;30%): Eager loading wins (1.5-2x faster)</li>
</ul>
</li>
<li>
<p><strong>File pattern sensitivity</strong></p>
<ul>
<li>Many small files: Worse for lazy pulling (88s vs 79s)</li>
<li>Each file = separate HTTP request = more latency overhead</li>
</ul>
</li>
<li>
<p><strong>Network vs disk I/O trade-off</strong></p>
<ul>
<li>Bulk parallel download: ~45-53s for 8GB</li>
<li>Serialized on-demand fetches: ~78-87s for same data</li>
<li>Local disk reads &gt;&gt; HTTP range requests for large data access</li>
</ul>
</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="technical-architecture">Technical Architecture<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#technical-architecture" class="hash-link" aria-label="Direct link to Technical Architecture" title="Direct link to Technical Architecture" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="core-components">Core Components<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#core-components" class="hash-link" aria-label="Direct link to Core Components" title="Direct link to Core Components" translate="no">​</a></h3>
<ol>
<li>
<p><strong>Containerd Benchmark Framework</strong> (<code>containerd-bench/</code>)</p>
<ul>
<li>Pure Go API integration with containerd</li>
<li>Programmatic control over container lifecycle</li>
<li>JSON Lines logging for performance analysis</li>
<li>Operations: PullImage, RPullImage (lazy), CreateContainer, StartContainer, etc.</li>
</ul>
</li>
<li>
<p><strong>Lazy Pulling with eStargz</strong></p>
<ul>
<li>Uses stargz-snapshotter plugin for on-demand layer fetching</li>
<li>HTTP range requests to fetch only needed chunks</li>
<li>FUSE filesystem for transparent lazy loading</li>
<li>Zero disk storage overhead</li>
</ul>
</li>
<li>
<p><strong>Startup Benchmarking Tool</strong> (<code>startup-bench/</code>)</p>
<ul>
<li>Cold and warm start measurements</li>
<li>Container readiness detection (not just process start)</li>
<li>Auto-detection of eStargz images by <code>:esgz</code> suffix</li>
<li>Support for plain HTTP registries</li>
</ul>
</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-lazy-pulling-works">How Lazy Pulling Works<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#how-lazy-pulling-works" class="hash-link" aria-label="Direct link to How Lazy Pulling Works" title="Direct link to How Lazy Pulling Works" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="phase-1-metadata-fetch-006s-for-2gb-image">Phase 1: Metadata Fetch (~0.06s for 2GB image)<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#phase-1-metadata-fetch-006s-for-2gb-image" class="hash-link" aria-label="Direct link to Phase 1: Metadata Fetch (~0.06s for 2GB image)" title="Direct link to Phase 1: Metadata Fetch (~0.06s for 2GB image)" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Download index (290B) + manifest (2.6KB) + config (6.3KB) = ~9KB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Register layers with stargz-snapshotter as "remote"</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="phase-2-container-creation-003s">Phase 2: Container Creation (~0.03s)<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#phase-2-container-creation-003s" class="hash-link" aria-label="Direct link to Phase 2: Container Creation (~0.03s)" title="Direct link to Phase 2: Container Creation (~0.03s)" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Stargz-snapshotter creates remote snapshot mounts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FUSE filesystem presents layer contents virtually</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Container starts WITHOUT waiting for layer downloads</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="phase-3-on-demand-fetching-during-container-runtime">Phase 3: On-Demand Fetching (during container runtime)<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#phase-3-on-demand-fetching-during-container-runtime" class="hash-link" aria-label="Direct link to Phase 3: On-Demand Fetching (during container runtime)" title="Direct link to Phase 3: On-Demand Fetching (during container runtime)" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Application reads /app/data/file.dat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FUSE intercepts read()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HTTP GET with Range: bytes=1024-2048 to registry</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Data returned (cached in memory, NOT disk)</span><br></span></code></pre></div></div>
<p><strong>Result</strong>: For 2GB image with small working set (~20-30MB accessed), only those chunks are fetched.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-implications">Performance Implications<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#performance-implications" class="hash-link" aria-label="Direct link to Performance Implications" title="Direct link to Performance Implications" translate="no">​</a></h3>
<p><strong>Small Working Set (&lt;10% of image):</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Pull: &amp;lt;1s (metadata only)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Runtime: Fast (few on-demand fetches)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Total: 13.9x faster than eager loading ✅</span><br></span></code></pre></div></div>
<p><strong>Large Working Set (&gt;30% of image):</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Pull: &amp;lt;1s (metadata only)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Runtime: 78-87s (many serialized HTTP requests)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Total: 1.5-2x SLOWER than eager loading ❌</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Why slower:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Bulk parallel download: 45-53s for 8GB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- On-demand serial fetches: 78-87s for same 8GB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Each file access = network round-trip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- FUSE overhead + HTTP request overhead</span><br></span></code></pre></div></div>
<p><strong>Trade-off:</strong> Fast startup vs total completion time depends on working set size.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-highlights">Implementation Highlights<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#implementation-highlights" class="hash-link" aria-label="Direct link to Implementation Highlights" title="Direct link to Implementation Highlights" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rpullimage-operation">RPullImage Operation<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#rpullimage-operation" class="hash-link" aria-label="Direct link to RPullImage Operation" title="Direct link to RPullImage Operation" translate="no">​</a></h3>
<p>Used <code>source.AppendDefaultLabelsHandlerWrapper()</code> from stargz-snapshotter:</p>
<div class="language-go codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-go codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">"github.com/containerd/containerd/v2/client"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">"github.com/containerd/stargz-snapshotter/fs/source"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// Create label handler - this enables lazy pulling!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">labelHandler </span><span class="token operator" style="color:#393A34">:=</span><span class="token plain"> source</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">AppendDefaultLabelsHandlerWrapper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">imageRef</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> prefetchSize</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pullOpts </span><span class="token operator" style="color:#393A34">:=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">RemoteOpt</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">WithPullUnpack</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">WithImageHandlerWrapper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">labelHandler</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// Essential for lazy pulling</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">WithPullSnapshotter</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"stargz"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token boolean" style="color:#36acaa">_</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> err </span><span class="token operator" style="color:#393A34">:=</span><span class="token plain"> containerdClient</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">Pull</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> imageRef</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> pullOpts</span><span class="token operator" style="color:#393A34">...</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p><strong>Critical Insight</strong>: Regular <code>containerd.Pull()</code> downloads everything even with stargz snapshotter. The label handler wrapper is <strong>essential</strong> for true lazy pulling.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="critical-bugs-discovered--fixed">Critical Bugs Discovered &amp; Fixed<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#critical-bugs-discovered--fixed" class="hash-link" aria-label="Direct link to Critical Bugs Discovered &amp; Fixed" title="Direct link to Critical Bugs Discovered &amp; Fixed" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-content-blob-caching">1. Content Blob Caching<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#1-content-blob-caching" class="hash-link" aria-label="Direct link to 1. Content Blob Caching" title="Direct link to 1. Content Blob Caching" translate="no">​</a></h3>
<p><strong>Problem</strong>: Cold start iterations reused cached content blobs (48s → 0.17s on iteration 2).</p>
<p><strong>Root Cause</strong>: Content blobs are globally shared across namespaces. Image removal only cleared metadata.</p>
<p><strong>Solution</strong>: Use <code>images.SynchronousDelete()</code> to trigger immediate garbage collection:</p>
<div class="language-go codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-go codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">deleteOpts </span><span class="token operator" style="color:#393A34">:=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">images</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DeleteOpt</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">images</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">SynchronousDelete</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">imageService</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">Delete</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ctx</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> imageRef</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> deleteOpts</span><span class="token operator" style="color:#393A34">...</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-metadata-corruption">2. Metadata Corruption<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#2-metadata-corruption" class="hash-link" aria-label="Direct link to 2. Metadata Corruption" title="Direct link to 2. Metadata Corruption" translate="no">​</a></h3>
<p><strong>Problem</strong>: Mixing regular <code>Pull()</code> and <code>rpull</code> caused "target snapshot already exists" errors.</p>
<p><strong>Root Cause</strong>: Content blobs retained <code>containerd.io/uncompressed</code> annotations from previous pulls.</p>
<p><strong>Solution</strong>: Clean content store before lazy pulling:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo ctr-remote content ls | grep workload | awk '{print $1}' | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  xargs -I {} sudo ctr-remote content rm {}</span><br></span></code></pre></div></div>
<p><strong>Prevention</strong>: Never mix pull methods - always use RPullImage for eStargz images.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-plain-http-registry-support">3. Plain HTTP Registry Support<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#3-plain-http-registry-support" class="hash-link" aria-label="Direct link to 3. Plain HTTP Registry Support" title="Direct link to 3. Plain HTTP Registry Support" translate="no">​</a></h3>
<p><strong>Problem</strong>: Custom Docker resolver breaks lazy pulling by forcing full downloads.</p>
<p><strong>Solution for RPullImage</strong>: Configure stargz-snapshotter daemon instead:</p>
<div class="language-toml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-toml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># /etc/containerd-stargz-grpc/config.toml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[[resolver.host."172.17.0.2:5000".mirrors]]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">host = "172.17.0.2:5000"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">insecure = true</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="estargz-format-verification">eStargz Format Verification<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#estargz-format-verification" class="hash-link" aria-label="Direct link to eStargz Format Verification" title="Direct link to eStargz Format Verification" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-characteristics">Key Characteristics<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#key-characteristics" class="hash-link" aria-label="Direct link to Key Characteristics" title="Direct link to Key Characteristics" translate="no">​</a></h3>
<p><strong>Media Type</strong>: <code>application/vnd.oci.image.layer.v1.tar+gzip</code> (same as regular gzip!)</p>
<p><strong>Distinguishing Features</strong>:</p>
<ol>
<li><strong>STARGZ footer</strong> in blob (verify with <code>xxd</code>)</li>
<li><strong>TOC digest annotation</strong>: <code>containerd.io/snapshot/stargz/toc.digest</code></li>
<li><strong>Uncompressed size annotation</strong>: <code>io.containers.estargz.uncompressed-size</code></li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="creating-estargz-images">Creating eStargz Images<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#creating-estargz-images" class="hash-link" aria-label="Direct link to Creating eStargz Images" title="Direct link to Creating eStargz Images" translate="no">​</a></h3>
<p>Use ctr-remote workflow (NOT docker buildx):</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 1. Build regular image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker buildx build -t localhost:5000/image:base --push .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2. Pull to containerd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo ctr-remote image pull localhost:5000/image:base</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 3. Optimize to eStargz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo ctr-remote image optimize --no-optimize --oci \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  localhost:5000/image:base localhost:5000/image:esgz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 4. Push eStargz image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo ctr-remote images push --plain-http localhost:5000/image:esgz</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verification">Verification<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#verification" class="hash-link" aria-label="Direct link to Verification" title="Direct link to Verification" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check manifest annotations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">curl -s http://localhost:5000/v2/image/manifests/esgz | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  jq '.layers[].annotations'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Verify STARGZ footer in blob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo tail -c 100 /var/lib/containerd/.../blobs/sha256/... | xxd | tail -3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Look for: "STARGZ" marker</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="best-practices">Best Practices<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#best-practices" class="hash-link" aria-label="Direct link to Best Practices" title="Direct link to Best Practices" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="decision-framework-lazy-pulling-vs-eager-loading">Decision Framework: Lazy Pulling vs Eager Loading<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#decision-framework-lazy-pulling-vs-eager-loading" class="hash-link" aria-label="Direct link to Decision Framework: Lazy Pulling vs Eager Loading" title="Direct link to Decision Framework: Lazy Pulling vs Eager Loading" translate="no">​</a></h3>
<p><strong>The critical factor is WORKING SET SIZE:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Working Set &lt; 10% of image:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Use lazy pulling (13.9x faster startup)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Working Set &gt; 30% of image:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Use eager loading (1.5-2x faster total completion)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Working Set 10-30% of image:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Depends on whether you optimize for startup or total time</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="when-to-use-lazy-pulling-">When to Use Lazy Pulling ✅<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#when-to-use-lazy-pulling-" class="hash-link" aria-label="Direct link to When to Use Lazy Pulling ✅" title="Direct link to When to Use Lazy Pulling ✅" translate="no">​</a></h3>
<p><strong>Best for startup latency optimization:</strong></p>
<ol>
<li>
<p><strong>Small working set</strong> (&lt;10% of image accessed)</p>
<ul>
<li>Example: Web API loading libraries (100MB of 2GB image)</li>
<li>Result: 13.9x faster cold start</li>
</ul>
</li>
<li>
<p><strong>Ephemeral workloads</strong> - short-lived containers</p>
<ul>
<li>Containers that start, perform task, exit quickly</li>
<li>Don't benefit from caching anyway</li>
</ul>
</li>
<li>
<p><strong>Cold start critical</strong> - startup time is the bottleneck</p>
<ul>
<li>Serverless functions</li>
<li>Auto-scaling scenarios</li>
<li>Development/testing iterations</li>
</ul>
</li>
<li>
<p><strong>Limited disk space</strong> - can't cache full images</p>
<ul>
<li>Edge devices</li>
<li>Multi-tenant nodes with many images</li>
</ul>
</li>
<li>
<p><strong>High bandwidth, low latency</strong> to registry</p>
<ul>
<li>On-demand fetches need fast network</li>
<li>Registry co-located with compute</li>
</ul>
</li>
</ol>
<p><strong>Example Use Case:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">LLM Inference API:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Image: 4GB (model weights)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Working set: 300MB (actively loaded model portion)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Access pattern: Load once, serve many requests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Lazy pulling: 1-2s startup vs 18s eager</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Result: 9-18x faster! ✅</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="when-not-to-use-lazy-pulling-">When NOT to Use Lazy Pulling ❌<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#when-not-to-use-lazy-pulling-" class="hash-link" aria-label="Direct link to When NOT to Use Lazy Pulling ❌" title="Direct link to When NOT to Use Lazy Pulling ❌" translate="no">​</a></h3>
<p><strong>Eager loading is faster when:</strong></p>
<ol>
<li>
<p><strong>Large working set</strong> (&gt;30% of image accessed)</p>
<ul>
<li>Example: Batch processing reading 8GB of 8GB image</li>
<li>Result: Lazy pulling 1.5-2x SLOWER for total completion</li>
</ul>
</li>
<li>
<p><strong>Data-intensive workloads</strong> - process significant data</p>
<ul>
<li>Training jobs accessing entire dataset</li>
<li>ETL pipelines reading many files</li>
<li>Stress tests (like our benchmark)</li>
</ul>
</li>
<li>
<p><strong>Sequential file access</strong> - many files read in order</p>
<ul>
<li>Each file = separate HTTP request with lazy pulling</li>
<li>Bulk download is much faster (parallel, large chunks)</li>
</ul>
</li>
<li>
<p><strong>Small images</strong> (&lt;100MB) - overhead not worth it</p>
<ul>
<li>Metadata overhead dominates</li>
</ul>
</li>
<li>
<p><strong>Slow/high-latency network</strong> - on-demand fetches will be slow</p>
<ul>
<li>Each file access waits for network round-trip</li>
</ul>
</li>
<li>
<p><strong>Offline/air-gapped environments</strong> - no registry access</p>
</li>
</ol>
<p><strong>Example Use Case:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">LLM Training/Fine-tuning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Image: 8GB (dataset + checkpoints)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Working set: 7GB (accessing most data during training)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Access pattern: Read many files sequentially</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Lazy pulling: 79-88s total time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Eager loading: 45-54s total time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Result: Eager 1.5-2x faster! ✅</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-optimization-matrix">Performance Optimization Matrix<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#performance-optimization-matrix" class="hash-link" aria-label="Direct link to Performance Optimization Matrix" title="Direct link to Performance Optimization Matrix" translate="no">​</a></h3>
<table><thead><tr><th>Metric to Optimize</th><th>Image Size</th><th>Working Set</th><th>Recommendation</th></tr></thead><tbody><tr><td><strong>Cold start time</strong></td><td>Large (&gt;1GB)</td><td>Small (&lt;10%)</td><td>Lazy pulling ✅</td></tr><tr><td><strong>Cold start time</strong></td><td>Large (&gt;1GB)</td><td>Large (&gt;30%)</td><td>Lazy pulling ✅ (startup only)</td></tr><tr><td><strong>Total completion time</strong></td><td>Large (&gt;1GB)</td><td>Small (&lt;10%)</td><td>Lazy pulling ✅</td></tr><tr><td><strong>Total completion time</strong></td><td>Large (&gt;1GB)</td><td>Large (&gt;30%)</td><td>Eager loading ✅</td></tr><tr><td><strong>Disk usage</strong></td><td>Any</td><td>Any</td><td>Lazy pulling ✅</td></tr><tr><td><strong>Network bandwidth</strong></td><td>Large (&gt;1GB)</td><td>Small (&lt;10%)</td><td>Lazy pulling ✅</td></tr><tr><td><strong>Network bandwidth</strong></td><td>Large (&gt;1GB)</td><td>Large (&gt;30%)</td><td>Eager loading ✅</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="architecture-insights">Architecture Insights<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#architecture-insights" class="hash-link" aria-label="Direct link to Architecture Insights" title="Direct link to Architecture Insights" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="containerd-design-principles">Containerd Design Principles<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#containerd-design-principles" class="hash-link" aria-label="Direct link to Containerd Design Principles" title="Direct link to Containerd Design Principles" translate="no">​</a></h3>
<ol>
<li>
<p><strong>Content Store is Global</strong></p>
<ul>
<li>Image metadata: namespaced ✅</li>
<li>Container metadata: namespaced ✅</li>
<li>Content blobs: <strong>GLOBAL</strong> (shared across namespaces) ❌</li>
</ul>
</li>
<li>
<p><strong>Snapshotter Abstraction</strong></p>
<ul>
<li>Each snapshotter has unique requirements</li>
<li>Stargz needs special label handlers for lazy pulling</li>
<li>Not as simple as just switching a snapshotter flag</li>
</ul>
</li>
<li>
<p><strong>Trade-offs</strong></p>
<ul>
<li><strong>Startup latency</strong>: Lazy pulling dramatically faster (13.9x)</li>
<li><strong>Total completion</strong>: Depends on working set size<!-- -->
<ul>
<li>Small working set (&lt;10%): Lazy pulling wins (13.9x faster)</li>
<li>Large working set (&gt;30%): Eager loading wins (1.5-2x faster)</li>
</ul>
</li>
<li><strong>Network vs Disk I/O</strong>:<!-- -->
<ul>
<li>Bulk parallel download: ~45-53s for 8GB</li>
<li>Serialized on-demand fetches: ~78-87s for same 8GB data</li>
<li>Local disk reads &gt;&gt; HTTP range requests for large data access</li>
</ul>
</li>
<li><strong>Zero storage overhead</strong> vs traditional caching benefits</li>
<li><strong>Network-dependent performance</strong> - requires good bandwidth/latency</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="version-compatibility">Version Compatibility<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#version-compatibility" class="hash-link" aria-label="Direct link to Version Compatibility" title="Direct link to Version Compatibility" translate="no">​</a></h3>
<p><strong>Critical</strong>: Match library versions with system installations</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check system version</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">containerd --version  # v2.1.4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Use matching library version</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">go get github.com/containerd/containerd/v2@v2.1.4</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="debugging-techniques">Debugging Techniques<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#debugging-techniques" class="hash-link" aria-label="Direct link to Debugging Techniques" title="Direct link to Debugging Techniques" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-check-content-store-annotations">1. Check Content Store Annotations<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#1-check-content-store-annotations" class="hash-link" aria-label="Direct link to 1. Check Content Store Annotations" title="Direct link to 1. Check Content Store Annotations" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo ctr-remote content ls | grep image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Look for: containerd.io/uncompressed annotations</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-verify-lazy-pulling-is-active">2. Verify Lazy Pulling is Active<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#2-verify-lazy-pulling-is-active" class="hash-link" aria-label="Direct link to 2. Verify Lazy Pulling is Active" title="Direct link to 2. Verify Lazy Pulling is Active" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Inside container, check for stargz metadata</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ls /.stargz-snapshotter/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat /.stargz-snapshotter/*.json</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-binary-verification">3. Binary Verification<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#3-binary-verification" class="hash-link" aria-label="Direct link to 3. Binary Verification" title="Direct link to 3. Binary Verification" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check STARGZ footer (authoritative proof)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo tail -c 100 /var/lib/containerd/.../blobs/sha256/... | xxd | tail -3</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-monitor-on-demand-fetches">4. Monitor On-Demand Fetches<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#4-monitor-on-demand-fetches" class="hash-link" aria-label="Direct link to 4. Monitor On-Demand Fetches" title="Direct link to 4. Monitor On-Demand Fetches" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Watch stargz-snapshotter logs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo journalctl -u stargz-snapshotter -f</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quick-reference-commands">Quick Reference Commands<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#quick-reference-commands" class="hash-link" aria-label="Direct link to Quick Reference Commands" title="Direct link to Quick Reference Commands" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Start local registry</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker run -d --name registry -p 5000:5000 registry:2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Start stargz-snapshotter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo systemctl start stargz-snapshotter</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarking">Benchmarking<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#benchmarking" class="hash-link" aria-label="Direct link to Benchmarking" title="Direct link to Benchmarking" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Build tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd startup-bench &amp;&amp; go build -o startup-bench main.go</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Cold start with lazy pulling (auto-detected via :esgz suffix)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo ./startup-bench \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -image=localhost:5000/workload-2048mb-few-large:esgz \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -snapshotter=stargz \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -mode=cold \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -iterations=3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Cold start with regular pull</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo ./startup-bench \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -image=localhost:5000/workload-2048mb-few-large:latest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -snapshotter=overlayfs \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -mode=cold \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -iterations=3</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cleanup">Cleanup<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#cleanup" class="hash-link" aria-label="Direct link to Cleanup" title="Direct link to Cleanup" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Clean content store for true cold starts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo ctr-remote content ls | grep workload | awk '{print $1}' | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  xargs -I {} sudo ctr-remote content rm {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Restart services</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo systemctl restart stargz-snapshotter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo systemctl restart containerd</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="external-resources">External Resources<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#external-resources" class="hash-link" aria-label="Direct link to External Resources" title="Direct link to External Resources" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="official-documentation">Official Documentation<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#official-documentation" class="hash-link" aria-label="Direct link to Official Documentation" title="Direct link to Official Documentation" translate="no">​</a></h3>
<p><strong>Stargz-Snapshotter</strong>:</p>
<ul>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/overview.md" target="_blank" rel="noopener noreferrer">Project Overview</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/getting-started.md" target="_blank" rel="noopener noreferrer">Getting Started Guide</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/ctr-remote.md" target="_blank" rel="noopener noreferrer">ctr-remote CLI Tool</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/overview.md#registry-mirrors-and-insecure-connection" target="_blank" rel="noopener noreferrer">Registry Configuration</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter" target="_blank" rel="noopener noreferrer">GitHub Repository</a></li>
</ul>
<p><strong>Containerd</strong>:</p>
<ul>
<li><a href="https://github.com/containerd/containerd/tree/main/docs" target="_blank" rel="noopener noreferrer">Official Documentation</a></li>
<li><a href="https://github.com/containerd/containerd/blob/main/docs/garbage-collection.md" target="_blank" rel="noopener noreferrer">Garbage Collection</a></li>
<li><a href="https://github.com/containerd/containerd/blob/main/docs/content-flow.md" target="_blank" rel="noopener noreferrer">Content Store Design</a></li>
<li><a href="https://github.com/containerd/containerd/blob/main/docs/namespaces.md" target="_blank" rel="noopener noreferrer">Namespaces</a></li>
<li><a href="https://github.com/containerd/containerd/blob/main/docs/snapshotters/README.md" target="_blank" rel="noopener noreferrer">Snapshotters</a></li>
<li><a href="https://github.com/containerd/containerd" target="_blank" rel="noopener noreferrer">GitHub Repository</a></li>
</ul>
<p><strong>OCI Specifications</strong>:</p>
<ul>
<li><a href="https://github.com/opencontainers/image-spec" target="_blank" rel="noopener noreferrer">OCI Image Spec</a></li>
<li><a href="https://github.com/opencontainers/image-spec/blob/main/media-types.md" target="_blank" rel="noopener noreferrer">Media Types</a></li>
<li><a href="https://github.com/opencontainers/image-spec/blob/main/layer.md" target="_blank" rel="noopener noreferrer">Image Layer Spec</a></li>
</ul>
<p><strong>eStargz Format</strong>:</p>
<ul>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/estargz.md" target="_blank" rel="noopener noreferrer">eStargz Paper</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/stargz-estargz.md" target="_blank" rel="noopener noreferrer">Format Specification</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="related-tools--projects">Related Tools &amp; Projects<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#related-tools--projects" class="hash-link" aria-label="Direct link to Related Tools &amp; Projects" title="Direct link to Related Tools &amp; Projects" translate="no">​</a></h3>
<p><strong>Container Runtimes</strong>:</p>
<ul>
<li><a href="https://containerd.io/" target="_blank" rel="noopener noreferrer">containerd</a> - Industry-standard container runtime</li>
<li><a href="https://github.com/opencontainers/runc" target="_blank" rel="noopener noreferrer">runc</a> - OCI container runtime</li>
</ul>
<p><strong>Image Optimization</strong>:</p>
<ul>
<li><a href="https://github.com/moby/buildkit" target="_blank" rel="noopener noreferrer">Buildkit</a> - Concurrent, cache-efficient build toolkit</li>
<li><a href="https://github.com/dragonflyoss/nydus" target="_blank" rel="noopener noreferrer">Nydus</a> - Alternative lazy-pulling solution by Dragonfly</li>
</ul>
<p><strong>Registries</strong>:</p>
<ul>
<li><a href="https://docs.docker.com/registry/" target="_blank" rel="noopener noreferrer">Docker Registry</a> - Open-source registry implementation</li>
<li><a href="https://github.com/opencontainers/distribution-spec" target="_blank" rel="noopener noreferrer">Distribution Spec</a> - OCI distribution specification</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="research-papers--articles">Research Papers &amp; Articles<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#research-papers--articles" class="hash-link" aria-label="Direct link to Research Papers &amp; Articles" title="Direct link to Research Papers &amp; Articles" translate="no">​</a></h3>
<p><strong>Lazy Pulling &amp; Container Startup</strong>:</p>
<ul>
<li><a href="https://www.usenix.org/conference/fast20/presentation/li" target="_blank" rel="noopener noreferrer">FAST '20: Startup Containers in Lightning Speed with Lazy Image Distribution</a></li>
<li><a href="https://www.usenix.org/conference/fast16/technical-sessions/presentation/harter" target="_blank" rel="noopener noreferrer">Slacker: Fast Distribution with Lazy Docker Containers</a></li>
</ul>
<p><strong>Container Image Optimization</strong>:</p>
<ul>
<li><a href="https://www.usenix.org/conference/atc19/presentation/zhao-jian" target="_blank" rel="noopener noreferrer">USENIX ATC '19: Packer: Toward Million-fold Container Image Optimization</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="community--support">Community &amp; Support<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#community--support" class="hash-link" aria-label="Direct link to Community &amp; Support" title="Direct link to Community &amp; Support" translate="no">​</a></h3>
<p><strong>Issue Trackers</strong>:</p>
<ul>
<li><a href="https://github.com/containerd/stargz-snapshotter/issues" target="_blank" rel="noopener noreferrer">Stargz-Snapshotter Issues</a></li>
<li><a href="https://github.com/containerd/containerd/issues" target="_blank" rel="noopener noreferrer">Containerd Issues</a></li>
<li><a href="https://github.com/dragonflyoss/nydus/issues/1527" target="_blank" rel="noopener noreferrer">Nydus Lazy Pulling Issue #1527</a> - Related metadata corruption</li>
</ul>
<p><strong>Communication</strong>:</p>
<ul>
<li><a href="https://slack.containerd.io/" target="_blank" rel="noopener noreferrer">Containerd Slack</a> - Community chat</li>
<li><a href="https://cloud-native.slack.com/messages/containerd" target="_blank" rel="noopener noreferrer">CNCF Slack #containerd</a> - Technical discussions</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tutorials--guides">Tutorials &amp; Guides<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#tutorials--guides" class="hash-link" aria-label="Direct link to Tutorials &amp; Guides" title="Direct link to Tutorials &amp; Guides" translate="no">​</a></h3>
<p><strong>Getting Started</strong>:</p>
<ul>
<li><a href="https://containerd.io/docs/getting-started/" target="_blank" rel="noopener noreferrer">Containerd Getting Started</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/getting-started.md" target="_blank" rel="noopener noreferrer">Stargz-Snapshotter Quick Start</a></li>
</ul>
<p><strong>Advanced Topics</strong>:</p>
<ul>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/overview.md#lazy-pulling-feature" target="_blank" rel="noopener noreferrer">Lazy Pulling Deep Dive</a></li>
<li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/ctr-remote.md#building-estargz" target="_blank" rel="noopener noreferrer">Building eStargz Images</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="technical-insights">Technical Insights<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#technical-insights" class="hash-link" aria-label="Direct link to Technical Insights" title="Direct link to Technical Insights" translate="no">​</a></h3>
<ol>
<li><strong>Lazy pulling is essential for large images</strong> - 150x pull speedup for 2GB images</li>
<li><strong>Label handlers are critical</strong> - Regular containerd.Pull() doesn't enable lazy pulling</li>
<li><strong>Content store is global</strong> - Shared across namespaces, requires explicit cleanup</li>
<li><strong>Never mix pull methods</strong> - Causes metadata corruption</li>
<li><strong>eStargz verification</strong> - Check STARGZ footer in blobs, not just media type</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-characteristics">Performance Characteristics<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#performance-characteristics" class="hash-link" aria-label="Direct link to Performance Characteristics" title="Direct link to Performance Characteristics" translate="no">​</a></h3>
<ol>
<li><strong>Speedup scales with image size</strong> - Larger images benefit more</li>
<li><strong>Network-dependent</strong> - Requires good bandwidth/latency to registry</li>
<li><strong>Working set matters</strong> - Only fetches accessed files</li>
<li><strong>Trade-off exists</strong> - Faster pull, slightly slower start</li>
<li><strong>Zero storage overhead</strong> - No disk caching of full layers</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="development-best-practices">Development Best Practices<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#development-best-practices" class="hash-link" aria-label="Direct link to Development Best Practices" title="Direct link to Development Best Practices" translate="no">​</a></h3>
<ol>
<li><strong>Performance-driven debugging</strong> - Timing anomalies reveal bugs</li>
<li><strong>Binary-level verification</strong> - Source of truth for format validation</li>
<li><strong>Read upstream source code</strong> - Reveals exact implementation details</li>
<li><strong>Test with realistic workloads</strong> - Small images don't show benefits</li>
<li><strong>Match system versions</strong> - Library versions should align with binaries</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>This project demonstrates that <strong>eStargz with lazy pulling provides dramatic performance improvements for startup latency</strong>, but reveals a <strong>critical trade-off with total workload completion time</strong> that depends on working set size.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-findings-1">Key Findings<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#key-findings-1" class="hash-link" aria-label="Direct link to Key Findings" title="Direct link to Key Findings" translate="no">​</a></h3>
<p><strong>✅ Lazy Pulling Wins for Startup Latency:</strong></p>
<ul>
<li>150x faster pull time (9.2s → 0.06s)</li>
<li>13.9x faster cold start (9.4s → 0.67s)</li>
<li>Zero disk storage overhead</li>
<li>Ideal for small working sets (&lt;10% of image)</li>
</ul>
<p><strong>⚠️ Eager Loading Wins for Data-Intensive Workloads:</strong></p>
<ul>
<li>1.5-2x faster total completion for large working sets (&gt;30% of image)</li>
<li>Bulk parallel downloads faster than serialized on-demand fetches</li>
<li>Better for batch processing, training, ETL pipelines</li>
<li>Stress test (8GB sequential read): Overlayfs 45-54s vs Stargz 79-88s</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="decision-framework">Decision Framework<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#decision-framework" class="hash-link" aria-label="Direct link to Decision Framework" title="Direct link to Decision Framework" translate="no">​</a></h3>
<p><strong>The critical question: What percentage of your image does the workload access?</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Small working set (&amp;lt;10%):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Lazy pulling essential (13.9x faster)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Example: LLM inference API loading 300MB of 4GB image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Large working set (&gt;30%):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Eager loading faster (1.5-2x faster total time)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Example: Training job accessing 7GB of 8GB image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Optimize for startup time:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Always use lazy pulling</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Optimize for total completion time:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  → Use lazy pulling only for small working sets</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="production-recommendations">Production Recommendations<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#production-recommendations" class="hash-link" aria-label="Direct link to Production Recommendations" title="Direct link to Production Recommendations" translate="no">​</a></h3>
<ol>
<li>
<p><strong>LLM Inference/Serving</strong> - Use lazy pulling ✅</p>
<ul>
<li>Small working set, startup critical</li>
<li>10-20x faster cold start for auto-scaling</li>
</ul>
</li>
<li>
<p><strong>LLM Training/Fine-tuning</strong> - Use eager loading ✅</p>
<ul>
<li>Large working set, total time matters</li>
<li>Avoid 1.5-2x penalty for on-demand fetches</li>
</ul>
</li>
<li>
<p><strong>Development/Testing</strong> - Use lazy pulling ✅</p>
<ul>
<li>Fast iteration cycles</li>
<li>Disk space savings</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="technical-validation">Technical Validation<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week2#technical-validation" class="hash-link" aria-label="Direct link to Technical Validation" title="Direct link to Technical Validation" translate="no">​</a></h3>
<p>The implementation validates that:</p>
<ul>
<li>Proper integration with stargz-snapshotter enables true lazy pulling</li>
<li>Label handlers (<code>AppendDefaultLabelsHandlerWrapper</code>) are essential</li>
<li>Content store management critical for accurate benchmarking</li>
<li>Working set size is the primary performance factor</li>
<li>Network vs disk I/O trade-off is significant for large data access</li>
</ul>]]></content>
        <author>
            <name>Ranjan Ojha</name>
            <uri>https://github.com/hungerarray</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Video Cutter - Week 2 Learnings]]></title>
        <id>https://blog.vertexcover.io/learnings/2025-10-aman-week2</id>
        <link href="https://blog.vertexcover.io/learnings/2025-10-aman-week2"/>
        <updated>2025-10-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[{/ truncate /}]]></summary>
        <content type="html"><![CDATA[
<p>The original approach relied heavily on fixed thresholds to determine whether a frame was suitable for cutting. For example, we would check if motion was below 2.5 pixels/frame, or if mouth openness was below 0.08 aspect ratio. While this seemed reasonable in theory, several fundamental issues emerged:</p>
<p><strong>The Binary Decision Problem</strong>: Thresholds create hard boundaries - a frame with motion at 2.4 is "good" while one at 2.6 is "bad". This ignores the fact that quality exists on a spectrum. We were discarding potentially excellent cut points simply because one metric was slightly above threshold, even if all other metrics were perfect.</p>
<p><strong>The Context Blindness Problem</strong>: A threshold of 2.5 pixels/frame might be perfectly fine for one video but completely wrong for another. A talking head video shot on a stabilized camera will have very different motion characteristics than one shot handheld. The threshold approach had no way to understand relative quality within a video's context.</p>
<p><strong>The Combinatorial Explosion Problem</strong>: With 5+ metrics (eye openness, motion, expression, pose, sharpness), we faced an impossible tuning challenge. What if a frame had excellent eye openness and stability but slightly high motion? Which threshold should win? We ended up with increasingly complex boolean logic that was brittle and hard to reason about.</p>
<p><strong>The "No Good Frame" Scenario</strong>: In some video segments, no frame passed all thresholds. The system would then either fail completely or pick arbitrarily, defeating the purpose of quality analysis. The threshold approach couldn't say "this frame is better than that one" - it could only say "pass" or "fail".</p>
<p>These limitations made it clear that we needed a fundamentally different approach that could handle relative quality, context-awareness, and graceful degradation.</p>
<h1>Moving to a Pure Ranking Algorithm</h1>
<p>Instead of asking "does this frame pass?", we now ask "which frame is best?". The ranking algorithm in <code>try/cut_point_ranker/</code> implements a pure ranking approach with no thresholds whatsoever. Every frame gets scored, and we simply pick the highest-ranked ones.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-factor-scoring-system">Multi-Factor Scoring System<a href="https://blog.vertexcover.io/learnings/2025-10-aman-week2#multi-factor-scoring-system" class="hash-link" aria-label="Direct link to Multi-Factor Scoring System" title="Direct link to Multi-Factor Scoring System" translate="no">​</a></h2>
<p>The ranker combines 5 key metrics with configurable weights:</p>
<ol>
<li>
<p><strong>Eye Openness</strong> - Uses Eye Aspect Ratio (EAR) detection based on Soukupová &amp; Čech (2016). We want eyes fully open, not blinking or partially closed.</p>
</li>
<li>
<p><strong>Motion Stability</strong> - Uses Farneback optical flow to measure frame-to-frame motion. Lower motion is better (inverse scoring).</p>
</li>
<li>
<p><strong>Expression Neutrality</strong> - Analyzes MediaPipe facial blendshapes to detect mouth movement and eyebrow activity. We prefer neutral expressions (inverse scoring).</p>
</li>
<li>
<p><strong>Pose Stability</strong> - Measures head pose deviation from neutral position. Stable head position is better (inverse scoring).</p>
</li>
<li>
<p><strong>Visual Sharpness</strong> - Laplacian variance to ensure the frame isn't blurry.</p>
</li>
</ol>
<p>The beauty of weighted scoring is that it allows trade-offs. A frame with perfect eye openness but slightly higher motion can still score well, whereas with thresholds it might have been rejected entirely.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-stage-ranking-pipeline">Multi-Stage Ranking Pipeline<a href="https://blog.vertexcover.io/learnings/2025-10-aman-week2#multi-stage-ranking-pipeline" class="hash-link" aria-label="Direct link to Multi-Stage Ranking Pipeline" title="Direct link to Multi-Stage Ranking Pipeline" translate="no">​</a></h2>
<p>The scoring happens in multiple stages to ensure quality:</p>
<p><strong>Stage 1: Feature Extraction</strong> - Extract all raw metrics from every frame in the time range. This is done in a single pass through the video for efficiency.</p>
<p><strong>Stage 2: Normalization</strong> - Normalize all metrics to [0, 1] range across the entire segment. This is crucial - the normalization happens relative to the video segment being analyzed, making it context-aware.</p>
<p><strong>Stage 3: Quality Gating</strong> - Instead of hard thresholds, we use percentile-based penalties. If a frame's expression activity is above the 75th percentile for the segment, it receives a penalty multiplier. The penalty is proportional to how extreme the outlier is, not a binary yes/no.</p>
<p><strong>Stage 4: Local Stability Boost</strong> - Frames that are part of stable sequences (low variance in a 5-frame window) receive a boost multiplier. This rewards temporal coherence.</p>
<p><strong>Stage 5: Context Window Smoothing</strong> - Apply a sliding window average over composite scores. A frame is better if its neighbors are also good, ensuring we don't pick an isolated good frame in a bad sequence.</p>
<h1>Research-Based Feature Extraction</h1>
<p>Rather than inventing metrics from scratch, the implementation uses proven computer vision algorithms:</p>
<ul>
<li>
<p><strong>Eye Aspect Ratio (EAR)</strong>: Based on the 2016 paper by Soukupová &amp; Čech for blink detection. Calculates ratio of vertical to horizontal eye landmark distances.</p>
</li>
<li>
<p><strong>Optical Flow</strong>: Uses Farneback dense optical flow, a well-established method for motion estimation in video.</p>
</li>
<li>
<p><strong>MediaPipe FaceMesh</strong>: Google's solution providing 478 facial landmarks plus 52 blendshape coefficients for detailed expression analysis.</p>
</li>
<li>
<p><strong>Laplacian Variance</strong>: Standard technique for measuring image sharpness by analyzing high-frequency content.</p>
</li>
</ul>
<h1>Word-Level Pause Detection</h1>
<p>Improved the speech analysis to detect pauses at word-level granularity rather than just sentence boundaries. This allows us to find natural cut points mid-sentence during natural speaking pauses, which is especially important for AI-generated talking head videos where sentences can be quite long.</p>
<p>The transcription analysis now tracks word-level timestamps and identifies pauses between words that are long enough to indicate a natural break in speech flow.</p>
<h1>Adaptive Padding for Cut Points</h1>
<p>Implemented an adaptive padding calculator that analyzes visual stability around a cut point to determine optimal padding amounts. Instead of fixed padding values, the system now:</p>
<ul>
<li>Analyzes frame similarity before/after the cut point</li>
<li>Measures face movement and general motion</li>
<li>Detects scene changes that would affect padding needs</li>
</ul>
<p>This ensures we add just enough padding for smooth transitions without including unstable or transitional frames, with padding amounts ranging from configured minimum to maximum based on actual video content stability.</p>
<h1>References and Resources</h1>
<ul>
<li><strong>Eye Aspect Ratio (EAR)</strong>: <a href="http://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf" target="_blank" rel="noopener noreferrer">Real-Time Eye Blink Detection using Facial Landmarks</a></li>
<li><strong>Farneback Optical Flow</strong>: <a href="http://www.diva-portal.org/smash/get/diva2:273847/FULLTEXT01.pdf" target="_blank" rel="noopener noreferrer">Two-Frame Motion Estimation Based on Polynomial Expansion</a></li>
<li><strong>MediaPipe FaceMesh</strong>: <a href="https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker" target="_blank" rel="noopener noreferrer">Official Documentation</a></li>
<li><strong>Laplacian Variance</strong>: <a href="https://pyimagesearch.com/2015/09/07/blur-detection-with-opencv/" target="_blank" rel="noopener noreferrer">PyImageSearch Blur Detection Tutorial</a></li>
</ul>]]></content>
        <author>
            <name>Aman Kumar Singh</name>
            <uri>https://github.com/amankumarsingh77</uri>
        </author>
        <category label="video-processing" term="video-processing"/>
        <category label="video clips" term="video clips"/>
        <category label="video cuts" term="video cuts"/>
        <category label="python" term="python"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weekly learnings: Week1]]></title>
        <id>https://blog.vertexcover.io/learnings/2025-10-ranjan-week1</id>
        <link href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week1"/>
        <updated>2025-10-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[{/ truncate /}]]></summary>
        <content type="html"><![CDATA[
<p>Container checkpoint and restore is a facility by which any running Linux container is saved to memory
and later restored at a later time from the same point at which the checkpoint was created. This restore
is not limited to a single device and can also be in a different remote computer.</p>
<p>This was a project started by some "mad russians", and later merged into Linux Kernel, and is called
<a href="https://criu.org/Main_Page" target="_blank" rel="noopener noreferrer"><code>Checkpoint / Restore in Userspace (CRIU)</code></a>. The sheer idea of saving a process that is currently
running and restoring it later in time is why this process was called mad, much like how the cryogenic
sleep for humans is considered a fiction. Infact, this feature comes with lots of limitations mentioned
later. However, this is not an unproven technology. Such a thing has been done with VMs in the past.
Despite all the limitations and issues that might come up, it's still widely used for the simple fact that
it expedites the startup process.</p>
<p>To create a checkpoint we have to create what is known as a container memory snapshot.
A Container memory snapshot is when we basically take a copy of the entire state of a Linux Container.
For this we need to copy the entire container's filesystem, and process tree. Process tree itself contains
all the memory mappings, file descriptor tables, registers, environment variables, process IDs, etc.</p>
<p>Before <code>CRIU</code> was officially available, to create such a snapshot, it was necessary for users to maintain
their own custom variant of the kernel with required features. However, with <code>CRIU</code> available in the mainline
Linux Kernel, most of the container runtimes now do offer this facility. Of particular mention is <code>gVisor</code>. The
container runtime utility, <code>runsc</code> which stands for <code>run sandboxed container</code>, to it's counterpart <code>runc</code>, has
added functionality for checkpoint and restore. Given that <code>gVisor</code> has a usermode kernel functionality, it can
infact, offer more granularity and features for checkpoint and restore.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="limitations">Limitations<a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week1#limitations" class="hash-link" aria-label="Direct link to Limitations" title="Direct link to Limitations" translate="no">​</a></h2>
<ul>
<li>While the restore can be made in different computer, it has to mimic the original system as much as possible. Otherwise the invariants that program expect to be maintained will be broken, and can lead to some nasty surprises down the line.</li>
<li>The CPU that the restore is made on has to match the instruction set, where the snapshot was taken, otherwise there can be runtime issues with invalid opcode.</li>
<li>A container that utilizes GPU, is sensitive to differences in NVIDIA driver versions and in addition to container runtime versions.</li>
<li>Programs need to account for the fact that the machine IP might change in between restore.</li>
<li>A Problem documented in Modal documentation is that, there are some functions in <code>torch.cuda</code> that after restoring from snapshot will initialize CUDA as having zero GPU devices. The only fix is to reinitialize <code>torch.cuda</code> again.</li>
<li>In particular, when loading a huge snapshot, there is a significant CPU pressure as hundreds of 4KiB pages are getting loaded into memory. Such a particular workload is particularly affected by <a href="https://blog.vertexcover.io/learnings/2025-10-ranjan-week1#cpu-stalls">CPU Stalls</a>.</li>
</ul>
<h1>CPU Stalls</h1>
<p>To explain a CPU stall, we first need to understand that any given process is either running on the CPU or it's not.
There can never be in between. So what happens when we have 3 processes each granted 0.3 of CPU running on the system.</p>
<p>For the above process, lets make a few assumptions. First is our CPU currently only has a single core and a single thread. Now, it's not really possible for us to divide this thread into 0.3 sections and grant each of the process
running a section. As previously stated, a process is either running or not running, and when it is running it
utilizes 100% of the thread and when it's not running it utilizes 0% of the thread. So instead, CPU makes the
division in time instead. For our example, lets consider that the CPU segments 100ms of CPU time window. So,
with our 3 processes, in this 100ms window, each process gets 30ms of execution time, with the last 10ms being
wasted and non of our processes running. Again when a new 100ms window is created all 3 process are allowed to continue their run.</p>
<p>Now, the issue is if you consider a compute intensive workload, it would really benefit off of that extra 10ms of
CPU time, but currently the way Linux schedular works, and also how the default CPU limits on pods by
kubernetes works, each of the process are allocated equal precedence. Hence, for performance critical processes,
it makes sense to also tune your application to get more CPU time.</p>
<p>However, in real world, we don't have a single CPU core, and most commercial CPU's nowadays offer capabilities for running 2 threads. Also of note, most of our applications when parallelized, will spawn additional threads along
with the main thread inside the running process. However, the CPU time granted to each is still at process level.
That means, if say our hypothetical application has 3 threads each running in the same CPU time window, now each of
our thread will get 10ms of actual CPU time down from 30ms of time our single thread was getting. The problem is worsened if we have 10 threads and somehow all 10 threads are granted run in the same time, in different cores, then
each thread only gets about 3ms of worktime.</p>
<p>This situation of having potentially adequate CPU power, but still being unable to utilize 100% of the CPU for
compute is known as CPU stall.</p>
<p>In a single thread situation, the best way to deal with this issue is to grant higher priority to the process to
allow it to gain more CPU time. And in the case of multi threaded situation, infact it's actually much more
beneficial to pin the process to a certain CPU core. Infact, many games actually see quite a significant performance
boost when their processes are pinned to a few cores rather than allowing them access to all the cores.</p>
<h1>Making <code>syscalls</code> in Linux</h1>
<p>Most of the program we write, ultimately have to make a <code>syscall</code> to do any operation on a system. Understandably, I
had a misconception that the <code>syscalls</code> are themselves exposed over <code>C-API</code> and that any language that wishes to make
a <code>syscall</code> had to at minimum link to a lower level <code>C library</code> like <code>libc</code> that does the work for them. However,
a particular note was we can have <code>golang</code> applications without <code>C-go</code>. While at the time, I hadn't connected the
dots, I was recently watching some video on getting the smallest kernel, and there I chanced upon the fact that to
make a <code>syscall</code> you don't really need to bind to <code>C library</code>. You just need to be able to emit specific assembly instructions.</p>
<p>A <code>syscall</code> is triggered by writing the particular <code>syscall</code> number into a particular register. Then calling the
<code>syscall</code>  instruction in CPU. This internally triggers a trap request, which is captured by Kernel.</p>
<p>Given that it's assembly code, the following description is for how to perform a <code>syscall</code> in Linux, particular
in x86_64 system.</p>
<ul>
<li>
<p>First place the system call number into the <code>rax</code> register. <code>write syscall</code> is for instance number 1, and <code>read syscall</code> is number 0. For more <code>syscall</code> numbers visit <a href="https://elixir.bootlin.com/linux/v6.13/source/arch/x86/entry/syscalls/syscall_64.tbl" target="_blank" rel="noopener noreferrer">here</a>.</p>
</li>
<li>
<p>Place the arguments for the system call into the designated registers,</p>
<ul>
<li>
<p><code>rdi</code> (first argument)</p>
</li>
<li>
<p><code>rsi</code> (second argument)</p>
</li>
<li>
<p><code>rdx</code> (third argument)</p>
</li>
<li>
<p><code>r10</code> (fourth argument)</p>
</li>
<li>
<p><code>r8</code> (fifth argument)</p>
</li>
<li>
<p><code>r9</code> (sixth argument)</p>
<p>This order is specified by the calling convention.</p>
</li>
</ul>
</li>
<li>
<p>Invoke the systemcall by executing the <code>syscall</code> instruction.</p>
</li>
<li>
<p>The return value is placed inside <code>rax</code>.</p>
</li>
</ul>
<h1>Some tools used to deploy model</h1>
<ul>
<li>
<p><a href="https://www.ray.io/" target="_blank" rel="noopener noreferrer">ray</a> Allows for distributed GPU computation</p>
<ul>
<li><a href="https://docs.ray.io/en/latest/cluster/kubernetes/index.html" target="_blank" rel="noopener noreferrer">kuberay</a> to deploy ray in kubernetes</li>
</ul>
</li>
<li>
<p><a href="https://www.kubeflow.org/" target="_blank" rel="noopener noreferrer">Kubeflow</a></p>
<p>A CNCF (Cloud Native Computing Formation) project, which is the foundation of tools for AI Platforms on Kubernetes. Of particular note is that recently in a conference, Ubucon, a speaker was telling that kubeflow is almost an industry standard for deploying AI in kubernetes.</p>
</li>
</ul>]]></content>
        <author>
            <name>Ranjan Ojha</name>
            <uri>https://github.com/hungerarray</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Video Cutter - Week 1 Learnings]]></title>
        <id>https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1</id>
        <link href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1"/>
        <updated>2025-01-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Been working on this video cutting tool that uses AI to find optimal cut points. Some things worked, some things I had to completely rewrite. Here's what went down.]]></summary>
        <content type="html"><![CDATA[<p>Been working on this video cutting tool that uses AI to find optimal cut points. Some things worked, some things I had to completely rewrite. Here's what went down.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="misunderstood-the-problem-statement">Misunderstood the problem statement<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#misunderstood-the-problem-statement" class="hash-link" aria-label="Direct link to Misunderstood the problem statement" title="Direct link to Misunderstood the problem statement" translate="no">​</a></h2>
<p>Built this whole <code>find_optimal_cut_point()</code> function that finds the optimal cutpoint in a video considering the Start point and End Point given by the user. Used Whisper for speech detection, OpenCV for scene changes, added motion analysis. Worked great.</p>
<p>Problem: Understood the problem statement wrong. It was "Find the optimal frame to cut near the timestamp that the user gives". Which means that the user already knows where to cut but is not precise at a frame level, So we just ask for the estimated timestamp and then look around to find the best frame to cut.</p>
<p>Learnings : Always clarify the problem statement by repeating it to the person. So you both are on the same page.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="weighted-scoring-doesnt-work-for-hard-constraints">Weighted scoring doesn't work for hard constraints<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#weighted-scoring-doesnt-work-for-hard-constraints" class="hash-link" aria-label="Direct link to Weighted scoring doesn't work for hard constraints" title="Direct link to Weighted scoring doesn't work for hard constraints" translate="no">​</a></h2>
<p>First version used a points system: sentence boundary +40pts, pause +30pts, scene change +30pts, etc. Add them up, pick highest score.</p>
<p>Bug: System kept cutting mid-word because a scene change (30pts) + low motion (20pts) outscored a sentence boundary (40pts) by itself.</p>
<p>Realized some rules aren't negotiable. You literally cannot cut while someone is speaking. It's not a preference, it's a constraint.</p>
<p>Rewrote to use strict priority filtering:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Priority 1: Remove all frames mid-speech (absolute)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Priority 2: Remove frames with motion &gt; 2.5 (strict)  </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Priority 3: Remove frames with blinks/open mouth (best effort)</span><br></span></code></pre></div></div>
<p>Each filter runs sequentially. If all frames fail a priority, fallback to previous level. This will be changed as if there are no frames left after filtering then its not a good range to extract any cut point.</p>
<p>If you catch yourself using weighted scoring to "compensate" for bad choices, you probably need filters instead.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="caching-saves-90-seconds-per-request">Caching saves 90 seconds per request<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#caching-saves-90-seconds-per-request" class="hash-link" aria-label="Direct link to Caching saves 90 seconds per request" title="Direct link to Caching saves 90 seconds per request" translate="no">​</a></h2>
<p>Whisper transcription: ~60s for 5min video. Scene detection: ~30s. Runs on every cut request.</p>
<p>People want multiple clips from the same video. Transcribing the same video 5 times = 5 minutes wasted.</p>
<p>Added basic caching with video file hashes. First cut takes 90s, subsequent cuts from same video take 0.2s. Just stores the analysis results in <code>.video_cache/</code>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> FastPreprocessingPipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">use_cache</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">analysis </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">preprocess_video</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"video.mp4"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Slow first time, instant after</span><br></span></code></pre></div></div>
<p>Should've done this from day one.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="integration-is-80-of-the-work">Integration is 80% of the work<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#integration-is-80-of-the-work" class="hash-link" aria-label="Direct link to Integration is 80% of the work" title="Direct link to Integration is 80% of the work" translate="no">​</a></h2>
<p>Individual pieces are straightforward:</p>
<ul>
<li>Whisper gives word timestamps</li>
<li>OpenCV detects scene changes</li>
<li>Optical flow tracks motion</li>
<li>MediaPipe finds faces/blinks</li>
<li>Librosa analyzes audio</li>
</ul>
<p>Making them work together without contradicting each other is some interesting job which I am still figuring out.</p>
<p>Had to add a validation layer that checks if the selected range:</p>
<ul>
<li>Has complete sentences (not cut mid-thought)</li>
<li>Doesn't have jarring visual jumps</li>
<li>Maintains topic coherence</li>
<li>Has stable audio (no clipping)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-broken-right-now">What's broken right now<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#whats-broken-right-now" class="hash-link" aria-label="Direct link to What's broken right now" title="Direct link to What's broken right now" translate="no">​</a></h2>
<p>Face detection in "full" mode takes forever. Like 70% of total processing time. Need to profile this.</p>
<p>Semantic analysis doesn't actually detect topic boundaries well. Using basic sentence embeddings but they're not good enough. Might need to try a different approach or just remove this feature.</p>
<p>Error messages are terrible. When the system can't find a good cut point it just says "Priority 2 failed" which means nothing to users.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="stuff-that-actually-helped">Stuff that actually helped<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#stuff-that-actually-helped" class="hash-link" aria-label="Direct link to Stuff that actually helped" title="Direct link to Stuff that actually helped" translate="no">​</a></h2>
<p>Whisper's tiny model works better than expected. Word-level timestamps are pretty accurate even with background noise and is fast enough. Might be because we are focusing on talking head/podcast videos.</p>
<p>Cyclopts for CLI was good. Better than argparse, handles nested commands cleanly.</p>
<p>PySceneDetect saved time. Didn't have to write scene detection from scratch.</p>
<p>MediaPipe face detection works but is slow. Might need to sample frames instead of processing every single one.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-i-shouldve-done-differently">What I should've done differently<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#what-i-shouldve-done-differently" class="hash-link" aria-label="Direct link to What I should've done differently" title="Direct link to What I should've done differently" translate="no">​</a></h2>
<p>Should've built the CLI interface first. Forces you to think about actual usage before implementation.</p>
<p>Should've started with the simplest possible version - just find pauses and cut there. Then add complexity. Instead I went straight to "multi-modal AI fusion" which took hours.</p>
<p>Should've added batch evaluation for accuracy testing from the start. Added it late and it's now one of the most useful features.</p>
<p>Should've added way more logging. When a cut looks wrong I have no idea why the system chose it. About to do it next week.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="random-win">Random win<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#random-win" class="hash-link" aria-label="Direct link to Random win" title="Direct link to Random win" translate="no">​</a></h2>
<p>The batch evaluation system (process multiple videos, generate accuracy reports) wasn't even planned. Built it for testing. Turns out it's really useful for seeing how the system performs across different video types.</p>
<p>Sometimes the tools you build to test your code end up being features.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next steps<a href="https://blog.vertexcover.io/learnings/2025/01/20/ai-video-cutter-week1#next-steps" class="hash-link" aria-label="Direct link to Next steps" title="Direct link to Next steps" translate="no">​</a></h2>
<p>Need to fix face detection performance. Probably sampling frames instead of processing all of them.</p>
<p>Semantic analysis either needs better models or needs to be removed.</p>
<p>Better error messages so people know why a cut point was chosen or why it failed.</p>
<p>Add logging with jsonl and try to visualize each filter as to how they reject/accept a frame.</p>]]></content>
        <author>
            <name>Aman Kumar Singh</name>
            <uri>https://github.com/amankumarsingh77</uri>
        </author>
        <category label="video-processing" term="video-processing"/>
        <category label="video clips" term="video clips"/>
        <category label="video cuts" term="video cuts"/>
        <category label="whisper" term="whisper"/>
        <category label="python" term="python"/>
    </entry>
</feed>