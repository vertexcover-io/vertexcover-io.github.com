<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-learnings" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">AI Video Cutter - Week 2 Learnings | Blog - Vertexcover</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://blog.vertexcover.io/img/vertexcover.png"><meta data-rh="true" name="twitter:image" content="https://blog.vertexcover.io/img/vertexcover.png"><meta data-rh="true" property="og:url" content="https://blog.vertexcover.io/learnings/2025-10-aman-week2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="AI Video Cutter - Week 2 Learnings | Blog - Vertexcover"><meta data-rh="true" name="description" content="{/ truncate /}"><meta data-rh="true" property="og:description" content="{/ truncate /}"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-10-21T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/amankumarsingh77"><meta data-rh="true" property="article:tag" content="video-processing,video clips,video cuts,python"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://blog.vertexcover.io/learnings/2025-10-aman-week2"><link data-rh="true" rel="alternate" href="https://blog.vertexcover.io/learnings/2025-10-aman-week2" hreflang="en"><link data-rh="true" rel="alternate" href="https://blog.vertexcover.io/learnings/2025-10-aman-week2" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://blog.vertexcover.io/learnings/2025-10-aman-week2","mainEntityOfPage":"https://blog.vertexcover.io/learnings/2025-10-aman-week2","url":"https://blog.vertexcover.io/learnings/2025-10-aman-week2","headline":"AI Video Cutter - Week 2 Learnings","name":"AI Video Cutter - Week 2 Learnings","description":"{/ truncate /}","datePublished":"2025-10-21T00:00:00.000Z","author":{"@type":"Person","name":"Aman Kumar Singh","description":"Software Engineer Intern","url":"https://github.com/amankumarsingh77","image":"https://github.com/amankumarsingh77.png"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://blog.vertexcover.io/learnings","name":"Learnings"}}</script><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Blog - Vertexcover RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Blog - Vertexcover Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JS91KNQLR"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0JS91KNQLR",{})</script>




<link rel="alternate" type="application/rss+xml" href="/learnings/rss.xml" title="Blog - Vertexcover RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/learnings/atom.xml" title="Blog - Vertexcover Atom Feed">
<meta name="generator" content="vertex cover"><link rel="stylesheet" href="/assets/css/styles.9909b52a.css">
<script src="/assets/js/runtime~main.4e5a35ed.js" defer="defer"></script>
<script src="/assets/js/main.22422905.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><link rel="preload" as="image" href="https://github.com/amankumarsingh77.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Vertexcover Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Vertexcover Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Vertexcover</b></a><a class="navbar__item navbar__link" href="/">Blog</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/learnings">Learnings</a><a class="navbar__item navbar__link" href="/about-us">About Us</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/vertexcover-io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All learnings</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/learnings/2025-10-ranjan-week2">Weekly learnings: Week2</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/learnings/2025-10-aman-week2">AI Video Cutter - Week 2 Learnings</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/learnings/2025-10-ranjan-week1">Weekly learnings: Week1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/learnings/2025/01/20/ai-video-cutter-week1">AI Video Cutter - Week 1 Learnings</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">AI Video Cutter - Week 2 Learnings</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-10-21T00:00:00.000Z">October 21, 2025</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/learnings/authors/aksdev"><img class="avatar__photo authorImage_XqGP" src="https://github.com/amankumarsingh77.png" alt="Aman Kumar Singh"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/learnings/authors/aksdev"><span class="authorName_yefp" translate="no">Aman Kumar Singh</span></a></div><small class="authorTitle_nd0D" title="Software Engineer Intern">Software Engineer Intern</small><div class="authorSocials_rSDt"><a href="https://www.linkedin.com/in/aksdev/" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" preserveAspectRatio="xMidYMid" viewBox="0 0 256 256" style="--dark:#0a66c2;--light:#ffffffe6" class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"></path></svg></a><a href="https://github.com/amankumarsingh77" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown">
<p>The original approach relied heavily on fixed thresholds to determine whether a frame was suitable for cutting. For example, we would check if motion was below 2.5 pixels/frame, or if mouth openness was below 0.08 aspect ratio. While this seemed reasonable in theory, several fundamental issues emerged:</p>
<p><strong>The Binary Decision Problem</strong>: Thresholds create hard boundaries - a frame with motion at 2.4 is &quot;good&quot; while one at 2.6 is &quot;bad&quot;. This ignores the fact that quality exists on a spectrum. We were discarding potentially excellent cut points simply because one metric was slightly above threshold, even if all other metrics were perfect.</p>
<p><strong>The Context Blindness Problem</strong>: A threshold of 2.5 pixels/frame might be perfectly fine for one video but completely wrong for another. A talking head video shot on a stabilized camera will have very different motion characteristics than one shot handheld. The threshold approach had no way to understand relative quality within a video&#x27;s context.</p>
<p><strong>The Combinatorial Explosion Problem</strong>: With 5+ metrics (eye openness, motion, expression, pose, sharpness), we faced an impossible tuning challenge. What if a frame had excellent eye openness and stability but slightly high motion? Which threshold should win? We ended up with increasingly complex boolean logic that was brittle and hard to reason about.</p>
<p><strong>The &quot;No Good Frame&quot; Scenario</strong>: In some video segments, no frame passed all thresholds. The system would then either fail completely or pick arbitrarily, defeating the purpose of quality analysis. The threshold approach couldn&#x27;t say &quot;this frame is better than that one&quot; - it could only say &quot;pass&quot; or &quot;fail&quot;.</p>
<p>These limitations made it clear that we needed a fundamentally different approach that could handle relative quality, context-awareness, and graceful degradation.</p>
<h1>Moving to a Pure Ranking Algorithm</h1>
<p>Instead of asking &quot;does this frame pass?&quot;, we now ask &quot;which frame is best?&quot;. The ranking algorithm in <code>try/cut_point_ranker/</code> implements a pure ranking approach with no thresholds whatsoever. Every frame gets scored, and we simply pick the highest-ranked ones.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-factor-scoring-system">Multi-Factor Scoring System<a href="#multi-factor-scoring-system" class="hash-link" aria-label="Direct link to Multi-Factor Scoring System" title="Direct link to Multi-Factor Scoring System" translate="no">​</a></h2>
<p>The ranker combines 5 key metrics with configurable weights:</p>
<ol>
<li>
<p><strong>Eye Openness</strong> - Uses Eye Aspect Ratio (EAR) detection based on Soukupová &amp; Čech (2016). We want eyes fully open, not blinking or partially closed.</p>
</li>
<li>
<p><strong>Motion Stability</strong> - Uses Farneback optical flow to measure frame-to-frame motion. Lower motion is better (inverse scoring).</p>
</li>
<li>
<p><strong>Expression Neutrality</strong> - Analyzes MediaPipe facial blendshapes to detect mouth movement and eyebrow activity. We prefer neutral expressions (inverse scoring).</p>
</li>
<li>
<p><strong>Pose Stability</strong> - Measures head pose deviation from neutral position. Stable head position is better (inverse scoring).</p>
</li>
<li>
<p><strong>Visual Sharpness</strong> - Laplacian variance to ensure the frame isn&#x27;t blurry.</p>
</li>
</ol>
<p>The beauty of weighted scoring is that it allows trade-offs. A frame with perfect eye openness but slightly higher motion can still score well, whereas with thresholds it might have been rejected entirely.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-stage-ranking-pipeline">Multi-Stage Ranking Pipeline<a href="#multi-stage-ranking-pipeline" class="hash-link" aria-label="Direct link to Multi-Stage Ranking Pipeline" title="Direct link to Multi-Stage Ranking Pipeline" translate="no">​</a></h2>
<p>The scoring happens in multiple stages to ensure quality:</p>
<p><strong>Stage 1: Feature Extraction</strong> - Extract all raw metrics from every frame in the time range. This is done in a single pass through the video for efficiency.</p>
<p><strong>Stage 2: Normalization</strong> - Normalize all metrics to [0, 1] range across the entire segment. This is crucial - the normalization happens relative to the video segment being analyzed, making it context-aware.</p>
<p><strong>Stage 3: Quality Gating</strong> - Instead of hard thresholds, we use percentile-based penalties. If a frame&#x27;s expression activity is above the 75th percentile for the segment, it receives a penalty multiplier. The penalty is proportional to how extreme the outlier is, not a binary yes/no.</p>
<p><strong>Stage 4: Local Stability Boost</strong> - Frames that are part of stable sequences (low variance in a 5-frame window) receive a boost multiplier. This rewards temporal coherence.</p>
<p><strong>Stage 5: Context Window Smoothing</strong> - Apply a sliding window average over composite scores. A frame is better if its neighbors are also good, ensuring we don&#x27;t pick an isolated good frame in a bad sequence.</p>
<h1>Research-Based Feature Extraction</h1>
<p>Rather than inventing metrics from scratch, the implementation uses proven computer vision algorithms:</p>
<ul>
<li>
<p><strong>Eye Aspect Ratio (EAR)</strong>: Based on the 2016 paper by Soukupová &amp; Čech for blink detection. Calculates ratio of vertical to horizontal eye landmark distances.</p>
</li>
<li>
<p><strong>Optical Flow</strong>: Uses Farneback dense optical flow, a well-established method for motion estimation in video.</p>
</li>
<li>
<p><strong>MediaPipe FaceMesh</strong>: Google&#x27;s solution providing 478 facial landmarks plus 52 blendshape coefficients for detailed expression analysis.</p>
</li>
<li>
<p><strong>Laplacian Variance</strong>: Standard technique for measuring image sharpness by analyzing high-frequency content.</p>
</li>
</ul>
<h1>Word-Level Pause Detection</h1>
<p>Improved the speech analysis to detect pauses at word-level granularity rather than just sentence boundaries. This allows us to find natural cut points mid-sentence during natural speaking pauses, which is especially important for AI-generated talking head videos where sentences can be quite long.</p>
<p>The transcription analysis now tracks word-level timestamps and identifies pauses between words that are long enough to indicate a natural break in speech flow.</p>
<h1>Adaptive Padding for Cut Points</h1>
<p>Implemented an adaptive padding calculator that analyzes visual stability around a cut point to determine optimal padding amounts. Instead of fixed padding values, the system now:</p>
<ul>
<li>Analyzes frame similarity before/after the cut point</li>
<li>Measures face movement and general motion</li>
<li>Detects scene changes that would affect padding needs</li>
</ul>
<p>This ensures we add just enough padding for smooth transitions without including unstable or transitional frames, with padding amounts ranging from configured minimum to maximum based on actual video content stability.</p>
<h1>References and Resources</h1>
<ul>
<li><strong>Eye Aspect Ratio (EAR)</strong>: <a href="http://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf" target="_blank" rel="noopener noreferrer">Real-Time Eye Blink Detection using Facial Landmarks</a></li>
<li><strong>Farneback Optical Flow</strong>: <a href="http://www.diva-portal.org/smash/get/diva2:273847/FULLTEXT01.pdf" target="_blank" rel="noopener noreferrer">Two-Frame Motion Estimation Based on Polynomial Expansion</a></li>
<li><strong>MediaPipe FaceMesh</strong>: <a href="https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker" target="_blank" rel="noopener noreferrer">Official Documentation</a></li>
<li><strong>Laplacian Variance</strong>: <a href="https://pyimagesearch.com/2015/09/07/blur-detection-with-opencv/" target="_blank" rel="noopener noreferrer">PyImageSearch Blur Detection Tutorial</a></li>
</ul></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/learnings/tags/video-processing">video-processing</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/learnings/tags/video-clips">video clips</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/learnings/tags/video-cuts">video cuts</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/learnings/tags/python">python</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/learnings/2025-10-ranjan-week2"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Weekly learnings: Week2</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/learnings/2025-10-ranjan-week1"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Weekly learnings: Week1</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#multi-factor-scoring-system" class="table-of-contents__link toc-highlight">Multi-Factor Scoring System</a></li><li><a href="#multi-stage-ranking-pipeline" class="table-of-contents__link toc-highlight">Multi-Stage Ranking Pipeline</a></li></ul></div></div></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/vertexcover-io" target="_blank" rel="noopener noreferrer" class="footer__link-item footer-github-link" aria-label="GitHub repository">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Codeshelf, Inc.</div></div></div></footer></div>
</body>
</html>