<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Blog - Vertexcover Blog</title>
        <link>https://blog.vertexcover.io</link>
        <description>Blog - Vertexcover Blog</description>
        <lastBuildDate>Sun, 23 Nov 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Building SceneFlow: The Intelligent Video Cutter]]></title>
            <link>https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive</link>
            <guid>https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive</guid>
            <pubDate>Sun, 23 Nov 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[SceneFlow isn't just a video cutter, it's an intelligent editor. By combining signal processing with Multimodal AI, it finds the perfect cut points, ensuring your videos never end with awkward freezes, mid-sentence chops, or blinking eyes.]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p><strong>SceneFlow</strong> isn't just a video cutter, it's an intelligent editor. By combining signal processing with <strong>Multimodal AI</strong>, it finds the <em>perfect</em> cut points, ensuring your videos never end with awkward freezes, mid-sentence chops, or blinking eyes.</p></div></div>
<p>If you've ever worked with AI-generated videos, you know the problem. The content is great, but the endings are... weird. The avatar freezes, stares blankly into the soul of the viewer, or cuts off mid-breath.</p>
<div style="display:flex;flex-direction:column;align-items:center;margin:20px 0"><video width="100%" style="max-width:200px;border-radius:8px" controls=""><source src="/video/before_last3s.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video><p style="margin-top:10px;font-style:italic;color:var(--ifm-color-emphasis-600)">Notice the awkward movement of the subject at the end of this AI-generated video</p></div>
<p>To make these videos production-ready, you have to manually trim that awkward tail. For one video, it's fine. For 1,000 personalized outreach videos? It's a nightmare.</p>
<p>We wanted to automate this. But simple tools like <code>ffmpeg</code> or basic silence detectors aren't enough. They don't "see" the video. They don't know if an avatar's face looks unnatural.</p>
<p>So we built <strong>SceneFlow</strong>.</p>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-did-we-build-sceneflow">Why did we build SceneFlow<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#why-did-we-build-sceneflow" class="hash-link" aria-label="Direct link to Why did we build SceneFlow" title="Direct link to Why did we build SceneFlow" translate="no">​</a></h2>
<p>It started with a client project. We were working with AI-generated avatar videos, hundreds of them for personalized outreach campaigns. The content itself was impressive. The avatars looked natural, the scripts were on point, and the lip-sync was nearly flawless.</p>
<p>But there was one consistent problem: <strong>the endings were terrible</strong>.</p>
<p>Every video would finish with the avatar in some awkward state, mid-breath, eyes half-closed, mouth slightly open, or frozen in an unnatural pose. For a single video, you'd just trim it manually and move on. But when you're processing hundreds of videos that need to be stitched together into sequences, those bad endings become a real problem. The transitions between clips looked jarring and unprofessional.</p>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;margin:20px 0"><div style="text-align:center"><p><strong>Actual Cut Frame</strong></p><img src="https://blog.vertexcover.io/img/before_last_frame.jpg" alt="Actual cut frame - awkward ending" style="max-width:250px;border-radius:8px"><p style="margin-top:8px;font-style:italic;color:var(--ifm-color-emphasis-600);font-size:0.9em">Awkward pose, eyes half-closed</p></div><div style="text-align:center"><p><strong>Expected Cut Frame</strong></p><img src="https://blog.vertexcover.io/img/before_last_1.5s.jpg" alt="Expected cut frame - natural ending" style="max-width:250px;border-radius:8px"><p style="margin-top:8px;font-style:italic;color:var(--ifm-color-emphasis-600);font-size:0.9em">Natural expression, proper ending</p></div></div>
<p>We searched for existing tools. Surely someone had solved this, right?</p>
<p>We tried silence detectors, they'd cut during pauses, but the avatar might still be moving. We experimented with motion-based cutters, they'd find still moments, but the face might look weird. Nothing understood the full picture: audio <em>and</em> video <em>and</em> facial expressions all at once.</p>
<p>So we built our own solution.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-core-intuition-what-makes-a-good-cut">The Core Intuition: What Makes a "Good" Cut?<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#the-core-intuition-what-makes-a-good-cut" class="hash-link" aria-label="Direct link to The Core Intuition: What Makes a &quot;Good&quot; Cut?" title="Direct link to The Core Intuition: What Makes a &quot;Good&quot; Cut?" translate="no">​</a></h2>
<p>Before writing any code, we asked ourselves a simple question: <em>What does a human editor actually look for when trimming a video?</em></p>
<p>Think about it. When you manually trim a video, you don't just look at the waveform. You <em>watch</em> the person. You wait for them to finish their sentence. You check if their eyes are open. You make sure they're not mid-gesture. You look for that brief moment of stillness where everything feels... complete.</p>
<p>That's the intuition. <strong>A good cut happens when multiple signals align</strong>: the speaker has stopped talking, their face is composed, their body is still, and visually, the frame looks intentional rather than accidental.</p>
<p>The problem is that these signals don't always agree. The audio might be silent, but the speaker is still moving. The face might look great, but they're mid-word. Traditional tools optimize for <em>one</em> signal and ignore the rest.</p>
<p>SceneFlow's approach is different: <strong>treat each signal as a vote, and find the moment where the most votes align.</strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-four-pillars-of-a-clean-cut">The Four Pillars of a Clean Cut<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#the-four-pillars-of-a-clean-cut" class="hash-link" aria-label="Direct link to The Four Pillars of a Clean Cut" title="Direct link to The Four Pillars of a Clean Cut" translate="no">​</a></h3>
<p>We identified four signals that together define a "natural" cut point:</p>
<p><strong>1. Speech Boundaries</strong></p>
<p>Are they still talking? We use <strong>Silero VAD</strong> (Voice Activity Detection) to detect exactly when speech ends. It gives us millisecond-accurate timestamps without needing full transcription. However, the VAD timestamps are not always very accurate, which we'll discuss later in this blog.</p>
<p><strong>2. Motion Stillness</strong></p>
<p>Are they moving? We use optical flow to track pixel movement between frames. When the motion drops to the lowest 25%, we've found a moment of stillness.</p>
<p><strong>3. Facial Composure</strong></p>
<p>Do they look natural? Using <strong>InsightFace</strong>, we detect blinks (EAR), mouth openness (MAR), and head angle. If someone's mid-blink or has their mouth open, it's not a good frame.</p>
<p><strong>4. Visual Stability</strong></p>
<p>Is there a scene change? We detect hard cuts, fades, and dissolves. Cutting right before a transition looks accidental; cutting after looks intentional.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="handling-different-scenarios">Handling Different Scenarios<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#handling-different-scenarios" class="hash-link" aria-label="Direct link to Handling Different Scenarios" title="Direct link to Handling Different Scenarios" translate="no">​</a></h3>
<p>SceneFlow is optimized for two primary content types:</p>
<p><strong>Talking Head / Avatar Videos</strong> — Close-up shots with one speaker, minimal camera movement. Facial analysis dominates here. We're strict about mouth closure, eye state, and subtle expressions. Motion thresholds are tight because any movement is noticeable in a close-up.</p>
<p><strong>Podcasts &amp; Interviews</strong> — Similar to talking heads, but with wider frames and more natural speech patterns. We weight speech boundaries heavily and allow slightly more tolerance for motion.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-sceneflow-implements-this">How SceneFlow Implements This<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#how-sceneflow-implements-this" class="hash-link" aria-label="Direct link to How SceneFlow Implements This" title="Direct link to How SceneFlow Implements This" translate="no">​</a></h2>
<p>Here's the high-level flow:</p>
<p><strong>Step 1: Find the speech end</strong> — When you provide a video, we first run Silero VAD to detect the end timestamp of the last speech segment. This gives us a starting point for analysis.</p>
<p><strong>Step 2: Analyze frames visually</strong> — From that timestamp, we analyze each frame for:</p>
<ul>
<li class=""><strong>EAR</strong> (Eye Aspect Ratio) — Are they blinking?</li>
<li class=""><strong>MAR</strong> (Mouth Aspect Ratio) — Is their mouth open?</li>
<li class=""><strong>Motion</strong> — Is the subject in motion?</li>
<li class=""><strong>Stability</strong> — Is the frame stable?</li>
</ul>
<p><strong>Step 3: Score and rank</strong> — Each frame gets a composite score based on these metrics. We then rank all frames from 1 to n, where rank 1 is the best candidate and rank n is the worst.</p>
<p><strong>Step 4: Select the best</strong> — The highest-ranked frame becomes the cut point.</p>
<p>The ranking prioritizes frames where the speaker has finished talking, isn't blinking, has their mouth closed, and is relatively still. If no perfect frame exists, we pick the best available.</p>
<img src="https://blog.vertexcover.io/img/sceneflow.png" alt="SceneFlow Architecture" style="width:70%;display:block;margin:0 auto">
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="real-world-challenges-we-faced">Real-World Challenges We Faced<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#real-world-challenges-we-faced" class="hash-link" aria-label="Direct link to Real-World Challenges We Faced" title="Direct link to Real-World Challenges We Faced" translate="no">​</a></h2>
<p>Building SceneFlow wasn't just about wiring up APIs. We hit some genuinely hard problems.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-vad-timestamp-inaccuracy-problem">The VAD Timestamp Inaccuracy Problem<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#the-vad-timestamp-inaccuracy-problem" class="hash-link" aria-label="Direct link to The VAD Timestamp Inaccuracy Problem" title="Direct link to The VAD Timestamp Inaccuracy Problem" translate="no">​</a></h3>
<p>Silero VAD's end timestamps are always a few frames too late. This means we're analyzing extra frames where the speaker is already quiet, potentially missing the perfect cut point.</p>
<p><strong>Our Fix: Energy-Based Refinement</strong></p>
<p>We use VAD as a rough guide, then look backwards for a sudden energy drop (≥8 dB) in the audio. This drop marks the actual speech end, giving us frame-level precision and ensuring we never miss that ideal cut moment.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-mid-gesture-problem">The "Mid-Gesture" Problem<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#the-mid-gesture-problem" class="hash-link" aria-label="Direct link to The &quot;Mid-Gesture&quot; Problem" title="Direct link to The &quot;Mid-Gesture&quot; Problem" translate="no">​</a></h3>
<p>Optical flow is great at detecting <em>large</em> motion, but bad at detecting <em>subtle</em> gestures. A speaker might be perfectly still from the waist up, but their hand is moving off-screen. Early versions of SceneFlow would happily cut during these moments, making the final frame look awkward.</p>
<p>We fixed this by implementing <strong>region-of-interest (ROI) weighting</strong>. The algorithm gives more weight to motion near the speaker's face and less weight to the edges of the frame. Now it can distinguish between "speaker is gesturing" and "a car drove by in the background."</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="when-to-use-sceneflow">When to Use SceneFlow<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#when-to-use-sceneflow" class="hash-link" aria-label="Direct link to When to Use SceneFlow" title="Direct link to When to Use SceneFlow" translate="no">​</a></h2>
<p>SceneFlow is designed for high-quality, automated video workflows. It excels in situations where precision and polish matter.</p>
<ul>
<li class=""><strong>AI Avatar Videos</strong>: Perfect for cleaning up the awkward starts and stops of generated content from platforms like HeyGen or Synthesia.</li>
<li class=""><strong>Webinar &amp; Podcast Clips</strong>: Extracting short, punchy clips from long-form content without cutting off speakers mid-sentence.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="see-it-in-action">See it in Action<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#see-it-in-action" class="hash-link" aria-label="Direct link to See it in Action" title="Direct link to See it in Action" translate="no">​</a></h2>
<p>Here's a comparison of a raw AI-generated video versus one processed by SceneFlow. Notice how the "After" clip ends naturally without the awkward freeze.</p>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;margin-top:30px"><div style="text-align:center"><p><strong>Before (Raw)</strong></p><video width="100%" style="max-width:300px;border-radius:8px" controls=""><source src="/video/example_input4.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div><div style="text-align:center"><p><strong>After (SceneFlow)</strong></p><video width="100%" style="max-width:300px;border-radius:8px" controls=""><source src="/video/example_output4.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div></div>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;margin-top:30px"><div style="text-align:center"><p><strong>Before (Raw)</strong></p><video width="100%" style="max-width:300px;border-radius:8px" controls=""><source src="/video/example_input2.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div><div style="text-align:center"><p><strong>After (SceneFlow)</strong></p><video width="100%" style="max-width:300px;border-radius:8px" controls=""><source src="/video/example_output2.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div></div>
<div style="display:flex;gap:20px;justify-content:center;flex-wrap:wrap;margin-top:30px"><div style="text-align:center"><p><strong>Before (Raw)</strong></p><video width="100%" style="max-width:300px;border-radius:8px" controls=""><source src="/video/example_input3.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div><div style="text-align:center"><p><strong>After (SceneFlow)</strong></p><video width="100%" style="max-width:300px;border-radius:8px" controls=""><source src="/video/example_output3.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-to-use-it">How to Use It<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#how-to-use-it" class="hash-link" aria-label="Direct link to How to Use It" title="Direct link to How to Use It" translate="no">​</a></h2>
<p>SceneFlow is built as a powerful CLI tool that fits right into your existing pipelines.</p>
<p>Check out the project on GitHub: <a href="https://github.com/vertexcover-io/sceneflow" target="_blank" rel="noopener noreferrer" class="">https://github.com/vertexcover-io/sceneflow</a></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="installation">Installation<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#installation" class="hash-link" aria-label="Direct link to Installation" title="Direct link to Installation" translate="no">​</a></h3>
<p>Install SceneFlow via pip:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install sceneflow</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="basic-usage">Basic Usage<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#basic-usage" class="hash-link" aria-label="Direct link to Basic Usage" title="Direct link to Basic Usage" translate="no">​</a></h3>
<p>Find the optimal cut point in your video:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Find the best cut point timestamp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sceneflow input.mp4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Save the trimmed video (requires ffmpeg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sceneflow input.mp4 --output cut_video.mp4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Get top 5 candidate cut points with scores</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sceneflow input.mp4 --top-n 5</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://blog.vertexcover.io/ai-video-cutter-technical-deep-dive#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>SceneFlow works exceptionally well with AI-generated podcasts and talking head videos, delivering clean, professional cuts every time.</p>
<p>Our goal is to expand this into a comprehensive rough-cut tool for real-world podcasts, making it the go-to solution for automated video editing.</p>
<p>The code is open source. Give it a spin and stop scrubbing through timelines manually.</p>]]></content:encoded>
            <category>Video Processing</category>
            <category>AI</category>
            <category>Python</category>
            <category>Automation</category>
        </item>
        <item>
            <title><![CDATA[Why Node.js and Python Don't Use Linux's Native Async I/O API]]></title>
            <link>https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio</link>
            <guid>https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio</guid>
            <pubDate>Sat, 08 Nov 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Linux provides a native Asynchronous I/O (AIO) API that should theoretically allow true background file operations. Yet popular frameworks like Node.js and Python's asyncio avoid it entirely, relying instead on thread pools with blocking I/O. Why? The answer reveals important lessons about API design, cross-platform compatibility, and the gap between theoretical elegance and practical engineering. The future may lie in io_uring, a modern interface that addresses many of AIO's shortcomings.]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>Linux provides a native Asynchronous I/O (AIO) API that should theoretically allow true background file operations. Yet popular frameworks like Node.js and Python's asyncio avoid it entirely, relying instead on thread pools with blocking I/O. Why? The answer reveals important lessons about API design, cross-platform compatibility, and the gap between theoretical elegance and practical engineering. The future may lie in io_uring, a modern interface that addresses many of AIO's shortcomings.</p></div></div>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-puzzle">The Puzzle<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#the-puzzle" class="hash-link" aria-label="Direct link to The Puzzle" title="Direct link to The Puzzle" translate="no">​</a></h2>
<p>If you've worked with async programming in Node.js or Python, you know that file I/O operations like <code>fs.readFile()</code> or <code>aiofiles.read()</code> don't truly run in the background at the kernel level. Instead, these frameworks use thread pools to simulate asynchronous behavior—spawning threads that make blocking system calls while the main event loop continues.</p>
<p>This seems wasteful. Why maintain a thread pool when Linux provides a dedicated AIO API specifically designed for asynchronous I/O? The answer isn't obvious, and understanding it requires examining how different I/O models actually work in practice.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="three-io-models-in-linux">Three I/O Models in Linux<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#three-io-models-in-linux" class="hash-link" aria-label="Direct link to Three I/O Models in Linux" title="Direct link to Three I/O Models in Linux" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-blocking-io">1. Blocking I/O<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#1-blocking-io" class="hash-link" aria-label="Direct link to 1. Blocking I/O" title="Direct link to 1. Blocking I/O" translate="no">​</a></h3>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token class-name">ssize_t</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">buf</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">size_t</span><span class="token plain"> count</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">ssize_t</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">buf</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">size_t</span><span class="token plain"> count</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<p><strong>Behavior:</strong> The process halts until the operation completes. If data isn't available, the call blocks the entire thread. Simple to use but creates concurrency bottlenecks.</p>
<p><strong>Use case:</strong> Single-threaded programs or situations where blocking is acceptable.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-non-blocking-io">2. Non-Blocking I/O<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#2-non-blocking-io" class="hash-link" aria-label="Direct link to 2. Non-Blocking I/O" title="Direct link to 2. Non-Blocking I/O" translate="no">​</a></h3>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">fcntl</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> cmd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">long</span><span class="token plain"> arg</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// Set O_NONBLOCK</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">ssize_t</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">buf</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">size_t</span><span class="token plain"> count</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">ssize_t</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">buf</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">size_t</span><span class="token plain"> count</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<p><strong>Behavior:</strong> When you set the <code>O_NONBLOCK</code> flag on a file descriptor, <code>read</code> and <code>write</code> return immediately. If the operation can't complete, they return <code>-1</code> with <code>errno</code> set to <code>EAGAIN</code> or <code>EWOULDBLOCK</code>.</p>
<p><strong>The Critical Caveat:</strong> This works perfectly for network sockets, pipes, and device files, but regular file I/O ignores the non-blocking flag. Opening a file with <code>O_NONBLOCK</code> has essentially no effect—file reads and writes block regardless. This is a fundamental limitation of how the Linux VFS (Virtual File System) layer interacts with filesystems.</p>
<p><strong>Integration Pattern:</strong> Non-blocking I/O typically pairs with multiplexing mechanisms:</p>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">// Pseudo-code for event loop</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">while</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">true</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> ready </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">epoll_wait</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">epoll_fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> events</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> MAX_EVENTS</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> timeout</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> i </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> i </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain"> ready</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> i</span><span class="token operator" style="color:#393A34">++</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">events</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">events </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> EPOLLIN</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic">// Socket is readable, call read()</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">events</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">events </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> EPOLLOUT</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic">// Socket is writable, call write()</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<p><strong>Why This Matters:</strong> Since file I/O blocks regardless of the flag, async frameworks must use thread pools for disk operations while using non-blocking I/O for network operations. This hybrid approach adds complexity but is necessary given the limitations.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-posix-asynchronous-io-aio">3. POSIX Asynchronous I/O (AIO)<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#3-posix-asynchronous-io-aio" class="hash-link" aria-label="Direct link to 3. POSIX Asynchronous I/O (AIO)" title="Direct link to 3. POSIX Asynchronous I/O (AIO)" translate="no">​</a></h3>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;aio.h&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">aio_read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">aiocb</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">aio_write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">aiocb</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">aio_error</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">aiocb</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">ssize_t</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">aio_return</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">aiocb</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<p><strong>Behavior:</strong> These functions initiate truly asynchronous operations. You submit a request via <code>aio_read</code> or <code>aio_write</code>, which returns immediately. Later, you check completion status with <code>aio_error</code> and retrieve results with <code>aio_return</code>.</p>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">// Example usage</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">aiocb</span><span class="token plain"> cb</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">memset</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">sizeof</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">aio_fildes </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">aio_buf </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> buffer</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">aio_nbytes </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> size</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">aio_offset </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> offset</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">aio_read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// Initiates async read, returns immediately</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// Later, check if complete</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">while</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token function" style="color:#d73a49">aio_error</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> EINPROGRESS</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// Do other work</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">ssize_t</span><span class="token plain"> bytes_read </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">aio_return</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">cb</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<p>On paper, this looks ideal. The kernel handles I/O in the background while your application continues executing. So why don't frameworks use it?</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-frameworks-avoid-posix-aio">Why Frameworks Avoid POSIX AIO<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#why-frameworks-avoid-posix-aio" class="hash-link" aria-label="Direct link to Why Frameworks Avoid POSIX AIO" title="Direct link to Why Frameworks Avoid POSIX AIO" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-platform-fragmentation-and-incompatibility">1. Platform Fragmentation and Incompatibility<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#1-platform-fragmentation-and-incompatibility" class="hash-link" aria-label="Direct link to 1. Platform Fragmentation and Incompatibility" title="Direct link to 1. Platform Fragmentation and Incompatibility" translate="no">​</a></h3>
<p><strong>Multiple Incompatible APIs:</strong> Cross-platform runtimes must support:</p>
<ul>
<li class="">Linux native AIO (<code>io_submit</code>, <code>io_getevents</code>)</li>
<li class="">POSIX AIO (different implementations across BSDs, macOS, Linux)</li>
<li class="">Windows Overlapped I/O (completely different model)</li>
</ul>
<p>Each requires platform-specific code paths, different error handling, and separate testing matrices. A thread pool provides a single, uniform abstraction that works identically everywhere.</p>
<p><strong>Platform-Specific Limitations:</strong></p>
<ul>
<li class="">macOS POSIX AIO caps concurrent operations at ~16, making it unusable for high-throughput applications</li>
<li class="">Some OSes lack async support for critical operations like <code>close()</code>, <code>rename()</code>, <code>stat()</code>, or <code>fsync()</code></li>
<li class="">Behavior differs across filesystem types (ext4 vs XFS vs NFS)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-linux-aios-strict-requirements">2. Linux AIO's Strict Requirements<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#2-linux-aios-strict-requirements" class="hash-link" aria-label="Direct link to 2. Linux AIO's Strict Requirements" title="Direct link to 2. Linux AIO's Strict Requirements" translate="no">​</a></h3>
<p><strong>Direct I/O Mandate:</strong> To get true async behavior with Linux native AIO (<code>io_submit</code>), you must use the <code>O_DIRECT</code> flag, which has onerous requirements:</p>
<ul>
<li class=""><strong>512-byte alignment:</strong> Both buffer addresses and file offsets must align to 512-byte boundaries</li>
<li class=""><strong>Bypasses page cache:</strong> <code>O_DIRECT</code> skips the kernel's buffer cache, which can hurt performance for small, cached operations</li>
<li class=""><strong>Complex buffer management:</strong> Arbitrary reads/writes require custom allocators and padding</li>
</ul>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">// Linux AIO with O_DIRECT requires this complexity</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">void</span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> buffer</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">posix_memalign</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">buffer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ALIGNED_SIZE</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// Must align to 512 bytes</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">off_t</span><span class="token plain"> offset </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1024</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// Must be multiple of 512</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// This would FAIL with EINVAL:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// off_t offset = 1000;  // Not 512-aligned</span><br></span></code></pre></div></div>
<p><strong>Why This Breaks Node.js/Python:</strong> Applications frequently work with arbitrary offsets and sizes (reading JSON configs at byte 127, writing logs of variable length). Handling alignment for every operation adds enormous complexity.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-problematic-completion-mechanisms">3. Problematic Completion Mechanisms<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#3-problematic-completion-mechanisms" class="hash-link" aria-label="Direct link to 3. Problematic Completion Mechanisms" title="Direct link to 3. Problematic Completion Mechanisms" translate="no">​</a></h3>
<p><strong>POSIX AIO Notification Issues:</strong></p>
<ul>
<li class=""><strong>Signals:</strong> Process-global, conflict with application code and other libraries, difficult to multiplex</li>
<li class=""><strong>aio_suspend:</strong> Scales poorly—you must pass an array of all pending operations to check for completion</li>
<li class="">Neither integrates cleanly with epoll/kqueue-based event loops</li>
</ul>
<p><strong>Linux AIO:</strong> Uses <code>eventfd</code> or <code>io_getevents</code>, which can integrate with event loops but adds significant complexity compared to "submit job to thread pool, get callback when done."</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-incomplete-operation-coverage">4. Incomplete Operation Coverage<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#4-incomplete-operation-coverage" class="hash-link" aria-label="Direct link to 4. Incomplete Operation Coverage" title="Direct link to 4. Incomplete Operation Coverage" translate="no">​</a></h3>
<p>Even if you solve read/write asynchrony, many filesystem operations remain blocking:</p>
<ul>
<li class=""><code>open()</code> - directory traversal can block on network filesystems</li>
<li class=""><code>close()</code> - may block flushing buffers (especially on macOS HFS+)</li>
<li class=""><code>stat()</code> / <code>fstat()</code> - metadata lookup can be slow</li>
<li class=""><code>fsync()</code> / <code>fdatasync()</code> - explicit flushes</li>
<li class=""><code>rename()</code>, <code>unlink()</code>, <code>mkdir()</code> - directory operations</li>
</ul>
<p><strong>Thread Pool Advantage:</strong> Treating all filesystem operations uniformly as "potentially blocking" simplifies the programming model. You don't need special cases for which operations are async vs sync.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-thread-pools-are-actually-good">5. Thread Pools Are Actually Good<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#5-thread-pools-are-actually-good" class="hash-link" aria-label="Direct link to 5. Thread Pools Are Actually Good" title="Direct link to 5. Thread Pools Are Actually Good" translate="no">​</a></h3>
<p><strong>Efficiency:</strong> Modern thread pools (like libuv's in Node.js) are highly optimized:</p>
<ul>
<li class="">Thread reuse eliminates creation/destruction overhead</li>
<li class="">Bounded concurrency prevents system overload</li>
<li class="">Work stealing and priority queues optimize scheduling</li>
<li class="">Blocking in a worker thread doesn't affect the event loop</li>
</ul>
<p><strong>Advanced I/O Support:</strong></p>
<ul>
<li class=""><code>readv</code>/<code>writev</code> for scatter-gather I/O (POSIX AIO lacks this)</li>
<li class="">Easy integration with compression, hashing, or encryption pipelines</li>
<li class="">Straightforward cancellation semantics</li>
</ul>
<p><strong>Real-World Performance:</strong> For many workloads, thread pool overhead is negligible compared to actual I/O time. A 0.1ms thread scheduling cost is insignificant when disk latency is 5-10ms.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="comparison-table">Comparison Table<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#comparison-table" class="hash-link" aria-label="Direct link to Comparison Table" title="Direct link to Comparison Table" translate="no">​</a></h2>
<table><thead><tr><th>Feature</th><th>Non-Blocking I/O + Thread Pool</th><th>POSIX AIO</th></tr></thead><tbody><tr><td>Network Operations</td><td>✅ True async via epoll/kqueue</td><td>❌ Not designed for sockets</td></tr><tr><td>File Operations</td><td>⚠️ Blocking calls in thread pool</td><td>✅ True async (in theory)</td></tr><tr><td>Cross-Platform</td><td>✅ Works everywhere identically</td><td>❌ Platform-specific quirks</td></tr><tr><td>Buffer Alignment</td><td>✅ No restrictions</td><td>❌ Linux requires O_DIRECT alignment</td></tr><tr><td>Operation Coverage</td><td>✅ All operations uniform</td><td>❌ Many operations remain blocking</td></tr><tr><td>Event Loop Integration</td><td>✅ Clean callback model</td><td>⚠️ Complex signal/suspend mechanisms</td></tr><tr><td>Vector I/O</td><td>✅ readv/writev support</td><td>❌ Not available</td></tr><tr><td>Learning Curve</td><td>✅ Straightforward</td><td>❌ Steep, error-prone</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="where-aio-actually-succeeds">Where AIO Actually Succeeds<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#where-aio-actually-succeeds" class="hash-link" aria-label="Direct link to Where AIO Actually Succeeds" title="Direct link to Where AIO Actually Succeeds" translate="no">​</a></h2>
<p>It's important to note that AIO isn't universally avoided. It works well in specialized contexts:</p>
<p><strong>Database Systems:</strong> PostgreSQL, MySQL/InnoDB use Linux native AIO for tablespace I/O. They benefit because:</p>
<ul>
<li class="">Database pages are naturally aligned (typically 8KB or 16KB blocks)</li>
<li class=""><code>O_DIRECT</code> is desirable to avoid double buffering (page cache + database buffer pool)</li>
<li class="">They control the entire I/O path and can absorb implementation complexity</li>
</ul>
<p><strong>High-Performance Applications:</strong> Custom storage engines, video processing pipelines, and HPC applications use AIO when they need maximum throughput and can handle the alignment requirements.</p>
<p><strong>The Key Difference:</strong> These applications control their data format and can architect around AIO's constraints. General-purpose runtimes like Node.js must handle arbitrary user code.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-future-io_uring">The Future: io_uring<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#the-future-io_uring" class="hash-link" aria-label="Direct link to The Future: io_uring" title="Direct link to The Future: io_uring" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-io_uring">What Is io_uring?<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#what-is-io_uring" class="hash-link" aria-label="Direct link to What Is io_uring?" title="Direct link to What Is io_uring?" translate="no">​</a></h3>
<p>Introduced in Linux 5.1 (2019), <code>io_uring</code> is a modern asynchronous I/O interface that addresses many of AIO's shortcomings:</p>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;liburing.h&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">io_uring_queue_init</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">unsigned</span><span class="token plain"> entries</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">unsigned</span><span class="token plain"> flags</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">io_uring_prep_read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring_sqe</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">sqe</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">buf</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">unsigned</span><span class="token plain"> nbytes</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">off_t</span><span class="token plain"> offset</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">io_uring_submit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">io_uring_wait_cqe</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring_cqe</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">cqe</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<p><strong>Architecture:</strong> Uses two ring buffers (submission queue and completion queue) shared between user space and kernel space, minimizing system call overhead.</p>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">// Simplified io_uring usage</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring</span><span class="token plain"> ring</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">io_uring_queue_init</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// Prepare a read operation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring_sqe</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">sqe </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">io_uring_get_sqe</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">io_uring_prep_read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sqe</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> fd</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> buffer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> offset</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// Submit to kernel (batches multiple operations)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">io_uring_submit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// Later, retrieve completions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">io_uring_cqe</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">cqe</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">io_uring_wait_cqe</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">cqe</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token class-name">ssize_t</span><span class="token plain"> result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cqe</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">res</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">io_uring_cqe_seen</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">ring</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> cqe</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-advantages-over-aio">Key Advantages Over AIO<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#key-advantages-over-aio" class="hash-link" aria-label="Direct link to Key Advantages Over AIO" title="Direct link to Key Advantages Over AIO" translate="no">​</a></h3>
<ol>
<li class="">
<p><strong>No O_DIRECT Requirement:</strong> Works with buffered I/O, eliminating alignment constraints. Applications can use the page cache naturally.</p>
</li>
<li class="">
<p><strong>Lower System Call Overhead:</strong></p>
<ul>
<li class="">Batch multiple operations in a single <code>io_uring_submit()</code></li>
<li class="">Polling mode can eliminate syscalls entirely for high-throughput scenarios</li>
<li class="">Reduces context switches by orders of magnitude</li>
</ul>
</li>
<li class="">
<p><strong>Unified Interface:</strong></p>
<ul>
<li class="">Handles file I/O, network I/O, and more through a single API</li>
<li class="">Supports <code>read</code>, <code>write</code>, <code>accept</code>, <code>send</code>, <code>recv</code>, <code>fsync</code>, <code>openat</code>, <code>close</code>, etc.</li>
<li class="">Even supports operations like <code>timeout</code> and <code>poll</code></li>
</ul>
</li>
<li class="">
<p><strong>Fixed Buffers and Files:</strong></p>
<ul>
<li class="">Pre-register buffers and file descriptors for zero-copy operations</li>
<li class="">Eliminates per-operation memory pinning overhead</li>
</ul>
</li>
<li class="">
<p><strong>Modern Event Loop Integration:</strong> Designed from the ground up to work with epoll-style programming models.</p>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="real-world-performance">Real-World Performance<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#real-world-performance" class="hash-link" aria-label="Direct link to Real-World Performance" title="Direct link to Real-World Performance" translate="no">​</a></h3>
<p>Benchmarks show significant improvements:</p>
<ul>
<li class="">50-80% reduction in CPU usage for I/O-heavy workloads</li>
<li class="">2-3x throughput for high-concurrency scenarios</li>
<li class="">Particularly impressive for mixed read/write workloads</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="current-adoption-status">Current Adoption Status<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#current-adoption-status" class="hash-link" aria-label="Direct link to Current Adoption Status" title="Direct link to Current Adoption Status" translate="no">​</a></h3>
<p><strong>Node.js:</strong> Experimental support added in Node.js 21 (2023) behind the <code>--experimental-io-uring</code> flag. Disabled by default due to:</p>
<ul>
<li class="">Security concerns: <code>io_uring</code> can bypass certain permission checks with symbolic links</li>
<li class="">File descriptor exposure: Potential for unauthorized access if misused</li>
<li class="">Kernel version requirements: Requires Linux 5.10+ for stable operation</li>
</ul>
<p><strong>Python:</strong> <code>python-liburing</code> bindings exist, but not yet integrated into <code>asyncio</code> core. Community experimentation ongoing.</p>
<p><strong>Rust:</strong> The <code>io-uring</code> and <code>tokio-uring</code> crates provide production-ready wrappers, seeing increasing adoption.</p>
<p><strong>C/C++:</strong> Libraries like <code>liburing</code> are mature and widely used in performance-critical applications.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="challenges-and-limitations">Challenges and Limitations<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#challenges-and-limitations" class="hash-link" aria-label="Direct link to Challenges and Limitations" title="Direct link to Challenges and Limitations" translate="no">​</a></h3>
<ol>
<li class="">
<p><strong>Linux-Only:</strong> No cross-platform support (yet). Runtimes still need thread pool fallbacks for other OSes.</p>
</li>
<li class="">
<p><strong>Security Surface:</strong> New CVEs discovered periodically (SQPOLL mode issues, privilege escalation bugs). Some distros disable <code>io_uring</code> by sysctl.</p>
</li>
<li class="">
<p><strong>Complexity:</strong> While better than AIO, it's still more complex than "submit job to thread pool."</p>
</li>
<li class="">
<p><strong>Ecosystem Maturity:</strong> Fewer resources, examples, and debugging tools compared to established patterns.</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="when-to-use-what">When to Use What<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#when-to-use-what" class="hash-link" aria-label="Direct link to When to Use What" title="Direct link to When to Use What" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="use-thread-pools--blocking-io-when">Use Thread Pools + Blocking I/O When:<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#use-thread-pools--blocking-io-when" class="hash-link" aria-label="Direct link to Use Thread Pools + Blocking I/O When:" title="Direct link to Use Thread Pools + Blocking I/O When:" translate="no">​</a></h3>
<ul>
<li class="">Building cross-platform applications</li>
<li class="">Working with arbitrary file formats and offsets</li>
<li class="">Simplicity and maintainability are priorities</li>
<li class="">I/O isn't the primary bottleneck</li>
</ul>
<p><strong>This is the right default for most applications</strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="use-io_uring-when">Use io_uring When:<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#use-io_uring-when" class="hash-link" aria-label="Direct link to Use io_uring When:" title="Direct link to Use io_uring When:" translate="no">​</a></h3>
<ul>
<li class="">Building Linux-specific high-performance systems</li>
<li class="">I/O throughput is critical (storage systems, proxies, databases)</li>
<li class="">You can absorb the complexity and security considerations</li>
<li class="">Targeting modern kernels (5.10+)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="use-posix-aio-when">Use POSIX AIO When:<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#use-posix-aio-when" class="hash-link" aria-label="Direct link to Use POSIX AIO When:" title="Direct link to Use POSIX AIO When:" translate="no">​</a></h3>
<ul>
<li class="">You have legacy requirements</li>
<li class="">Operating in a controlled environment with aligned I/O patterns</li>
</ul>
<p><strong>Generally avoid in new projects</strong></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>The question "why don't frameworks use Linux AIO?" reveals a deeper truth about systems programming: elegant APIs don't always win. POSIX AIO offers theoretical purity—true asynchronous I/O at the kernel level—but fails in practice due to platform fragmentation, onerous constraints, and incomplete coverage.</p>
<p>Thread pools, despite appearing crude, provide a pragmatic solution that works reliably across platforms, handles all operations uniformly, and performs well enough for most use cases. The overhead of thread scheduling is negligible compared to actual I/O latency.</p>
<p>The emergence of <code>io_uring</code> represents a potential shift. By learning from AIO's failures—eliminating alignment requirements, reducing syscall overhead, and providing unified operation coverage—it may finally deliver on the promise of kernel-level async I/O. However, adoption remains cautious due to its Linux-only nature and evolving security posture.</p>
<p><strong>The takeaway:</strong> When designing systems APIs, developer experience, cross-platform consistency, and practical constraints often matter more than theoretical elegance. The "best" solution isn't always the most sophisticated one—it's the one developers can actually use reliably.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="further-reading">Further Reading<a href="https://blog.vertexcover.io/why-nodejs-python-avoid-linux-aio#further-reading" class="hash-link" aria-label="Direct link to Further Reading" title="Direct link to Further Reading" translate="no">​</a></h2>
<ul>
<li class=""><a href="https://github.com/axboe/liburing" target="_blank" rel="noopener noreferrer" class="">liburing documentation</a> - Comprehensive io_uring guide by its creator</li>
<li class=""><a href="https://github.com/nodejs/node/discussions/44919" target="_blank" rel="noopener noreferrer" class="">Node.js io_uring discussion</a> - Design decisions and security concerns</li>
<li class=""><a href="https://www.scylladb.com/2020/05/05/how-io-uring-and-ebpf-will-revolutionize-programming-in-linux/" target="_blank" rel="noopener noreferrer" class="">Linux AIO limitations</a> - ScyllaDB's deep dive</li>
<li class=""><a href="https://docs.libuv.org/en/v1.x/threadpool.html" target="_blank" rel="noopener noreferrer" class="">Thread pool design in libuv</a> - Node.js's I/O implementation</li>
</ul>]]></content:encoded>
            <category>Infrastructure</category>
        </item>
        <item>
            <title><![CDATA[Building a LinkedIn Scraper (and Turning It Into an MCP Integration)]]></title>
            <link>https://blog.vertexcover.io/linkedin-scraper-mcp-integration</link>
            <guid>https://blog.vertexcover.io/linkedin-scraper-mcp-integration</guid>
            <pubDate>Thu, 06 Nov 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[We recently built a LinkedIn scraping tool that can extract profiles, company data, and connections without getting flagged.]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>We recently built a LinkedIn scraping tool that can extract profiles, company data, and connections <strong>without getting flagged</strong>.<br>
<!-- -->Sounds simple, right? Well, three weeks and countless "unusual activity detected" warnings later, We learned that scraping LinkedIn is less about parsing HTML and more about outsmarting their anti-bot systems.</p></div></div>
<p>Full source code: <a href="https://github.com/vertexcover-io/linkedin-spider" target="_blank" rel="noopener noreferrer" class="">github.com/vertexcover-io/linkedin-spider</a></p>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-build-this">Why Build This?<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#why-build-this" class="hash-link" aria-label="Direct link to Why Build This?" title="Direct link to Why Build This?" translate="no">​</a></h2>
<p>We built this to <strong>automate our sales pipeline</strong> — to find, connect, and communicate with potential leads directly from LinkedIn.</p>
<p>The official API is too limited for that. You can't filter profiles the way you need to, or access detailed company data.</p>
<p>So we built <strong><code>linkedin-spider</code></strong>, a Python scraper with an <strong>MCP server</strong> on top that plugs into Claude Code.<br>
<!-- -->This setup lets Claude search for leads, gather insights, and even assist with outreach — all through natural language.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-authentication-nightmare">The Authentication Nightmare<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#the-authentication-nightmare" class="hash-link" aria-label="Direct link to The Authentication Nightmare" title="Direct link to The Authentication Nightmare" translate="no">​</a></h2>
<p>LinkedIn does not like bots — and it makes that very clear.</p>
<p>At first, we thought authentication would be simple: just grab the <code>li_at</code> cookie, inject it, and start scraping.<br>
<strong>Wrong.</strong></p>
<p>LinkedIn's enhanced anti-bot system quickly detected cookie-based sessions, leading to random logouts and account challenges.<br>
<!-- -->So we pivoted to <strong>email/password-based authentication with session persistence.</strong></p>
<p>The system now:</p>
<ul>
<li class="">Tries multiple authentication methods in order of reliability</li>
<li class="">Stores session cookies in a persistent Chrome profile</li>
<li class="">Minimizes repeated logins across runs</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="fixing-chrome-profile-persistence">Fixing Chrome Profile Persistence<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#fixing-chrome-profile-persistence" class="hash-link" aria-label="Direct link to Fixing Chrome Profile Persistence" title="Direct link to Fixing Chrome Profile Persistence" translate="no">​</a></h2>
<p>In the early versions, Chrome profiles were stored in the working directory.<br>
<!-- -->Users who ran the scraper from different folders were asked to log in every time — defeating the purpose of "persistence."</p>
<p><strong>The fix?</strong> A centralized profile directory that stays consistent across runs.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="handling-otp-challenges-in-the-cli">Handling OTP Challenges in the CLI<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#handling-otp-challenges-in-the-cli" class="hash-link" aria-label="Direct link to Handling OTP Challenges in the CLI" title="Direct link to Handling OTP Challenges in the CLI" translate="no">​</a></h2>
<p>Nothing tests your patience like LinkedIn's OTP challenges — especially when you're running a headless CLI tool.</p>
<p>To handle this, we implemented an interactive pause during setup:</p>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>OTP handling code →</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">_handle_verification_code_challenge</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">bool</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"\n Email verification code required"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Please check your email for the verification code."</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    verification_code </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">input</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Enter the 6-digit verification code: "</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">strip</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div></div></div></div>
<p>The CLI now detects OTP prompts, waits for user input, submits the code, and resumes.<br>
<!-- -->A simple feature, but getting it right across multiple challenge types was surprisingly tricky.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="scraping-where-premium-users-broke-everything">Scraping: Where Premium Users Broke Everything<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#scraping-where-premium-users-broke-everything" class="hash-link" aria-label="Direct link to Scraping: Where Premium Users Broke Everything" title="Direct link to Scraping: Where Premium Users Broke Everything" translate="no">​</a></h2>
<p>It turns out LinkedIn's HTML isn't the same for all users — <strong>premium accounts get entirely different structures</strong> for the same pages.</p>
<p>Here's how we handled it:</p>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Multi-selector approach →</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">_extract_name_and_url</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> container</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> WebElement</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">tuple</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    name_selectors </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">'a[data-view-name="search-result-lockup-title"]'</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Free accounts</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">'span.entity-result__title-text a'</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic"># Premium variant 1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">'a.app-aware-link span[aria-hidden="true"]'</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># Premium variant 2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div></div></div></div>
<p>The scraper cycles through multiple selectors for each data point — name, headline, location, image URLs, and more.<br>
<!-- -->Not the most elegant solution, but <strong>robust across user types.</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="search-filters-the-recursive-rabbit-hole">Search Filters: The Recursive Rabbit Hole<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#search-filters-the-recursive-rabbit-hole" class="hash-link" aria-label="Direct link to Search Filters: The Recursive Rabbit Hole" title="Direct link to Search Filters: The Recursive Rabbit Hole" translate="no">​</a></h2>
<p>LinkedIn's search filters are deeply nested and dynamically generated.<br>
<!-- -->Filtering by location, for example, involves dropdowns, autocompletes, and generated IDs.</p>
<p>To manage this, we built a dedicated <code>SearchFilterHandler</code> that automates:</p>
<ul>
<li class="">Location filters with autocomplete</li>
<li class="">Industry and company selectors</li>
<li class="">Current company searches</li>
<li class="">Connection degree filtering</li>
<li class="">Follower/connection-of filters</li>
</ul>
<p>Each required <strong>reverse-engineering LinkedIn's front-end logic</strong> and replicating it through Selenium.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="proxy-support-ip-bans">Proxy Support: IP Bans<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#proxy-support-ip-bans" class="hash-link" aria-label="Direct link to Proxy Support: IP Bans" title="Direct link to Proxy Support: IP Bans" translate="no">​</a></h2>
<p>While authenticating the scraper on a server, LinkedIn frequently threw image-based challenges — impossible to solve in a headless browser.</p>
<p><strong>The solution?</strong> A <strong>residential proxy.</strong><br>
<!-- -->It mimics normal browsing behavior from a typical user IP, drastically reducing challenges and OTP prompts during authentication.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="stealth-mode-hiding-the-automation">Stealth Mode: Hiding the Automation<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#stealth-mode-hiding-the-automation" class="hash-link" aria-label="Direct link to Stealth Mode: Hiding the Automation" title="Direct link to Stealth Mode: Hiding the Automation" translate="no">​</a></h2>
<p>Selenium is easily detectable. LinkedIn can identify automated browsers via <code>navigator</code> properties, missing APIs, or automation flags.</p>
<p>To counter that, we added a <strong>stealth mode</strong> layer using Chrome DevTools Protocol. It:</p>
<ul>
<li class="">Masks webdriver properties</li>
<li class="">Spoofs browser and OS information</li>
<li class="">Injects anti-detection scripts on each page load</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="human-behavior-simulation">Human Behavior Simulation<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#human-behavior-simulation" class="hash-link" aria-label="Direct link to Human Behavior Simulation" title="Direct link to Human Behavior Simulation" translate="no">​</a></h2>
<p>Bots act like machines; humans don't.</p>
<p>We built a <code>HumanBehavior</code> module that:</p>
<ul>
<li class="">Adds random delays between actions (0.5–2s by default)</li>
<li class="">Simulates typing character-by-character with natural pauses</li>
<li class="">Scrolls incrementally rather than jumping</li>
<li class="">Adds mouse movements before clicks</li>
</ul>
<p>These subtle touches reduce automation fingerprints and <strong>improve long-term reliability.</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-mcp-integration">The MCP Integration<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#the-mcp-integration" class="hash-link" aria-label="Direct link to The MCP Integration" title="Direct link to The MCP Integration" translate="no">​</a></h2>
<p>MCP (Model Context Protocol) by Anthropic allows AI assistants to interact with external data sources.</p>
<p>We built an MCP server around <code>linkedin-spider</code>, exposing scraping tools to assistants like Claude.</p>
<p>Claude can now answer queries like:</p>
<blockquote>
<p>"Find 10 product managers in San Francisco working at Series B startups."</p>
</blockquote>
<p>Example call:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">linkedin-mcp search_profiles   --query "product manager San Francisco Series B"   --max_results 10   --location "San Francisco"</span><br></span></code></pre></div></div>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Example output →</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"name"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Anand Raghavan"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"headline"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"VP Products, AI at Cisco"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"location"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"San Francisco Bay Area"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"experience"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"title"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Cisco"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"company"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Cisco"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"company_url"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"https://www.linkedin.com/company/1063/"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"duration"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Full-time · 2 yrs 4 mos"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"location"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"San Francisco Bay Area"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-id-do-differently">What I'd Do Differently<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#what-id-do-differently" class="hash-link" aria-label="Direct link to What I'd Do Differently" title="Direct link to What I'd Do Differently" translate="no">​</a></h2>
<ul>
<li class=""><strong>Decouple architecture:</strong> Separate driver management from scraping logic earlier</li>
<li class=""><strong>Async execution:</strong> Move to async/await with concurrent drivers for bulk ops</li>
<li class=""><strong>Error recovery:</strong> Add retry logic and exponential backoff</li>
<li class=""><strong>Dynamic selectors:</strong> Build a remote selector update mechanism</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="current-limitations">Current Limitations<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#current-limitations" class="hash-link" aria-label="Direct link to Current Limitations" title="Direct link to Current Limitations" translate="no">​</a></h2>
<ul>
<li class="">Cookie-based auth remains unreliable</li>
<li class="">Pagination caps restrict full dataset scraping</li>
<li class="">Rate limits still apply despite delays and proxies</li>
<li class="">Captchas still require manual intervention</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="try-it-yourself">Try It Yourself<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#try-it-yourself" class="hash-link" aria-label="Direct link to Try It Yourself" title="Direct link to Try It Yourself" translate="no">​</a></h2>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install linkedin-spider[cli]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">linkedin-spider-cli search -q "software engineer" -n 10   --email your@email.com --password yourpass</span><br></span></code></pre></div></div>
<p>Full source code: <a href="https://github.com/vertexcover-io/linkedin-spider" target="_blank" rel="noopener noreferrer" class="">github.com/vertexcover-io/linkedin-spider</a><br>
<!-- -->Licensed under MIT — please use responsibly.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="final-thoughts">Final Thoughts<a href="https://blog.vertexcover.io/linkedin-scraper-mcp-integration#final-thoughts" class="hash-link" aria-label="Direct link to Final Thoughts" title="Direct link to Final Thoughts" translate="no">​</a></h2>
<p>Building this scraper taught me that <strong>web scraping is 30% engineering and 70% understanding the adversarial dynamics</strong> between scrapers and platforms.</p>
<p>LinkedIn doesn't want to be scraped — but can't entirely block it without breaking its own UX.<br>
<!-- -->That gap is where projects like this thrive.</p>
<blockquote>
<p>With great scraping power comes great responsibility.<br>
<!-- -->Don't spam. Don't exploit. Don't cross ethical lines.<br>
<!-- -->Use tools like this for research, automation, and legitimate data needs only.</p>
</blockquote>]]></content:encoded>
            <category>Web Scraping</category>
            <category>MCP</category>
            <category>Automation</category>
        </item>
        <item>
            <title><![CDATA[How We Do Evals & Observability for Agentic Systems]]></title>
            <link>https://blog.vertexcover.io/strot-ai-observability-evaluation-system</link>
            <guid>https://blog.vertexcover.io/strot-ai-observability-evaluation-system</guid>
            <pubDate>Tue, 02 Sep 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[LLM agentic systems fail in subtle ways. At Vertexcover Labs, we use a 5-part evaluation approach—powered by a structured logging foundation:]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>LLM agentic systems fail in subtle ways. At Vertexcover Labs, we use a 5-part evaluation approach—powered by a structured logging foundation:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Custom reporting/observability app to inspect the step-by-step agent flow (screenshots, LLM traces, code samples, step context, JSON/text blocks, costs).</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Component/agent-level tests (like unit tests) to isolate/fix one step without re-running the whole agent.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">End-to-end evals that validate the final product output while also comparing each stage to explain failures.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Eval reporting dashboard (Airtable or similar) showing run status with linked "run → steps" tables for fast triage.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Easy promotion of failing production runs into test cases (just use the run_id).</li></ol><p><strong>Foundation:</strong> a structured logging layer that makes all of the above trivial to build and maintain.</p></div></div>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-evals--observability-are-hard-for-llmagent-systems">Why Evals &amp; Observability Are Hard for LLM/Agent Systems<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#why-evals--observability-are-hard-for-llmagent-systems" class="hash-link" aria-label="Direct link to Why Evals &amp; Observability Are Hard for LLM/Agent Systems" title="Direct link to Why Evals &amp; Observability Are Hard for LLM/Agent Systems" translate="no">​</a></h2>
<p>Everyone agrees evals &amp; obs are critical. Few teams have a practical pattern that works across domains. The pain points we kept hitting (and solved):</p>
<p><strong>🎲 LLMs are non-deterministic</strong><br>
<!-- -->Small prompt shifts, model updates, or temperature changes can flip outcomes. You need repeatable tests and live monitors per call.</p>
<p><strong>🔗 Deeply chained workflows</strong><br>
<!-- -->Planning → tool calls → retries → post-processing. A bad first decision can ripple invisibly. Only looking at the final result hides root causes, but product quality still depends on the final result.</p>
<p><strong>⏱️ Full-run latency &amp; cost</strong><br>
<!-- -->Running agents end-to-end for every tweak is slow and expensive. We need component isolation and captured inputs to iterate quickly.</p>
<p><strong>🔍 Debugging requires rich context</strong><br>
<!-- -->Off-the-shelf APM doesn't understand domain-specific failures like "selected wrong data source", "missed edge case in extraction logic", or "hallucinated field mappings". We need pipeline-aware traces: visual state captures, complete LLM interactions, generated artifacts, execution paths, and granular cost attribution.</p>
<p><strong>📉 Evals decay as use cases evolve</strong><br>
<!-- -->Your perfect eval suite from Q1 becomes incomplete by Q3. New customer patterns emerge, edge cases multiply, and existing tests miss real-world failures. You need frictionless eval creation from production data—one command to turn today's failure into tomorrow's regression test, without manual test writing.</p>
<p>We see these issues across all our agentic projects. Below is how we solve them in general, using our OSS project Strot as a running example.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="context-strot-example-system">Context: Strot (Example System)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#context-strot-example-system" class="hash-link" aria-label="Direct link to Context: Strot (Example System)" title="Direct link to Context: Strot (Example System)" translate="no">​</a></h2>
<p><a href="https://github.com/vertexcover-io/strot" target="_blank" rel="noopener noreferrer" class="">Strot</a> reverse-engineers websites to discover internal APIs and extract structured data. The pipeline has three AI components:</p>
<table><thead><tr><th>Component</th><th>What It Does</th><th>Example Failure</th></tr></thead><tbody><tr><td><strong>Request Detection</strong></td><td>Identify the network call loading target data</td><td>Picks non-related network call</td></tr><tr><td><strong>Parameter Analysis</strong></td><td>Detect pagination and dynamic filters</td><td>Misses cursor param, breaks pagination</td></tr><tr><td><strong>Structured Extraction</strong></td><td>Generate Python to parse responses into schema</td><td>Wrong JSON key mapping</td></tr></tbody></table>
<p>Each can fail differently across thousands of site patterns.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="our-solution-41-stages">Our Solution (4+1 Stages)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#our-solution-41-stages" class="hash-link" aria-label="Direct link to Our Solution (4+1 Stages)" title="Direct link to Our Solution (4+1 Stages)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-make-debugging-fast--visual-custom-nextjs-reporting-app">1) Make Debugging Fast &amp; Visual (Custom Next.js Reporting App)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#1-make-debugging-fast--visual-custom-nextjs-reporting-app" class="hash-link" aria-label="Direct link to 1) Make Debugging Fast &amp; Visual (Custom Next.js Reporting App)" title="Direct link to 1) Make Debugging Fast &amp; Visual (Custom Next.js Reporting App)" translate="no">​</a></h3>
<div style="background-color:rgba(9, 105, 218, 0.1);border:1px solid rgba(9, 105, 218, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #0969da;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">💾</span><strong style="color:#0969da;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Implementation Note<!-- -->: <!-- -->Pipeline-Aware Debug UI</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p><strong>What we built:</strong> A pipeline-aware debug UI that shows every step in a run:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Browser screenshots per step (so you see the exact DOM/context the LLM "saw")</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">LLM prompt/response traces with token counts &amp; costs</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Artifacts like generated code and validation results</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Run timeline + per-step cost/time + rollups</li></ol><p><strong>Why custom:</strong> General APM lacks LLM context and domain objects like "network request candidates," "pagination keys," etc. Our UI renders code blocks, JSON blocks, and text blocks differently so you can scan fast.</p><p><strong>What it unlocks:</strong></p><ul style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:disc;list-style-type:disc;list-style-position:outside"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Diagnose in seconds ("wrong request chosen")</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Optimize budgets ("this step is the cost hotspot")</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">No waiting for full pipeline completion—watch in flight</li></ul></div></div>
<!-- -->
<div style="margin:20px 0"><img src="https://blog.vertexcover.io/assets/images/observability-dashboard-e04deb7cd8c1a8f3b0d7f87ec26f9536.gif" alt="Observability Dashboard" style="width:100%;max-width:100%;height:auto;border-radius:8px;box-shadow:0 4px 12px rgba(0, 0, 0, 0.1)"></div>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-component-level-unit-testing-agent-lego-bricks">2) Component-Level Unit Testing (Agent "Lego Bricks")<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#2-component-level-unit-testing-agent-lego-bricks" class="hash-link" aria-label="Direct link to 2) Component-Level Unit Testing (Agent &quot;Lego Bricks&quot;)" title="Direct link to 2) Component-Level Unit Testing (Agent &quot;Lego Bricks&quot;)" translate="no">​</a></h3>
<p>Running the full agent to test a single change is slow and pricey. We treat each component as a unit:</p>
<ul style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:disc;list-style-type:disc;list-style-position:outside"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Provide captured inputs to just that component</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Support "replay this step from an existing run" (auto-plucks the right inputs via run_id)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Validate outputs against expectations (pagination keys, dynamic filters, parse schema, etc.)</li></ul>
<p>This is akin to unit tests for agents: ship fixes in minutes, not hours.</p>
<p><strong>CLI example:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">echo '[{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "request": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "url": "https://api.example.com/products",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "queries": {"page": "2", "limit": "50"},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "post_data": {"sort": "price", "filter": "new"}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_pagination_keys": ["page", "limit"],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_dynamic_keys": ["sort", "filter"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}]' | uv run stroteval</span><br></span></code></pre></div></div>
<p><img decoding="async" loading="lazy" alt="Parameter Detection View" src="https://blog.vertexcover.io/assets/images/observability-parameter-detection-view-1bdff9ab4dc789aaa7423ad75543d135.png" width="1718" height="736" class="img_ev3q"></p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-end-to-end-eval-product-level-confidence">3) End-to-End Eval (Product-Level Confidence)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#3-end-to-end-eval-product-level-confidence" class="hash-link" aria-label="Direct link to 3) End-to-End Eval (Product-Level Confidence)" title="Direct link to 3) End-to-End Eval (Product-Level Confidence)" translate="no">​</a></h3>
<p>The product cares about the final output. Our E2E eval suite runs the full pipeline and checks:</p>
<ul style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:disc;list-style-type:disc;list-style-position:outside"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Correct source endpoint</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Pagination/dynamic keys</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Entity counts &amp; schema parse correctness</li></ul>
<p>Crucially, we also compare intermediate stages so failures are explainable ("endpoint correct, pagination wrong").</p>
<p><strong>CLI example:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">echo '[{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "job_id": "existing-job-uuid",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_source": "https://api.example.com/reviews",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_pagination_keys": ["cursor", "limit"],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_entity_count": 243</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "site_url": "https://example.com/category/abc",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "query": "Listed products with name and prices",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_source": "https://api.example.com/products",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_pagination_keys": ["limit", "offset"],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "expected_entity_count": 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}]' | uv run stroteval</span><br></span></code></pre></div></div>
<p>We run this suite on every deployment to catch system-level regressions before they reach users.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-airtable-dashboards-explorable-for-the-whole-team">4) Airtable Dashboards (Explorable for the Whole Team)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#4-airtable-dashboards-explorable-for-the-whole-team" class="hash-link" aria-label="Direct link to 4) Airtable Dashboards (Explorable for the Whole Team)" title="Direct link to 4) Airtable Dashboards (Explorable for the Whole Team)" translate="no">​</a></h3>
<p>We push eval results to two linked tables:</p>
<table><thead><tr><th>Table</th><th>Contents</th><th>Purpose</th></tr></thead><tbody><tr><td><strong>Runs / Aggregates</strong></td><td>Pass rates by component/site/time; cost/time trends</td><td>High-level health monitoring</td></tr><tr><td><strong>Step Details</strong></td><td>One record per step with inputs, outputs, matches, screenshots, costs (linked to its run)</td><td>Deep debugging and analysis</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Airtable Analysis Report" src="https://blog.vertexcover.io/assets/images/airtable-analysis-report-ff597a14e50c71b5b9005b7815c49ad5.gif" width="1912" height="937" class="img_ev3q"></p>
<p><strong>Why Airtable?</strong> Fast charts, human-friendly filtering, collab-ready, and it mirrors our step-by-step mental model.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-production-failures--new-tests-the-feedback-loop">5) Production Failures → New Tests (The Feedback Loop)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#5-production-failures--new-tests-the-feedback-loop" class="hash-link" aria-label="Direct link to 5) Production Failures → New Tests (The Feedback Loop)" title="Direct link to 5) Production Failures → New Tests (The Feedback Loop)" translate="no">​</a></h3>
<p>Any run that fails is already fully recorded via structured logs and run_id. Turning it into a test is trivial:</p>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Grab run_id → auto-hydrate inputs for the failing component</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Save as a component test (today manual, automation is trivial from the same logs)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">The suite becomes a bug graveyard — nothing escapes twice</li></ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-foundation-structured-logging--distributed-tracing">The Foundation: Structured Logging + Distributed Tracing<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#the-foundation-structured-logging--distributed-tracing" class="hash-link" aria-label="Direct link to The Foundation: Structured Logging + Distributed Tracing" title="Direct link to The Foundation: Structured Logging + Distributed Tracing" translate="no">​</a></h2>
<div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">🔍</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->The Secret: Structured Logging Architecture</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">▼</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="results-across-strot--similar-projects">Results (Across Strot &amp; Similar Projects)<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#results-across-strot--similar-projects" class="hash-link" aria-label="Direct link to Results (Across Strot &amp; Similar Projects)" title="Direct link to Results (Across Strot &amp; Similar Projects)" translate="no">​</a></h2>
<div style="background-color:rgba(191, 135, 0, 0.1);border:1px solid rgba(191, 135, 0, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #bf8700;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">⚡</span><strong style="color:#bf8700;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Performance Insight<!-- -->: <!-- -->Impact Metrics</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">95% success across 50+ site architectures</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">10× faster debugging via visual traces &amp; step replays</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">3× faster iteration thanks to component isolation</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Zero regressions once full coverage landed</li></ol></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-takeaways">Key Takeaways<a href="https://blog.vertexcover.io/strot-ai-observability-evaluation-system#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" translate="no">​</a></h2>
<p>Building effective observability and evaluation for agentic systems requires a holistic approach:</p>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Structure logs once</strong> — Proper logging infrastructure is the foundation (observability, evals, and debugging)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Make debugging visual</strong> — Custom app to inspect step-by-step agent flow (screenshots, LLM traces, code samples, step context, JSON/text blocks, costs)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Test in layers</strong> — component-level tests for rapid iteration, E2E evals for product confidence</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Build reporting dashboards</strong> An easy way to view results of e2e evals with ability to drill down into each step</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Close the feedback loop</strong> — easy conversion of production failures into component and E2E regression tests</li><li style="margin-bottom:8px;padding-left:8px;display:list-item"><strong>Keep interfaces simple</strong> — CLI tools for running evals, web dashboards for exploring results</li></ol>
<p>The framework transforms AI development from "hope it works" to "know it works."</p>
<hr>
<p>🔗 <strong>Code</strong>: <a href="https://github.com/vertexcover-io/strot" target="_blank" rel="noopener noreferrer" class="">github.com/vertexcover-io/strot</a><br>
<!-- -->📄 <strong>Docs</strong>: <a href="https://github.com/vertexcover-io/strot#-evaluation" target="_blank" rel="noopener noreferrer" class="">Evaluation Guide</a></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Speed up Docker Builds on Github actions]]></title>
            <link>https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions</link>
            <guid>https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions</guid>
            <pubDate>Wed, 20 Aug 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Tricks to speed up docker builds]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Turn on BuildKit &amp; Buildx everywhere</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Reorder Dockerfile: copy package files first, then rest of code</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Use cache-mounts with buildkit-cache-dance action</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Pick the right cache backend (inline for speed, registry for large images)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Add tmpfs + unsafe-io flags for package installs</li></ol><table><thead><tr><th>Scenario</th><th>Avg. wall-clock</th></tr></thead><tbody><tr><td>No caching</td><td><strong>1 h 10 m</strong></td></tr><tr><td>Layer-cache hit</td><td><strong>6 m</strong></td></tr><tr><td>Layer-cache miss (deps change)</td><td><strong>52 m</strong></td></tr><tr><td>Cache-mount + Cache-Dance</td><td><strong>8 m</strong></td></tr></tbody></table><p>Stop rebuilding the world on every pull-request—turn on these flags and ship faster.</p></div></div>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-this-matters">Why this matters<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#why-this-matters" class="hash-link" aria-label="Direct link to Why this matters" title="Direct link to Why this matters" translate="no">​</a></h3>
<blockquote>
<p>70 min ➜ 6 min (deps unchanged) or 8 min (deps changed).</p>
<p>Those are the real numbers we saw after switching our Node + Python monorepo to the techniques below.</p>
</blockquote>
<p>Slow builds waste CI minutes, break focus, and block deploys.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-turn-on-buildkit--buildx-everywhere">1. Turn on BuildKit &amp; Buildx everywhere<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#1-turn-on-buildkit--buildx-everywhere" class="hash-link" aria-label="Direct link to 1. Turn on BuildKit &amp; Buildx everywhere" title="Direct link to 1. Turn on BuildKit &amp; Buildx everywhere" translate="no">​</a></h2>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># .github/workflows/build.yml</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">uses</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> docker/setup</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">buildx</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">action@v3   </span><span class="token comment" style="color:#999988;font-style:italic"># spins up an isolated BuildKit builder</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">run</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> echo "DOCKER_BUILDKIT=1" </span><span class="token punctuation" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">&gt;</span><span class="token plain"> $GITHUB_ENV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>BuildKit unlocks layer caching, cache-mounts, <code>RUN --mount</code>, and multi-platform bake (<a href="https://docs.docker.com/build/ci/github-actions/cache/" target="_blank" rel="noopener noreferrer" class="">BuildKit documentation</a>).</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-trim-the-build-context">2. Trim the build context<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#2-trim-the-build-context" class="hash-link" aria-label="Direct link to 2. Trim the build context" title="Direct link to 2. Trim the build context" translate="no">​</a></h2>
<p>Add a <code>.dockerignore</code> that excludes <code>node_modules/</code>, <code>docs/</code>, test data, and build artefacts. The runner uploads the entire context before <strong>any</strong> Docker layer executes; shrinking 500 MB of junk can save 30-90 s (<a href="https://docs.docker.com/build/cache/optimize/" target="_blank" rel="noopener noreferrer" class="">build optimization guide</a>).</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-re-order-your-dockerfile">3. Re-order your Dockerfile<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#3-re-order-your-dockerfile" class="hash-link" aria-label="Direct link to 3. Re-order your Dockerfile" title="Direct link to 3. Re-order your Dockerfile" translate="no">​</a></h2>
<div class="language-Dockerfile language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># syntax=docker/dockerfile:1.7</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM node:20-slim AS deps</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WORKDIR /app</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 1️⃣ copy only manifests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY package.json yarn.lock ./</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RUN --mount=type=cache,target=/root/.cache/yarn \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    yarn install --frozen-lockfile    # re-runs only when the lock-file changes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2️⃣ now copy the rest</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>Because the dependency layer rarely changes, 60+ minutes of <code>yarn install</code> drops to &lt; 6 minutes the next time a PR arrives.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-choose-the-right-layer-cache-backend">4. Choose the <em>right</em> layer-cache backend<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#4-choose-the-right-layer-cache-backend" class="hash-link" aria-label="Direct link to 4-choose-the-right-layer-cache-backend" title="Direct link to 4-choose-the-right-layer-cache-backend" translate="no">​</a></h2>
<table><thead><tr><th>Exporter</th><th>What’s stored</th><th>Cold restore on GH runner</th><th>Best when</th></tr></thead><tbody><tr><td><strong><code>type=inline</code></strong></td><td>cache <em>metadata</em> embedded in the image</td><td>&lt; 1 s (only tiny config pulled)</td><td>You already push the image anyway</td></tr><tr><td><strong><code>type=registry</code></strong></td><td>full layers in a <code>&lt;image&gt;-buildcache</code> tag</td><td>5-30 s (downloads blobs)</td><td>Huge images, need <code>mode=max</code> granularity</td></tr><tr><td><strong><code>type=gha</code></strong></td><td>tarball in GitHub Actions Cache (10 GB limit)</td><td>1-5 s (&lt; 500 MB)</td><td>No private registry, branch-scoped caches</td></tr></tbody></table>
<p><em>Inline feels snappiest</em> because BuildKit needs only the image manifest; layer blobs are fetched lazily. Note, though, that inline supports only <code>mode=min</code>. For ARG/secret-heavy pipelines, flip to <code>registry</code> (<a href="https://docs.docker.com/build/cache/backends/inline/" target="_blank" rel="noopener noreferrer" class="">inline cache guide</a>, <a href="https://docs.docker.com/build/cache/backends/" target="_blank" rel="noopener noreferrer" class="">cache backends overview</a>, <a href="https://docs.docker.com/build/cache/backends/gha/" target="_blank" rel="noopener noreferrer" class="">GitHub Actions cache</a>).</p>
<p><strong>Example call</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker buildx build \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --push -t ghcr.io/acme/web:sha-$GITHUB_SHA \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --cache-from type=registry,ref=ghcr.io/acme/web:buildcache \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --cache-to   type=inline .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-cache-mounts--the-buildkit-cache-dance">5. Cache-mounts + the “BuildKit Cache Dance”<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#5-cache-mounts--the-buildkit-cache-dance" class="hash-link" aria-label="Direct link to 5. Cache-mounts + the “BuildKit Cache Dance”" title="Direct link to 5. Cache-mounts + the “BuildKit Cache Dance”" translate="no">​</a></h2>
<div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">RUN --mount=type=cache,target=/var/cache/apt     \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --mount=type=cache,target=/root/.cache/pip   \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pip install -r requirements.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p><code>type=cache</code> keeps bulky package folders <strong>outside</strong> the image graph, so later layer changes don’t obliterate them. On GitHub-hosted runners those volumes disappear after each job—unless you use <strong>buildkit-cache-dance</strong> to export/import them between runs:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">uses</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> reproducible</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">containers/buildkit</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">cache</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">dance@v2</span><br></span></code></pre></div></div>
<p>Result: <em>52 min ➜ 8 min</em> even when <code>package.json</code> <em>does</em> change (<a href="https://github.com/reproducible-containers/buildkit-cache-dance" target="_blank" rel="noopener noreferrer" class="">buildkit-cache-dance repo</a>, <a href="https://github.com/moby/buildkit/issues/1673" target="_blank" rel="noopener noreferrer" class="">BuildKit cache issue discussion</a>).</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-tmpfs--unsafe-io---90-s-package-installs">6. tmpfs + “unsafe-io” = &lt; 90 s package installs<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#6-tmpfs--unsafe-io---90-s-package-installs" class="hash-link" aria-label="Direct link to 6. tmpfs + “unsafe-io” = < 90 s package installs" title="Direct link to 6. tmpfs + “unsafe-io” = < 90 s package installs" translate="no">​</a></h2>
<div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">RUN --mount=type=tmpfs,target=/var/lib/apt/lists  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --mount=type=cache,target=/var/cache/apt      \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    apt-get -o DPkg::Options::="--force-unsafe-io" \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update &amp;&amp; apt-get install -y git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<ol class="pl-5 my-4 leading-relaxed list-decimal list-outside" start="1"><li class="mb-2 pl-2"><span><code>tmpfs</code> keeps apt's index in RAM—zero disk writes.</span></li><li class="mb-2 pl-2"><span><code>-force-unsafe-io</code> turns off every fsync in <code>dpkg</code>, a safe bet in throw-away CI VMs. Ubuntu's base images already apply a partial version, but passing the flag still yields 15-30% extra speed.</span></li></ol>
<p>(<a href="https://docs.docker.com/reference/dockerfile/" target="_blank" rel="noopener noreferrer" class="">Dockerfile RUN reference</a>, <a href="https://www.reddit.com/r/debian/comments/1dz4jxk/how_can_you_speed_up_apt/" target="_blank" rel="noopener noreferrer" class="">APT speed optimization discussion</a>, <a href="https://gist.github.com/reegnz/990d0b01b5f5e8670f78257875d8daa8" target="_blank" rel="noopener noreferrer" class="">unsafe-io examples</a>).</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="7-other-micro-wins">7. Other micro-wins<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#7-other-micro-wins" class="hash-link" aria-label="Direct link to 7. Other micro-wins" title="Direct link to 7. Other micro-wins" translate="no">​</a></h2>
<ul>
<li class=""><strong>Pin base images by digest</strong> to avoid surprise cache busts.</li>
<li class=""><strong><code>buildx bake</code></strong> builds amd64+arm64 (or dev+prod variants) in parallel while sharing one cache (<a href="https://docs.docker.com/guides/bake/" target="_blank" rel="noopener noreferrer" class="">buildx bake guide</a>).</li>
<li class=""><strong>Garbage-collect</strong> with <code>buildx prune --filter keep-storage=20GB</code> (<a href="https://docs.docker.com/build/ci/github-actions/cache/" target="_blank" rel="noopener noreferrer" class="">cache management guide</a>).</li>
<li class=""><strong>Self-hosted SSD runners</strong> keep the entire BuildKit store between workflows—zero network latency.</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="references">References<a href="https://blog.vertexcover.io/speed-up-docker-builds-on-github-actions#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ul style="padding-left:20px;margin:16px 0;line-height:1.6"><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/backends/inline/" target="_blank" rel="noopener noreferrer">Inline cache documentation</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/backends/" target="_blank" rel="noopener noreferrer">Cache backends overview</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/backends/gha/" target="_blank" rel="noopener noreferrer">GitHub Actions cache backend</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/cache/optimize/" target="_blank" rel="noopener noreferrer">Build cache optimization guide</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://github.com/reproducible-containers/buildkit-cache-dance" target="_blank" rel="noopener noreferrer">BuildKit Cache Dance repository</a> - GitHub</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/reference/dockerfile/" target="_blank" rel="noopener noreferrer">Dockerfile RUN --mount reference</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://www.reddit.com/r/debian/comments/1dz4jxk/how_can_you_speed_up_apt/" target="_blank" rel="noopener noreferrer">APT speed optimization discussion</a> - Reddit</p></li><li style="margin-bottom:8px"><p><a href="https://gist.github.com/reegnz/990d0b01b5f5e8670f78257875d8daa8" target="_blank" rel="noopener noreferrer">DPKG unsafe-io examples</a> - GitHub Gist</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/guides/bake/" target="_blank" rel="noopener noreferrer">Buildx bake guide</a> - Docker Docs</p></li><li style="margin-bottom:8px"><p><a href="https://docs.docker.com/build/ci/github-actions/cache/" target="_blank" rel="noopener noreferrer">Cache management on GitHub Actions</a> - Docker Docs</p></li></ul>
<hr>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Video Rendering Pipeline for an AI-Driven Text-to-Video Platform]]></title>
            <link>https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform</link>
            <guid>https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform</guid>
            <pubDate>Wed, 06 Aug 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Video Rendering Pipeline for an AI-Driven Text-to-Video Platform]]></description>
            <content:encoded><![CDATA[<p>Replacing dual React-ffmpeg architecture with unified browser-based solution, achieving 100,000 daily video renders with consistent preview-output matching and halved development effort.</p>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="context">Context<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context" translate="no">​</a></h2>
<p>A leading AI company offers a cloud-based video editor, its core product, enabling users to effortlessly convert text into video with human avatars. The editor supports a wide range of features, from backgrounds, media integration, and text overlays to animations, transitions, fonts, styling, and scene management.</p>
<p>Video generation operates as a pipeline: users begin by crafting a video using the browser-based tool, previewing their creation in real-time. Once satisfied, the video undergoes a render pipeline that culminates in the production of a full HD video, ensuring the final output mirrors the preview's fidelity. At its foundation, the frontend editor employs React, while the backend relies on a custom ffmpeg video renderer.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="problem">Problem<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#problem" class="hash-link" aria-label="Direct link to Problem" title="Direct link to Problem" translate="no">​</a></h2>
<p>The company's video editor relied on a dual system: a React-based preview in the browser and an ffmpeg-driven backend for final video rendering. This architecture presented multiple challenges:</p>
<ul>
<li class="">
<p><strong>Complexity of ffmpeg</strong>: Using ffmpeg programmatically proved intricate due to its inherent complexities.</p>
</li>
<li class="">
<p><strong>Mismatch Between Preview and Final Render</strong>: The separation of technologies (React for preview and ffmpeg for rendering) occasionally led to inconsistencies between the video preview and the final output.</p>
</li>
<li class="">
<p><strong>Duplication of Effort</strong>: Introducing any new feature demanded double the effort: once for the preview in React and once more for the final render using ffmpeg. Moreover, ensuring consistency between these two stages added to the workload.</p>
</li>
<li class="">
<p><strong>Limitations with ffmpeg</strong>: The use of ffmpeg imposed constraints on integrating advanced video editing features.</p>
</li>
</ul>
<p>Furthermore, the ideal solution needed to meet specific criteria:</p>
<ul>
<li class="">Video generation time should align with the video's actual duration.</li>
<li class="">The cost of rendering should not exceed 1Rs per minute of video.</li>
<li class="">The solution should be feasible for relatively swift development and integration.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="challenges-and-solution">Challenges and Solution<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#challenges-and-solution" class="hash-link" aria-label="Direct link to Challenges and Solution" title="Direct link to Challenges and Solution" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluating-browser-based-solutions">Evaluating Browser-Based Solutions<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#evaluating-browser-based-solutions" class="hash-link" aria-label="Direct link to Evaluating Browser-Based Solutions" title="Direct link to Evaluating Browser-Based Solutions" translate="no">​</a></h3>
<p>Drawing from my prior experience with video rendering pipelines, it was evident that a browser-centric solution could address our functional requirements. However, constraints related to cost and development time necessitated further exploration.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="library-exploration-for-time-efficiency">Library Exploration for Time-Efficiency<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#library-exploration-for-time-efficiency" class="hash-link" aria-label="Direct link to Library Exploration for Time-Efficiency" title="Direct link to Library Exploration for Time-Efficiency" translate="no">​</a></h3>
<p>An open-source library promising the conversion of React components to video emerged as a viable solution for rapid deployment. Preliminary experiments ensured its compatibility with our feature set. An in-depth examination of the library's source code was undertaken to gauge its maintainability, ease of potential forking, and readiness for production scenarios. Direct discussions with the library's author and the wider community bolstered our confidence in its capabilities.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="benchmarking-library-performance-on-lambda">Benchmarking Library Performance on Lambda<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#benchmarking-library-performance-on-lambda" class="hash-link" aria-label="Direct link to Benchmarking Library Performance on Lambda" title="Direct link to Benchmarking Library Performance on Lambda" translate="no">​</a></h3>
<p>The library was designed to operate on AWS Lambda. A series of benchmarks provided insights into its performance metrics, both in terms of rendering time and cost implications.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cost-and-timing-optimization-with-prototype-benchmarking">Cost and Timing Optimization with Prototype Benchmarking<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#cost-and-timing-optimization-with-prototype-benchmarking" class="hash-link" aria-label="Direct link to Cost and Timing Optimization with Prototype Benchmarking" title="Direct link to Cost and Timing Optimization with Prototype Benchmarking" translate="no">​</a></h3>
<p>While the library met our immediate requirements, it presented cost-related challenges for the future, inherently rendering at a rate of 1fps. Recognizing this, I built a simplified clone of the open-source library to conduct focused benchmarking. The tests indicated that by leveraging the library's approach, we could achieve up to 4 FPS. The primary limitation was identified as the screenshot capture time, which took approximately 200ms per frame. This understanding offered clarity on the potential to optimize and align with the company's future cost and performance goals.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="addressing-the-vp8-format-bottleneck">Addressing the VP8 Format Bottleneck<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#addressing-the-vp8-format-bottleneck" class="hash-link" aria-label="Direct link to Addressing the VP8 Format Bottleneck" title="Direct link to Addressing the VP8 Format Bottleneck" translate="no">​</a></h3>
<p>The human avatar component of our rendering pipeline employed the VP8 video format for transparency support. While the chosen open-source platform accommodated VP8, it did so with suboptimal speeds. After experimenting with ffmpeg's WebAssembly version to disintegrate the video into frame sequences, we decided to restructure the text-to-video stage. Instead of producing videos, it was reconfigured to generate images directly, yielding twin advantages in performance and cost.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="custom-ffmpeg-integration">Custom ffmpeg Integration<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#custom-ffmpeg-integration" class="hash-link" aria-label="Direct link to Custom ffmpeg Integration" title="Direct link to Custom ffmpeg Integration" translate="no">​</a></h3>
<p>Our use case demanded specific ffmpeg flags and a customized ffmpeg version – elements not supported natively by the library. To bridge this gap, I employed pnpm patching and automated the building of a custom ffmpeg version from its source.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-reusability-for-consistency">Code Reusability for Consistency<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#code-reusability-for-consistency" class="hash-link" aria-label="Direct link to Code Reusability for Consistency" title="Direct link to Code Reusability for Consistency" translate="no">​</a></h3>
<p>A design approach was adopted where the developed code functioned as a reusable library. This allowed its integration into both the frontend for previews and the backend for final video rendering, ensuring uniformity across stages.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="animation-and-transition-integration">Animation and Transition Integration<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#animation-and-transition-integration" class="hash-link" aria-label="Direct link to Animation and Transition Integration" title="Direct link to Animation and Transition Integration" translate="no">​</a></h3>
<p>The final development phase involved the addition of animation and scene transition capabilities to the platform.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="impact">Impact<a href="https://blog.vertexcover.io/video-rendering-pipeline-for-an-ai-driven-text-to-video-platform#impact" class="hash-link" aria-label="Direct link to Impact" title="Direct link to Impact" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>Stable Production Implementation</strong>: The solution has been integrated into production and operates with minimal disruptions. It is written in 100% typescript with ~90% test coverage.</p>
</li>
<li class="">
<p><strong>Consistent Previews and Renders</strong>: The disparity between previews and final video renders, previously a pain point, has been eradicated, ensuring consistent user expectations.</p>
</li>
<li class="">
<p><strong>Swift Feature Integration</strong>: The new system facilitated the rapid introduction of enhancements like custom fonts, animations, and scene transitions, effectively halving the time and effort previously required for such additions.</p>
</li>
<li class="">
<p><strong>Seamless Scaling</strong>: With the implemented improvements, the platform now comfortably handles the rendering of up to 100,000 videos daily without necessitating additional adjustments or overhead.</p>
</li>
</ul>]]></content:encoded>
            <category>Infrastructure</category>
        </item>
        <item>
            <title><![CDATA[ML Infra design for the GPU Poor]]></title>
            <link>https://blog.vertexcover.io/ml-infra-for-the-gpu-poor</link>
            <guid>https://blog.vertexcover.io/ml-infra-for-the-gpu-poor</guid>
            <pubDate>Thu, 31 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[ML Infra design for the GPU Poor]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="taming-the-beast-how-to-design-a-queueing-system-for-gpu-intensive-workloads">Taming the Beast: How to Design a Queueing System for GPU-Intensive Workloads<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#taming-the-beast-how-to-design-a-queueing-system-for-gpu-intensive-workloads" class="hash-link" aria-label="Direct link to Taming the Beast: How to Design a Queueing System for GPU-Intensive Workloads" title="Direct link to Taming the Beast: How to Design a Queueing System for GPU-Intensive Workloads" translate="no">​</a></h2>
<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>When designing for scale, the limiting factor is the GPU availability. So all rate limits / queueing must be designed around GPU availability.</p></div></div>
<!-- -->
<p><strong>A guide for the aspiring software engineer on managing demand when your most critical resource is scarce.</strong></p>
<p>Imagine you're building a revolutionary video generation service. Your platform is a hit, but you have a problem—a good problem, but a problem nonetheless. You have three types of customers, all knocking on your door at once:</p>
<ul>
<li class=""><strong>B2C Customers:</strong> Individuals using your web app to create short, fun videos. They expect results in seconds.</li>
<li class=""><strong>B2B Giants:</strong> Large enterprise clients who want to process massive workloads of tens of thousands of videos via your API.</li>
</ul>
<p>Here’s the catch: the heart of your operation, the GPU, is a fixed and expensive resource. Unlike CPU and memory, which are elastic and can be scaled on demand, your GPU capacity is limited. One B2B giant's request could monopolize your entire system, leaving your B2C users staring at a loading spinner for hours.</p>
<p>How do you design a system that ingests all these requests, keeps every customer type happy, and doesn't crumble under the pressure of this GPU bottleneck? The answer lies in the mathematical study of waiting lines: <strong>Queueing Theory</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-counter-intuitive-truth-about-being-busy">The Counter-Intuitive Truth About Being Busy<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#the-counter-intuitive-truth-about-being-busy" class="hash-link" aria-label="Direct link to The Counter-Intuitive Truth About Being Busy" title="Direct link to The Counter-Intuitive Truth About Being Busy" translate="no">​</a></h3>
<p>Before we design our system, we must understand a fundamental insight from queueing theory: <strong>wait times skyrocket as utilization exceeds 80%</strong>.</p>
<p>In simple terms, queueing theory uses a few key variables:</p>
<ul>
<li class=""><strong>Arrival Rate (λ - Lambda):</strong> How quickly tasks enter the queue.</li>
<li class=""><strong>Service Rate (μ - Mu):</strong> How quickly a server can process tasks.</li>
<li class=""><strong>Utilization (ρ - Rho):</strong> How busy a server is (λ/μ).</li>
</ul>
<div class="w-full bg-gradient-to-br from-gray-50 via-blue-50 to-purple-50 p-4 md:p-8"><div class="absolute inset-0 overflow-hidden pointer-events-none"><div class="absolute -inset-10 opacity-10"><div class="absolute top-1/4 left-1/4 w-64 h-64 bg-purple-300 rounded-full mix-blend-multiply filter blur-3xl animate-pulse"></div><div class="absolute top-3/4 right-1/4 w-64 h-64 bg-blue-300 rounded-full mix-blend-multiply filter blur-3xl animate-pulse delay-1000"></div><div class="absolute bottom-1/4 left-1/2 w-64 h-64 bg-indigo-300 rounded-full mix-blend-multiply filter blur-3xl animate-pulse delay-500"></div></div></div><div class="relative max-w-6xl mx-auto"><div class="backdrop-blur-xl bg-white bg-opacity-40 rounded-3xl border border-white border-opacity-30 shadow-2xl p-4 md:p-8 mb-6 md:mb-8 relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-tr from-white opacity-30 via-transparent to-transparent opacity-50 rounded-3xl"></div><h1 class="text-2xl md:text-4xl font-bold text-gray-800 mb-6 md:mb-8 text-center relative z-10">Queue Wait Time vs. System Utilization</h1><div class="relative z-10 flex justify-center overflow-x-auto"><svg width="520" height="280" viewBox="0 0 520 280" class="min-w-[520px] md:min-w-0 w-full max-w-2xl"><defs><linearGradient id="curveGradient" x1="0%" y1="0%" x2="100%" y2="0%"><stop offset="0%" stop-color="#10b981"></stop><stop offset="70%" stop-color="#f59e0b"></stop><stop offset="95%" stop-color="#ef4444"></stop></linearGradient><filter id="glow"><feGaussianBlur stdDeviation="2.5" result="coloredBlur"></feGaussianBlur><feMerge><feMergeNode in="coloredBlur"></feMergeNode><feMergeNode in="SourceGraphic"></feMergeNode></feMerge></filter></defs><line x1="60" y1="40" x2="60" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="148" y1="40" x2="148" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="236" y1="40" x2="236" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="324" y1="40" x2="324" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="412" y1="40" x2="412" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="500" y1="40" x2="500" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="240" x2="500" y2="240" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="197.89473684210526" x2="500" y2="197.89473684210526" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="145.26315789473685" x2="500" y2="145.26315789473685" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="92.63157894736844" x2="500" y2="92.63157894736844" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><line x1="60" y1="40" x2="500" y2="40" stroke="rgba(156, 163, 175, 0.2)" stroke-width="1"></line><path d="M 60 240 L 64.356 239.8947474736736 L 68.712 239.7873688506105 L 73.068 239.67779905292448 L 77.424 239.56597031938446 L 81.78 239.45181206567182 L 86.136 239.33525073581254 L 90.492 239.2162096441275 L 94.84800000000001 239.09460880698705 L 99.20400000000001 238.97036476359412 L 103.56 238.8433903849524 L 107.916 238.71359467010024 L 112.27199999999999 238.58088252860932 L 116.62800000000001 238.44515454825518 L 120.98400000000001 238.306306746667 L 125.34 238.16423030565255 L 129.69600000000003 238.01881128677206 L 134.05200000000002 237.86993032659802 L 138.40800000000002 237.71746230994864 L 142.764 237.5612760192142 L 147.12 237.401233757711 L 151.476 237.23719094479034 L 155.832 237.06899568020023 L 160.188 236.89648827494088 L 164.54399999999998 236.719500745568 L 168.9 236.53785626857842 L 173.25600000000003 236.35136859115198 L 177.61200000000002 236.15984139412268 L 181.96800000000002 235.96306760259807 L 186.32399999999998 235.76082863913888 L 190.68 235.55289361383544 L 195.036 235.33901844497262 L 199.39200000000002 235.11894490324173 L 203.748 234.8923995716307 L 208.104 234.65909271218445 L 212.45999999999998 234.4187170297588 L 216.816 234.1709463216774 L 221.172 233.91543400081395 L 225.528 233.65181147803784 L 229.884 233.37968638814826 L 234.24 233.09864064133845 L 238.596 232.80822827983948 L 242.952 232.50797311663274 L 247.308 232.19736612993393 L 251.664 231.8758625834608 L 256.02 231.54287883821365 L 260.376 231.1977888165143 L 264.73199999999997 230.8399200732334 L 269.08799999999997 230.46854942233634 L 273.44399999999996 230.08289805889748 L 277.8 229.68212610734759 L 282.156 229.26532651564278 L 286.51200000000006 228.83151820193518 L 290.86800000000005 228.37963834475732 L 295.22400000000005 227.90853368918644 L 299.58 227.416950719279 L 303.93600000000004 226.90352452045732 L 308.292 226.36676612347947 L 312.64799999999997 225.8050480828657 L 317.00399999999996 225.21658799559611 L 321.36 224.599429608504 L 325.716 223.95142109249392 L 330.072 223.27018997519693 L 334.428 222.55311411667623 L 338.78400000000005 221.79728797977475 L 343.14 220.9994832804311 L 347.496 220.1561028942813 L 351.852 219.2631266315477 L 356.208 218.31604715583327 L 360.56399999999996 217.30979389148163 L 364.91999999999996 216.23864220812618 L 369.276 215.09610444826305 L 373.632 213.87479841665444 L 377.988 212.5662876990529 L 382.344 211.1608865094674 L 386.7 209.64741951967298 L 391.056 208.0129240710824 L 395.412 206.24227797090538 L 399.768 204.31773023427752 L 404.124 202.21830390570275 L 408.48 199.91902834008096 L 412.836 197.38994128430616 L 417.192 194.59477599418312 L 421.548 191.48921096909407 L 425.904 188.01850231278908 L 430.26 184.1142287896397 L 434.616 179.6897357795566 L 438.972 174.6336280499374 L 443.328 168.80026152337368 L 447.68399999999997 161.99548492762602 L 452.04 153.9546112988894 L 456.396 144.3071857241489 L 460.752 132.51829124380453 L 465.10800000000006 117.7858896927058 L 469.464 98.85029576823908 L 473.82 73.61344537815125 L 478.176 40 L 482.532 40 L 486.888 40 L 491.24399999999997 40 L 495.6 40" fill="none" stroke="url(#curveGradient)" stroke-width="4" filter="url(#glow)" style="stroke-dasharray:1000;stroke-dashoffset:1000;transition:stroke-dashoffset 2s ease-in-out"></path><g transform="translate(60, 240)"><circle r="6" fill="#10b981" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">0%</text></g><g transform="translate(148, 237.3684210526316)"><circle r="6" fill="#10b981" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">20%</text></g><g transform="translate(280, 229.47368421052633)"><circle r="6" fill="#10b981" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">50%</text></g><g transform="translate(412, 197.89473684210526)"><circle r="6" fill="#f59e0b" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">80%</text></g><g transform="translate(478, 40.00000000000017)"><circle r="6" fill="#ef4444" stroke="white" stroke-width="2" class="cursor-pointer transition-all duration-300"></circle><text y="-18" fill="#374151" text-anchor="middle" class="text-sm font-semibold pointer-events-none">95%</text></g><text x="280" y="275" fill="#374151" text-anchor="middle" class="text-sm font-medium">System Utilization (ρ)</text><text x="10" y="140" fill="#374151" text-anchor="middle" class="text-sm font-medium" transform="rotate(-90 10 140)">Avg. Wait Time</text><text x="52" y="244" fill="#6b7280" text-anchor="end" class="text-xs">1<!-- -->x</text><text x="52" y="201.89473684210526" fill="#6b7280" text-anchor="end" class="text-xs">5<!-- -->x</text><text x="52" y="149.26315789473685" fill="#6b7280" text-anchor="end" class="text-xs">10<!-- -->x</text><text x="52" y="96.63157894736844" fill="#6b7280" text-anchor="end" class="text-xs">15<!-- -->x</text><text x="52" y="44" fill="#6b7280" text-anchor="end" class="text-xs">20<!-- -->x</text><text x="60" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">0%</text><text x="148" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">20%</text><text x="236" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">40%</text><text x="324" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">60%</text><text x="412" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">80%</text><text x="500" y="255" fill="#6b7280" text-anchor="middle" class="text-xs">100%</text></svg></div></div><div class="grid grid-cols-1 lg:grid-cols-3 gap-4 md:gap-6"><div class="lg:col-span-2 backdrop-blur-xl bg-white bg-opacity-40 rounded-2xl border border-white border-opacity-30 shadow-xl p-4 md:p-6 relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-br from-white opacity-20 via-transparent to-transparent opacity-30 rounded-2xl"></div><div class="relative z-10"><h3 class="text-lg md:text-xl font-bold text-gray-800 mb-4">Key Insight</h3><p class="text-gray-700 mb-4 text-sm md:text-base">As system load (utilization) nears its maximum capacity (100%), the time a new task has to wait in the queue increases <span class="text-red-600 font-bold">exponentially</span>, not linearly.</p><div class="space-y-2 md:space-y-3"><div class="flex items-center justify-between p-3 backdrop-blur-sm bg-white bg-opacity-30 rounded-lg border border-white border-opacity-20"><div class="flex items-center"><div class="w-3 h-3 rounded-full bg-emerald-500 mr-3"></div><span class="text-gray-800 text-sm md:text-base">Safe Zone (Under 80%)</span></div><span class="text-gray-600 font-medium text-sm md:text-base">Predictable &amp; Fast</span></div><div class="flex items-center justify-between p-3 backdrop-blur-sm bg-white bg-opacity-30 rounded-lg border border-white border-opacity-20"><div class="flex items-center"><div class="w-3 h-3 rounded-full bg-amber-500 mr-3"></div><span class="text-gray-800 text-sm md:text-base">Danger Zone (80-95%)</span></div><span class="text-gray-600 font-medium text-sm md:text-base">Wait times skyrocket</span></div><div class="flex items-center justify-between p-3 backdrop-blur-sm bg-white bg-opacity-30 rounded-lg border border-white border-opacity-20"><div class="flex items-center"><div class="w-3 h-3 rounded-full bg-red-500 mr-3"></div><span class="text-gray-800 text-sm md:text-base">Collapse (Above 95%)</span></div><span class="text-gray-600 font-medium text-sm md:text-base">System becomes unstable</span></div></div></div></div><div class="backdrop-blur-xl bg-white bg-opacity-40 rounded-2xl border border-white border-opacity-30 shadow-xl p-4 md:p-6 relative overflow-hidden"><div class="absolute inset-0 bg-gradient-to-tl from-blue-500 opacity-10 via-transparent to-transparent opacity-50 rounded-2xl"></div><div class="relative z-10"><div class="flex items-center mb-4"><div class="w-10 h-10 rounded-full bg-blue-500/80 flex items-center justify-center mr-3 border-2 border-white/50"><span class="text-white font-bold text-xl">💡</span></div><h3 class="text-lg md:text-xl font-bold text-gray-800">Design Rule</h3></div><p class="text-gray-700 text-sm md:text-base">To maintain a stable and predictable system, design your auto-scaling and rate-limiting to keep average utilization below the <b class="text-blue-700">~80% "knee"</b> of the curve.</p></div></div></div></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-architects-solution-from-one-big-line-to-a-multi-lane-highway">The Architect's Solution: From One Big Line to a Multi-Lane Highway<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#the-architects-solution-from-one-big-line-to-a-multi-lane-highway" class="hash-link" aria-label="Direct link to The Architect's Solution: From One Big Line to a Multi-Lane Highway" title="Direct link to The Architect's Solution: From One Big Line to a Multi-Lane Highway" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-the-foundational-shift-the-video-minute-as-the-true-unit-of-work">1. The Foundational Shift: The "Video-Minute" as the True Unit of Work<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#1-the-foundational-shift-the-video-minute-as-the-true-unit-of-work" class="hash-link" aria-label="Direct link to 1. The Foundational Shift: The &quot;Video-Minute&quot; as the True Unit of Work" title="Direct link to 1. The Foundational Shift: The &quot;Video-Minute&quot; as the True Unit of Work" translate="no">​</a></h4>
<p>The system was re-architected around the concept of a "video-minute." Instead of measuring queue length by the number of jobs, it was measured by the total duration of all videos waiting to be processed. This immediately provided a far more accurate picture of the outstanding load on the GPU fleet.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-architecture-the-two-lane-highway">2. Architecture: The Two-Lane Highway<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#2-architecture-the-two-lane-highway" class="hash-link" aria-label="Direct link to 2. Architecture: The Two-Lane Highway" title="Direct link to 2. Architecture: The Two-Lane Highway" translate="no">​</a></h4>
<p>The core idea of separating UI and batch users was validated and implemented.
Action: Two completely parallel infrastructures were created, each with its own dedicated queue and GPU fleet. This prevented any possibility of a "noisy neighbor" from the batch API world affecting the premium UI user experience. The UI queue was fed by a small, reserved pool of GPUs, while the batch queue was serviced by an auto-scaling fleet.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-smart-scaling-beyond-simple-queue-length">3. Smart Scaling: Beyond Simple Queue Length<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#3-smart-scaling-beyond-simple-queue-length" class="hash-link" aria-label="Direct link to 3. Smart Scaling: Beyond Simple Queue Length" title="Direct link to 3. Smart Scaling: Beyond Simple Queue Length" translate="no">​</a></h4>
<div class="w-full bg-gradient-to-br from-gray-50 via-indigo-50 to-blue-50 p-4 md:p-8"><div class="relative max-w-6xl mx-auto"><div class="backdrop-blur-xl bg-white bg-opacity-40 rounded-3xl border border-white border-opacity-30 shadow-2xl p-4 md:p-8 mb-6 md:mb-8"><h1 class="text-2xl md:text-4xl font-bold text-gray-800 mb-2 text-center">The GPU Scaling Decision</h1><p class="text-center text-gray-600 mb-8">When is a cold start worth the cost?</p><div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-8 px-4"><div><label for="cold-start-slider" class="block text-sm font-medium text-gray-700">GPU Cold Start Time: <span class="font-bold text-indigo-600">3<!-- --> min</span></label><input id="cold-start-slider" type="range" min="2" max="5" step="0.5" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-indigo-600" value="3"></div><div><label for="queue-length-slider" class="block text-sm font-medium text-gray-700">Queued Work: <span class="font-bold text-teal-600">8<!-- --> video-minutes</span></label><input id="queue-length-slider" type="range" min="0" max="20" step="1" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-teal-600" value="8"></div></div><div class="flex flex-col gap-8"><div class="flex justify-center"><div class="relative z-10 flex-shrink-0"><svg width="520" height="300" viewBox="0 0 520 300" class="min-w-[520px] md:min-w-0"><line x1="60" y1="40" x2="60" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="170" y1="40" x2="170" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="280" y1="40" x2="280" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="390" y1="40" x2="390" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="500" y1="40" x2="500" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="250" x2="500" y2="250" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="197.5" x2="500" y2="197.5" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="145" x2="500" y2="145" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="92.5" x2="500" y2="92.5" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="40" x2="500" y2="40" stroke="#e5e7eb" stroke-width="1" stroke-dasharray="2 2"></line><line x1="60" y1="250" x2="500" y2="250" stroke="#6b7280" stroke-width="2"></line><line x1="60" y1="40" x2="60" y2="250" stroke="#6b7280" stroke-width="2"></line><g><line x1="60" y1="250" x2="60" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="60" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">0</text></g><g><line x1="170" y1="250" x2="170" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="170" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">5</text></g><g><line x1="280" y1="250" x2="280" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="280" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">10</text></g><g><line x1="390" y1="250" x2="390" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="390" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">15</text></g><g><line x1="500" y1="250" x2="500" y2="255" stroke="#6b7280" stroke-width="1"></line><text x="500" y="268" text-anchor="middle" class="text-xs fill-gray-600 font-medium">20</text></g><g><line x1="55" y1="250" x2="60" y2="250" stroke="#6b7280" stroke-width="1"></line><text x="50" y="254" text-anchor="end" class="text-xs fill-gray-600 font-medium">0</text></g><g><line x1="55" y1="197.5" x2="60" y2="197.5" stroke="#6b7280" stroke-width="1"></line><text x="50" y="201.5" text-anchor="end" class="text-xs fill-gray-600 font-medium">5</text></g><g><line x1="55" y1="145" x2="60" y2="145" stroke="#6b7280" stroke-width="1"></line><text x="50" y="149" text-anchor="end" class="text-xs fill-gray-600 font-medium">10</text></g><g><line x1="55" y1="92.5" x2="60" y2="92.5" stroke="#6b7280" stroke-width="1"></line><text x="50" y="96.5" text-anchor="end" class="text-xs fill-gray-600 font-medium">15</text></g><g><line x1="55" y1="40" x2="60" y2="40" stroke="#6b7280" stroke-width="1"></line><text x="50" y="44" text-anchor="end" class="text-xs fill-gray-600 font-medium">20</text></g><line x1="192" y1="40" x2="192" y2="250" stroke="#1e40af" stroke-width="2" stroke-dasharray="5 5"></line><path d="M 60 250 L 500 40" stroke="#f59e0b" stroke-width="3" fill="none" stroke-dasharray="6 4"></path><path d="M 60 218.5 L 500 113.5" stroke="#14b8a6" stroke-width="3" fill="none"></path><circle cx="192" cy="187" r="6" fill="#1e40af" stroke="white" stroke-width="2"></circle><text x="192" y="175" text-anchor="middle" class="text-xs font-bold fill-blue-800">Breakeven</text><text x="192" y="207" text-anchor="middle" class="text-xs font-bold fill-blue-800">6.0</text><line x1="236" y1="40" x2="236" y2="250" stroke="#4f46e5" stroke-width="2" stroke-dasharray="3 3"></line><circle cx="236" cy="166" r="5" fill="#f59e0b" stroke="white" stroke-width="2"></circle><circle cx="236" cy="176.5" r="5" fill="#14b8a6" stroke="white" stroke-width="2"></circle><text x="236" y="32" text-anchor="middle" class="text-xs font-bold fill-indigo-700">8</text><text x="280" y="290" text-anchor="middle" class="text-sm font-medium fill-gray-600">Video-Minutes in Queue</text><text x="15" y="145" text-anchor="middle" transform="rotate(-90 15 145)" class="text-sm font-medium fill-gray-600">Time to Complete (min)</text></svg></div></div><div class="max-w-4xl mx-auto w-full"><div class="p-6 bg-white/60 rounded-2xl border border-white/30 shadow-lg backdrop-blur-sm"><h3 class="text-xl font-bold text-gray-800 mb-6 text-center">Calculated Outcome</h3><div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6"><div class="flex items-center justify-between p-4 bg-amber-100/70 rounded-xl border border-amber-200/50"><span class="font-medium text-amber-800 text-lg">Time if you WAIT:</span><span class="font-bold text-2xl text-amber-900">8.0<!-- --> min</span></div><div class="flex items-center justify-between p-4 bg-teal-100/70 rounded-xl border border-teal-200/50"><span class="font-medium text-teal-800 text-lg">Time if you SCALE:</span><span class="font-bold text-2xl text-teal-900">7.0<!-- --> min</span></div></div><div class="grid grid-cols-1 lg:grid-cols-2 gap-6 items-center"><div class="flex justify-center lg:justify-start"><div class="px-8 py-4 rounded-xl text-center shadow-md min-w-[200px] bg-gradient-to-r from-teal-500 to-teal-600"><span class="text-white font-bold text-2xl tracking-wider drop-shadow-sm">SCALE NOW</span></div></div><div class="text-center lg:text-left"><h4 class="font-semibold text-gray-700 flex items-center justify-center lg:justify-start gap-2 mb-3">💡 Key Insight:</h4><p class="text-sm text-gray-600 leading-relaxed mb-3">It only makes sense to provision a new GPU when the queue length is more than <b class="text-indigo-700">twice the cold start time</b>.</p><div class="inline-block p-3 bg-indigo-50/70 rounded-lg border border-indigo-200/50"><p class="font-bold text-lg text-indigo-800">Breakeven at <!-- -->6.0<!-- --> video-minutes</p></div></div></div></div></div><div class="flex justify-center"><div class="p-4 bg-white/60 rounded-xl border border-white/30 shadow-md backdrop-blur-sm"><div class="flex items-center justify-center gap-8"><div class="flex items-center gap-3"><div class="w-4 h-4 bg-amber-500 rounded border-2 border-amber-600"></div><span class="text-sm font-medium text-gray-700">Wait (Don't Scale)</span></div><div class="flex items-center gap-3"><div class="w-4 h-4 bg-teal-500 rounded border-2 border-teal-600"></div><span class="text-sm font-medium text-gray-700">Scale Now</span></div></div></div></div></div></div></div></div>
<p>Yes, we should auto-scale the GPU, but how much? There are few places we can look for data to make informed choice.</p>
<ul>
<li class="">Historical Learning: The scaling logic was made parametric to learn from historical provisioning times, helping it make smarter predictions about when to initiate scaling.</li>
<li class="">Metric-Driven Scaling: The auto-scaler was triggered based on "video-minutes".</li>
<li class="">Cold Start problem: There is 2-4 minute cold-start time for GPUs. So, provisioning a GPU only makes sense if the <code>video-minutes</code> to be processed are <code>X</code> times of cold start time. That way, frequent GPU provisioning does not lead inefficient compute. It's economically inefficient to provision a new GPU that takes 3 minutes to start, only to process a 2-minute video.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-predictability-through-pragmatism-working-backwards-from-limits">4. Predictability Through Pragmatism: Working backwards from limits<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#4-predictability-through-pragmatism-working-backwards-from-limits" class="hash-link" aria-label="Direct link to 4. Predictability Through Pragmatism: Working backwards from limits" title="Direct link to 4. Predictability Through Pragmatism: Working backwards from limits" translate="no">​</a></h4>
<p>The team acknowledged a hard truth: their ability to autoscale was not infinite. Based on historical data and cloud provider limits, they identified a realistic maximum number of GPUs they could reliably provision.
The fixed maximum capacity (Max GPUs * video-minutes per GPU) became the system's total throughput budget. This budget was then divided among the maximum number of potential concurrent batch users.
Result: This calculation yielded a crucial metric: the maximum video-minutes per minute that could be allocated to a single user. This became the foundation for providing realistic SLAs.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-the-slas-per-tenant-throttling-and-dynamic-etas">5. The SLAs: Per-Tenant Throttling and Dynamic ETAs<a href="https://blog.vertexcover.io/ml-infra-for-the-gpu-poor#5-the-slas-per-tenant-throttling-and-dynamic-etas" class="hash-link" aria-label="Direct link to 5. The SLAs: Per-Tenant Throttling and Dynamic ETAs" title="Direct link to 5. The SLAs: Per-Tenant Throttling and Dynamic ETAs" translate="no">​</a></h4>
<p>This per-user capacity allocation was not just a theoretical number; it was enforced at the ingestion layer.
Action: A user-aware rate limiter was placed at the front of the batch queue. If a user was allocated a capacity of "1 video-minute per minute", this gatekeeper would only release that amount of work from that user's batch into the main queue each minute.
Accurate SLAs: This system allowed for incredibly predictable SLAs. If a user with a 1 video-minute/minute capacity submitted a batch of 100 jobs totaling 200 video-minutes, the system could confidently return an ETA of ~200 minutes plus a safety buffer, because it knew exactly how fast that user's jobs would be fed to the processors.</p>]]></content:encoded>
            <category>Infrastructure</category>
        </item>
        <item>
            <title><![CDATA[Strot - The API Scraper]]></title>
            <link>https://blog.vertexcover.io/strot-is-a-api-scraper</link>
            <guid>https://blog.vertexcover.io/strot-is-a-api-scraper</guid>
            <pubDate>Mon, 28 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Strot (Sanskrit meaning source) is an AI agent which scrapes web api:]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p>Strot (Sanskrit meaning source) is an AI agent which scrapes web api:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Instead of scraping the dom, identifies the right api call.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Fast, reliable, complete data scraping for listing data is possible via API scraping. </li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Strot figures the api call so you don't have to.</li></ol></div></div>
<p><a href="https://github.com/vertexcover-io/strot" target="_blank" rel="noopener noreferrer" class="">Try out Strot!</a></p>
<!-- -->
<div style="position:relative;width:100%;padding-bottom:56.25%;height:0"><iframe src="https://www.youtube.com/embed/OCL3rWG9mDs" title="Strot - The API Scraper Demo" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="position:absolute;top:0;left:0;width:100%;height:100%;border:none"></iframe></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-if--">What if ... ?<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#what-if--" class="hash-link" aria-label="Direct link to What if ... ?" title="Direct link to What if ... ?" translate="no">​</a></h2>
<p>When working with clients, we figured that they frequently need to scrape listing data like reviews and product listings. The DOM Scraping solutions don't give complete data.</p>
<p>When is comes to scraping reviews, things CAN BE slightly different than running playwright scripts. That's the idea we started with!</p>
<p>It stems from the insights on browsing shopify. Since, shopify has plugin ecosystem, a lot of reviews come from plugins. They give the reviews in html / json form via api that the page renders.
Since, reviews - if they are worthwhile - would be in 100s for a given product, it would be very unlikely that someone with good web-dev practices will send all of them on one shot. There MUST be a second call (pagination) that requests for further reviews for the given product.</p>
<p>What if ... we could scrape listing data via intercepting AJAX calls that are made from the browser itself?</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-genesis">The Genesis<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#the-genesis" class="hash-link" aria-label="Direct link to The Genesis" title="Direct link to The Genesis" translate="no">​</a></h2>
<p>Hence, an experiment is born - called <code>strot</code>. In sanskrit it means source. We are trying to get to the ajax calls that gets us listing data.</p>
<p>The review scraping problem sits at a unique position. There are always MANY reviews which either causes cost ballooning no matter which existing approach you take.</p>
<p>Strot is the only project which can scrape the data available as api call - at all - using natural language.</p>
<div style="overflow-x:auto;margin:20px 0"><table style="width:100%;border-collapse:collapse;font-size:14px;border:1px solid var(--comparison-border)"><thead><tr style="background-color:var(--comparison-header-bg)"><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">Feature</th><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">Playwright</th><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">LLM Scraper</th><th style="padding:12px;text-align:left;border-bottom:2px solid var(--comparison-border);font-weight:bold">Strot (Ours)</th></tr></thead><tbody><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Cost</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">Infrastructure costs for automation</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Pay per page + LLM inference</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">One-time API discovery</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Maintenance</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">High - UI changes break scripts</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">Medium - prompt engineering needed</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Low - APIs rarely change</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Intelligence Required</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">High - manual scraper</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">High - per page analysis</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">One-time - for API discovery</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Scalability</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Poor - loads full pages</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Expensive - each page costs $</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Excellent - pagination via API</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Setup Complexity</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-medium)">Medium - browser automation</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Low - plug and play</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Low - plug and play</td></tr><tr><td style="padding:12px;border-bottom:1px solid var(--comparison-border);font-weight:bold">Uniqueness</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Common approach</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-poor)">Common approach</td><td style="padding:12px;border-bottom:1px solid var(--comparison-border);background-color:var(--comparison-good)">Unique to us</td></tr></tbody></table></div>
<p>So, IF we could find the ajax call → we only have to spend time figuring out the API call. and voila! You can simply call API - this is cheapest, fastest, most reliable approach of all.</p>
<p>And the unique to us. Hence, we took a bite.</p>
<p>But the challenge is which api call is most relevnt for scraping reviews ?
we solve this by capturing screenshot, visually analysing if review is preseng in the screenshot. Then we find a matching ajax call that has a similar content. Voila!</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-challenges-of-current-approaches">The challenges of current approaches<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#the-challenges-of-current-approaches" class="hash-link" aria-label="Direct link to The challenges of current approaches" title="Direct link to The challenges of current approaches" translate="no">​</a></h2>
<p>Each traditional approach faces fundamental limitations that compound at scale:</p>
<div style="background-color:rgba(207, 34, 46, 0.1);border:1px solid rgba(207, 34, 46, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #cf222e;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">🐛</span><strong style="color:#cf222e;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Edge Case<!-- -->: <!-- -->The Listing Data has Volume Problem</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Most products with worthwhile reviews have 100-10,000+ reviews. Traditional approaches cost:</p><ul>
<li class=""><strong>Playwright</strong>: 100 reviews × 3 pages × 10s load time = 30+ minutes</li>
<li class=""><strong>LLM Scraper</strong>: 100 reviews × $0.10 per page = $10+ per product</li>
<li class=""><strong>Manual API</strong>: 100 reviews × 15min engineer time = $200+ per product</li>
</ul><p>Strot's approach: 100 reviews × 0.1s API call = 10 seconds total.</p></div></div>
<h1>Technical Details</h1>
<div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">🔍</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->System Architecture &amp; Technical Approach</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">▼</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div>
<div style="background-color:rgba(26, 127, 55, 0.1);border:1px solid rgba(26, 127, 55, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #1a7f37;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">🏗️</span><strong style="color:#1a7f37;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Architecture Detail<!-- -->: <!-- -->Why AJAX Interception vs DOM Scraping</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Traditional DOM scraping faces several fundamental limitations:</p><ul>
<li class=""><strong>Rate Limiting</strong>: Websites throttle based on page loads, not API calls</li>
<li class=""><strong>Bot Detection</strong>: Full page loads trigger anti-bot measures (Cloudflare, etc.)</li>
<li class=""><strong>Resource Overhead</strong>: Loading entire DOM + assets vs lightweight JSON responses</li>
<li class=""><strong>Maintenance Burden</strong>: CSS selectors break with UI changes, APIs rarely change</li>
</ul><p>AJAX interception bypasses these by operating at the data layer, not presentation layer.</p></div></div>
<div style="background-color:rgba(9, 105, 218, 0.1);border:1px solid rgba(9, 105, 218, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #0969da;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">💾</span><strong style="color:#0969da;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Implementation Note<!-- -->: <!-- -->AJAX Call Matching Algorithm</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Our matching algorithm works in stages:</p><ol>
<li class=""><strong>Content Extraction</strong>: Extract review text from screenshots using OCR + Vision LLM</li>
<li class=""><strong>API Response Analysis</strong>: Parse all captured AJAX responses for text content</li>
<li class=""><strong>Fuzzy String Matching</strong>: Use algorithms like Levenshtein distance, Jaccard similarity</li>
<li class=""><strong>Confidence Scoring</strong>:<!-- -->
<ul>
<li class="">Text overlap ratio (&gt;90% = high confidence)</li>
<li class="">JSON structure analysis (nested objects, review-like fields)</li>
<li class="">Response size correlation with visible review count</li>
</ul>
</li>
</ol><p><strong>Edge Case Handling</strong>:</p><ul>
<li class="">Paginated responses (partial matches expected)</li>
<li class="">Localized content (different languages)</li>
<li class="">Dynamic timestamps/IDs (filter out volatile fields)</li>
</ul></div></div>
<div style="background-color:rgba(191, 135, 0, 0.1);border:1px solid rgba(191, 135, 0, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #bf8700;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">⚡</span><strong style="color:#bf8700;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Performance Insight<!-- -->: <!-- -->Why Screenshot Analysis vs Pure Network Analysis</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Since we have to do the hard part of finding the right AJAX call ONLY once, it means that we can use augmentation from vision understanding to make it more accurate.</p><p>This helps by:</p><ul>
<li class="">Confirms which API calls actually render user-visible content.</li>
<li class="">Handles cases where multiple API calls contain review data</li>
<li class="">Eliminates false positives from internal/admin API calls</li>
</ul></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-codegen">The codegen<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#the-codegen" class="hash-link" aria-label="Direct link to The codegen" title="Direct link to The codegen" translate="no">​</a></h3>
<p>We internally represent all the relevant information as json. This helps us to generate http client in any language of choice. Calling this API endpoint in succession will give all the reviews.</p>
<div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">🔍</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->Code Generation Pipeline &amp; Implementation</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">▼</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div>
<div style="margin:48px 0;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:32px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04)"><div style="margin-bottom:32px"><div style="display:flex;align-items:center;margin-bottom:8px"><div style="width:4px;height:32px;background-color:var(--ifm-color-primary, #2e8555);border-radius:2px;margin-right:16px"></div><h2 style="font-size:1.8rem;font-weight:700;margin:0;background:linear-gradient(135deg, var(--ifm-color-primary, #2e8555), var(--ifm-color-primary-light, #33925d));-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text">Iteratively Improving via Error Analysis and Evals</h2></div><div style="height:1px;background:linear-gradient(90deg, var(--ifm-color-primary, #2e8555) 0%, transparent 100%);width:100%;opacity:0.3"></div></div><div style="line-height:1.7"><p>Evals were central to us while building this. We had three tiered system for evals that served us well.</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Does the analysis identify the right ajax call?</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Is the pagination strategy detection done correctly?</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Is the http api (codegen) able to get all the reviews?</li></ol><div style="background-color:var(--ifm-background-surface-color, #ffffff);border:1px solid var(--ifm-color-emphasis-300, #d0d7de);border-radius:12px;margin:20px 0;overflow:hidden;box-shadow:0 2px 8px rgba(0, 0, 0, 0.06);transition:all 0.2s ease-in-out"><div style="background-color:var(--ifm-color-emphasis-100, #f6f8fa);padding:16px 20px;cursor:pointer;display:flex;align-items:center;justify-content:space-between;border-bottom:none;transition:background-color 0.2s ease-in-out;user-select:none"><div style="display:flex;align-items:center"><span style="font-size:1.2rem;margin-right:8px">🔍</span><strong style="color:var(--ifm-color-primary, #2e8555);font-size:1.1rem;font-weight:600">Deep Dive: <!-- -->Comprehensive Evaluation System Architecture</strong></div><div style="transform:rotate(0deg);transition:transform 0.2s ease-in-out;font-size:1.2rem;color:var(--ifm-color-emphasis-600, #656d76)">▼</div></div><style>
          @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
          }
        </style></div><div style="margin-bottom:32px;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:24px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04);transition:all 0.2s ease-in-out"><h4 style="font-size:1.3rem;font-weight:700;margin-bottom:16px;color:var(--ifm-color-primary, #2e8555)">Error Analysis</h4><div style="font-size:1rem;line-height:1.7"><p>This was the most consuming element for us until we vibe-coded initial version of this dashboard to see the logs as data.</p><div style="background-color:rgba(9, 105, 218, 0.1);border:1px solid rgba(9, 105, 218, 0.3);border-radius:8px;padding:16px 20px;margin:16px 0;border-left:4px solid #0969da;position:relative;transition:all 0.2s ease-in-out"><div style="display:flex;align-items:center;margin-bottom:12px"><span style="font-size:1.1rem;margin-right:8px">💾</span><strong style="color:#0969da;font-size:1rem;font-weight:600;text-transform:uppercase;letter-spacing:0.5px">Implementation Note<!-- -->: <!-- -->Observability Dashboard</strong></div><div style="font-size:1rem;line-height:1.6;color:var(--ifm-color-content, #1c1e21)"><p>Our observability dashboard processes shows data from:</p><ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">Application logs (structured JSON)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">LLM API call traces (OpenAI/Anthropic)</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">Playwright screenshots</li></ol><p>This helps to do the error analysis and improve the system iteratively.</p></div></div><p>Here is a quick peek over the dashboard we made to do the error analysis:</p><p>This shows us the cost and token usage:</p><a href="https://blog.vertexcover.io/img/strot-dashboard-analysis.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-analysis.png" alt="Strot dashboard cost and token analysis" style="cursor:pointer"></a><p>This shows us the step by step observability into what is happening:</p><a href="https://blog.vertexcover.io/img/strot-dashboard-step.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-step.png" alt="Strot dashboard step by step analysis" style="cursor:pointer"></a></div></div><div style="margin-bottom:32px;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:24px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04);transition:all 0.2s ease-in-out"><h4 style="font-size:1.3rem;font-weight:700;margin-bottom:16px;color:var(--ifm-color-primary, #2e8555)">Pagination</h4><div style="font-size:1rem;line-height:1.7"><a href="https://blog.vertexcover.io/img/strot-dashboard-pagination.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-pagination.png" alt="Strot dashboard pagination" style="cursor:pointer"></a></div></div><div style="margin-bottom:32px;background:var(--ifm-background-surface-color, #ffffff);border-radius:12px;padding:24px;border:1px solid var(--ifm-color-emphasis-200, #e3e5e7);box-shadow:0 2px 8px rgba(0, 0, 0, 0.04);transition:all 0.2s ease-in-out"><h4 style="font-size:1.3rem;font-weight:700;margin-bottom:16px;color:var(--ifm-color-primary, #2e8555)">Codegen</h4><div style="font-size:1rem;line-height:1.7"><a href="https://blog.vertexcover.io/img/strot-dashboard-codegen.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.vertexcover.io/img/strot-dashboard-codegen.png" alt="Strot dashboard codegen" style="cursor:pointer"></a></div></div></div></div>
<p>We are also learning. This was our attempt at scraping the webpage and using the visual understanding of image models to get to the reviews faster. if you feel this can be improved, feel free to share those with us on <a href="https://github.com/vertexcover-io/strot/issues" target="_blank" rel="noopener noreferrer" class="">github-issues</a>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="roadmap">Roadmap<a href="https://blog.vertexcover.io/strot-is-a-api-scraper#roadmap" class="hash-link" aria-label="Direct link to Roadmap" title="Direct link to Roadmap" translate="no">​</a></h2>
<ol style="padding-left:20px;margin:16px 0;line-height:1.6;list-style:decimal;list-style-type:decimal;list-style-position:outside" start="1"><li style="margin-bottom:8px;padding-left:8px;display:list-item">We are already on a path to make this a generic scraper. Currently, our evals sets show the tracking progress on various websites. It will be released soon.</li><li style="margin-bottom:8px;padding-left:8px;display:list-item">if you would like us to host this as a service for you, we are more than happy to. Come chat with us at [contact email]</li></ol>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Teaching Claude Code to Work Independently]]></title>
            <link>https://blog.vertexcover.io/claude-code-context-engineering-v2</link>
            <guid>https://blog.vertexcover.io/claude-code-context-engineering-v2</guid>
            <pubDate>Mon, 21 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Problem: You're trapped micromanaging Claude Code instead of building]]></description>
            <content:encoded><![CDATA[<div class="bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg p-4 my-5 border-l-4 border-l-blue-500 dark:border-l-blue-400"><strong class="text-blue-600 dark:text-blue-400 text-sm uppercase tracking-wide font-semibold">TL;DR:</strong><div class="mt-2 text-gray-800 dark:text-gray-200"><p><strong>Problem:</strong> You're trapped micromanaging Claude Code instead of building</p><p><strong>Solution:</strong> Train Claude Code once, then let it work autonomously</p><p><strong>How:</strong> Strategic context engineering: CLAUDE.md files, systematic workflows, and learning capture</p><p><strong>Result:</strong> Claude Code becomes your autonomous teammate</p></div></div>
<p>Here is <a href="https://gist.github.com/tripathi456/bfaf9add4b70bff131cd574c2f93cfac" target="_blank" rel="noopener noreferrer" class="">CLAUDE.md</a></p>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="day-0-just-moved-from-cursor-to-claude-code">Day 0: Just moved from cursor to claude code<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-0-just-moved-from-cursor-to-claude-code" class="hash-link" aria-label="Direct link to Day 0: Just moved from cursor to claude code" title="Direct link to Day 0: Just moved from cursor to claude code" translate="no">​</a></h2>
<p><em>It's 11 PM on a Tuesday. My token budget just hit zero. Claude Code is asking me the same question for the fourth time: "What coding style does this project use?" I've spent 6 hours being a glorified copy-paste machine, explaining the same context over and over.</em></p>
<p><em>Sound familiar?</em></p>
<p>That night, I realized something critical: <strong>Claude Code is teachable</strong>. But I was the worst teacher on Earth.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="day-1-fighting-claude-code-the-problem">Day 1: Fighting Claude Code (The Problem)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-1-fighting-claude-code-the-problem" class="hash-link" aria-label="Direct link to Day 1: Fighting Claude Code (The Problem)" title="Direct link to Day 1: Fighting Claude Code (The Problem)" translate="no">​</a></h2>
<p>Every conversation was Groundhog Day:</p>
<ul>
<li class="">"What's our testing framework again?"</li>
<li class="">"How do we name files in this project?"</li>
<li class="">"What's the deployment process?"</li>
</ul>
<p>I was Claude Code's personal Wikipedia. <strong>This had to change.</strong></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="day-2-the-teaching-template-the-mentor">Day 2: The Teaching Template (The Mentor)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-2-the-teaching-template-the-mentor" class="hash-link" aria-label="Direct link to Day 2: The Teaching Template (The Mentor)" title="Direct link to Day 2: The Teaching Template (The Mentor)" translate="no">​</a></h2>
<blockquote>
<p>What if Claude Code could remember your project like a team member who's been there for years?</p>
</blockquote>
<p>Instead of explaining everything every time, I wrote a template. The gist is:</p>
<div class="language-md codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-md codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> Communication: Be concise, reference past learnings from docs/work/</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> File Naming: YYYY-MM-DD-[001]-[category]-[summary].md  </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> Never code without checking docs/work/ for similar past solutions</span><br></span></code></pre></div></div>
<p>That's it. <strong>This eliminated hours of repetitive context.</strong></p>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>See the prompt →</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-md codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-md codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token title important punctuation" style="color:#393A34">#</span><span class="token title important"> Project: [Your Project Name]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Tech Stack &amp; Tooling</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Language</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Python 3.11+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Package Manager</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: </span><span class="token code-snippet code keyword" style="color:#00009f">`uv`</span><span class="token plain"> (use </span><span class="token code-snippet code keyword" style="color:#00009f">`uv add &lt;dependency&gt;`</span><span class="token plain">, </span><span class="token code-snippet code keyword" style="color:#00009f">`uv run &lt;script&gt;`</span><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Testing</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: pytest with coverage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Linting</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: ruff + mypy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Systematic File Naming</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Format: </span><span class="token code-snippet code keyword" style="color:#00009f">`YYYY-MM-DD-[001-999]-[category]-[four-word-summary].md`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Folder: </span><span class="token code-snippet code keyword" style="color:#00009f">`docs/work/`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Categories: </span><span class="token code-snippet code keyword" style="color:#00009f">`bug`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`feature`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`task`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`research`</span><span class="token plain"> | </span><span class="token code-snippet code keyword" style="color:#00009f">`learnings`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Examples:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token code-snippet code keyword" style="color:#00009f">`2025-07-18-001-feature-user-authentication-system.md`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token code-snippet code keyword" style="color:#00009f">`2025-07-18-002-bug-database-connection-timeout.md`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Communication Style</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Concise</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: No fluff, direct responses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Evidence-based</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Show, don't just tell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Contextual</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Reference past learnings from </span><span class="token code-snippet code keyword" style="color:#00009f">`docs/work/`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token title important punctuation" style="color:#393A34">##</span><span class="token title important"> Planning Protocol</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">1.</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Context Gathering</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Check </span><span class="token code-snippet code keyword" style="color:#00009f">`docs/work/`</span><span class="token plain"> for relevant past decisions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">2.</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Assumption Documentation</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Explicit assumptions in plan files</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">3.</span><span class="token plain"> </span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token bold content">Execution Gate</span><span class="token bold punctuation" style="color:#393A34">**</span><span class="token plain">: Only proceed after planning is complete</span><br></span></code></pre></div></div></div></div></div>
<p><strong>The transformation was instant.</strong> Claude Code started referencing past decisions, avoiding repeated mistakes, and building on previous work. <strong>It finally felt like working with a teammate.</strong></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="day-3-the-learning-moment---30-context---the-training">Day 3: The Learning Moment - 30% context - (The Training)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-3-the-learning-moment---30-context---the-training" class="hash-link" aria-label="Direct link to Day 3: The Learning Moment - 30% context - (The Training)" title="Direct link to Day 3: The Learning Moment - 30% context - (The Training)" translate="no">​</a></h2>
<blockquote>
<p>What if Claude Code could learn from every mistake and never repeat it?</p>
</blockquote>
<p>When your context hits 30%, you have one chance to crystallize everything learned. Miss it, and you go back to day 1.</p>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>See the prompt →</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-md codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-md codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">When context drops below 30%: </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">1.</span><span class="token plain"> Document every decision made</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">2.</span><span class="token plain"> List what failed (with code snippets)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">3.</span><span class="token plain"> Note what worked brilliantly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token list punctuation" style="color:#393A34">4.</span><span class="token plain"> Write handoff notes for next session</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Use the </span><span class="token code-snippet code keyword" style="color:#00009f">`Systematic File Naming`</span><span class="token plain"> given above.</span><br></span></code></pre></div></div></div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="day-4-the-autonomous-engineer-the-victory">Day 4: The Autonomous Engineer (The Victory)<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#day-4-the-autonomous-engineer-the-victory" class="hash-link" aria-label="Direct link to Day 4: The Autonomous Engineer (The Victory)" title="Direct link to Day 4: The Autonomous Engineer (The Victory)" translate="no">​</a></h2>
<p>I saw this tweet - <a href="https://x.com/_svs_/status/1928753160337637726" target="_blank" rel="noopener noreferrer" class="">@svs used Claude Code as an MCP client to write an MCP server</a>.</p>
<p>Something magical discovered: <strong>When put in verifiable workflows, Claude Code started working much better!</strong>:</p>
<ul>
<li class="">Write code → Run tests → Fix failures → Repeat</li>
<li class="">Build feature → Deploy to staging → Check logs → Iterate</li>
<li class="">Analyze data → Generate insights → Verify against sources → Summarize</li>
</ul>
<p><strong>I wasn't micromanaging anymore. I was collaborating.</strong></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="stories-from-other-folks">Stories from other folks<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#stories-from-other-folks" class="hash-link" aria-label="Direct link to Stories from other folks" title="Direct link to Stories from other folks" translate="no">​</a></h2>
<p>Met awesome folks at <a href="https://hasgeek.com/fifthelephant/2025/" target="_blank" rel="noopener noreferrer" class="">Fifth Elephant Conference</a> where we shared claude code learnings.</p>
<div class="relative bg-emerald-50 bg-opacity-30 dark:bg-emerald-950 dark:bg-opacity-10 rounded-xl p-6 my-8 border-2 border-emerald-200 dark:border-emerald-800"><div class="absolute top-0 right-0 w-12 h-12 overflow-hidden"><div class="absolute top-0 right-0 w-0 h-0 border-l-12 border-b-12 border-l-transparent border-b-emerald-200 dark:border-b-emerald-800"></div></div><div class="flex items-center gap-3 mb-4"><div class="flex-shrink-0 w-10 h-10 bg-emerald-100 dark:bg-emerald-900 dark:bg-opacity-30 rounded-full flex items-center justify-center"><svg class="w-5 h-5 text-emerald-600 dark:text-emerald-400" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg></div><div><div class="text-xs font-medium text-emerald-700 dark:text-emerald-300 uppercase tracking-wide">Pro Tips from</div><a href="https://www.linkedin.com/in/codingnirvana/" target="_blank" rel="noopener noreferrer" class="text-lg font-semibold text-emerald-900 dark:text-emerald-100 hover:text-emerald-700 dark:hover:text-emerald-300 transition-colors">Rajesh</a></div></div><div class="border-l-4 border-emerald-300 dark:border-emerald-700 pl-4 text-gray-700 dark:text-gray-300"><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-token-budget-hack-that-doubled-my-productivity">The Token Budget Hack That Doubled My Productivity<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#the-token-budget-hack-that-doubled-my-productivity" class="hash-link" aria-label="Direct link to The Token Budget Hack That Doubled My Productivity" title="Direct link to The Token Budget Hack That Doubled My Productivity" translate="no">​</a></h3><p>Rajesh was burning through tokens like crazy at his startup. Then he discovered something weird about Claude's <a href="https://support.anthropic.com/en/articles/11145838-using-claude-code-with-your-pro-or-max-plan" target="_blank" rel="noopener noreferrer" class="">5-hour windows</a>.</p><p><strong>His discovery:</strong> Start sessions at 7 AM instead of 9 AM.</p><p>Why? The overlapping windows create a "double token zone" during peak hours:</p><p><strong>Before:</strong> 9am-2pm, 2pm-7pm (standard)<br>
<strong>After:</strong> 7am-12pm, 12pm-5pm, 5pm-10pm (overlapping)</p><p><strong>Result:</strong> Between 9am-5pm = <strong>double tokens available</strong></p><img src="https://blog.vertexcover.io/img/timeline.svg"><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-csv-strategy-that-saved-hours">The CSV Strategy That Saved Hours<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#the-csv-strategy-that-saved-hours" class="hash-link" aria-label="Direct link to The CSV Strategy That Saved Hours" title="Direct link to The CSV Strategy That Saved Hours" translate="no">​</a></h3><p>Rajesh's team was dealing with lots of data analysis requests. CSV files everywhere. Claude kept hitting context limits trying to process raw data.</p><p><strong>The breakthrough:</strong> Stop feeding Claude data. Feed it scripts.</p><p><strong>Old way:</strong> "Here's a 10MB CSV, analyze it"<br>
<strong>New way:</strong> "Write a script to analyze this CSV type, then run it"</p><p><strong>Why it works:</strong> Scripts are tiny. Results are focused. Claude guides itself using its own analysis output.</p></div></div>
<div class="relative bg-emerald-50 bg-opacity-30 dark:bg-emerald-950 dark:bg-opacity-10 rounded-xl p-6 my-8 border-2 border-emerald-200 dark:border-emerald-800"><div class="absolute top-0 right-0 w-12 h-12 overflow-hidden"><div class="absolute top-0 right-0 w-0 h-0 border-l-12 border-b-12 border-l-transparent border-b-emerald-200 dark:border-b-emerald-800"></div></div><div class="flex items-center gap-3 mb-4"><div class="flex-shrink-0 w-10 h-10 bg-emerald-100 dark:bg-emerald-900 dark:bg-opacity-30 rounded-full flex items-center justify-center"><svg class="w-5 h-5 text-emerald-600 dark:text-emerald-400" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg></div><div><div class="text-xs font-medium text-emerald-700 dark:text-emerald-300 uppercase tracking-wide">Pro Tips from</div><a href="https://www.shelfradar.ai/" target="_blank" rel="noopener noreferrer" class="text-lg font-semibold text-emerald-900 dark:text-emerald-100 hover:text-emerald-700 dark:hover:text-emerald-300 transition-colors">Ashwant</a></div></div><div class="border-l-4 border-emerald-300 dark:border-emerald-700 pl-4 text-gray-700 dark:text-gray-300"><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-accidental-discovery-that-changed-everything">The Accidental Discovery That Changed Everything<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#the-accidental-discovery-that-changed-everything" class="hash-link" aria-label="Direct link to The Accidental Discovery That Changed Everything" title="Direct link to The Accidental Discovery That Changed Everything" translate="no">​</a></h3><p>Ashwant was debugging a frustrating session. In a moment of rage, he accidentally hit ESC four times.</p><p><strong>What happened next blew his mind.</strong></p><p>Claude Code showed him a prompt history he'd never seen before. Every conversation. Every context. <strong>Time travel for developers.</strong></p><p><strong>The magic combo:</strong> ESC + ESC + ESC + ESC = Prompt history navigation</p><p><strong>Game changer:</strong> You can resurrect any previous session state instantly.</p><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="claude-code-as-your-database-whisperer">Claude Code as Your Database Whisperer<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#claude-code-as-your-database-whisperer" class="hash-link" aria-label="Direct link to Claude Code as Your Database Whisperer" title="Direct link to Claude Code as Your Database Whisperer" translate="no">​</a></h3><p>At ShelfRadar, Ashwant deployed Claude Code as their internal SQL agent.</p><p><strong>The setup:</strong> Claude Code + database schema = autonomous query optimizer</p><p><strong>The result:</strong></p><ul>
<li class="">Ad-hoc queries refined automatically</li>
<li class="">Schema changes don't break queries</li>
<li class="">Claude evolves with your database</li>
</ul></div></div>
<p><strong>The question isn't whether Claude Code is teachable.</strong><br>
<strong>The question is: Are you ready to become its teacher?</strong></p>
<p>Update 1: Claude code introduced hooks. Here is a short collection of hooks that I find useful for my workflow.</p>
<ol>
<li class="">bash script to notify the end of claude code turns.</li>
</ol>
<div class="my-4"><button class="inline-flex items-center gap-2 text-sm text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-300 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 rounded-md px-2 py-1 -mx-2 -my-1" aria-expanded="false"><svg class="w-4 h-4 transition-transform duration-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Full bash script →</button><div class="overflow-hidden transition-all duration-300 ease-in-out max-h-0 opacity-0"><div class="border-l-2 border-gray-200 dark:border-gray-700 pl-4 text-sm"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Read hook input data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INPUT=$(cat)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SESSION_DIR=$(basename "$(pwd)")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Extract message from transcript if available</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TRANSCRIPT_PATH=$(echo "$INPUT" | jq -r '.transcript_path')</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ -f "$TRANSCRIPT_PATH" ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  MSG=$(tail -10 "$TRANSCRIPT_PATH" |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    jq -r 'select(.message.role == "assistant") | .message.content[0].text' |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tail -1 | tr '\n' ' ' | cut -c1-60)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  MSG=${MSG:-"Task completed"}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  MSG="Task completed"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Show Linux desktop notification (requires notify-send)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">notify-send "Claude Code ($SESSION_DIR) Done" "$MSG"</span><br></span></code></pre></div></div></div></div></div>
<div class="relative bg-blue-50 bg-opacity-30 dark:bg-blue-950 dark:bg-opacity-10 rounded-xl p-6 my-8 border-2 border-blue-200 dark:border-blue-800"><div class="flex items-center gap-3 mb-4"><div class="flex-shrink-0 w-10 h-10 bg-blue-100 dark:bg-blue-900 dark:bg-opacity-30 rounded-full flex items-center justify-center"><svg class="w-5 h-5 text-blue-600 dark:text-blue-400" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg></div><div><h3 class="text-lg font-semibold text-blue-900 dark:text-blue-100 m-0">Useful Claude Code Hooks &amp; Scripts</h3></div></div><div class="space-y-4"><div class="space-y-3"><h4 class="text-sm font-semibold text-gray-900 dark:text-gray-100 mb-2">Related Links</h4><div class="space-y-2"><div class="border-l-4 border-blue-300 dark:border-blue-700 pl-4"><a href="https://gist.github.com/glennmatlin/fadc41edc3bb9ff68ff9cfa5d6b8aca7" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200 font-medium transition-colors">Making Claude use uv instead of pip</a><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Script for making Claude use uv package manager instead of pip</p></div><div class="border-l-4 border-blue-300 dark:border-blue-700 pl-4"><a href="https://conductor.build/" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200 font-medium transition-colors">Running multiple Claude Code sessions in parallel</a><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Using git worktrees for parallel Claude Code sessions</p></div><div class="border-l-4 border-blue-300 dark:border-blue-700 pl-4"><a href="https://www.reddit.com/r/ClaudeAI/comments/1loodjn/claude_code_now_supports_hooks/" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200 font-medium transition-colors">Claude Code Hooks Discussion</a><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Reddit discussion about Claude Code hooks support</p></div></div></div></div></div>
<hr>
<p><em>This revolution moves fast. By the time you read this, someone's already teaching Claude Code to do things we haven't imagined yet.</em></p>
<p><strong>Further Reading:</strong></p>
<ul>
<li class=""><a href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus" target="_blank" rel="noopener noreferrer" class="">Context Engineering by Manus</a></li>
<li class=""><a href="https://southbridge-research.notion.site/claude-code-an-agentic-cleanroom-analysis" target="_blank" rel="noopener noreferrer" class="">Hrishi's Claude Code Analysis</a></li>
<li class=""><a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents" target="_blank" rel="noopener noreferrer" class="">Claude Code Sub-Agents Documentation</a></li>
<li class=""><a href="https://docs.anthropic.com/en/docs/claude-code/hooks-guide" target="_blank" rel="noopener noreferrer" class="">Claude Code Hooks Guide</a></li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="are-your-developers-working-for-claude-code-or-is-claude-code-working-for-them">Are Your Developers Working FOR Claude Code? Or Is Claude Code Working FOR Them?<a href="https://blog.vertexcover.io/claude-code-context-engineering-v2#are-your-developers-working-for-claude-code-or-is-claude-code-working-for-them" class="hash-link" aria-label="Direct link to Are Your Developers Working FOR Claude Code? Or Is Claude Code Working FOR Them?" title="Direct link to Are Your Developers Working FOR Claude Code? Or Is Claude Code Working FOR Them?" translate="no">​</a></h2>
<p>Right now, your engineers spend 30% of their AI time being Claude's personal assistants - explaining context, re-describing architecture, and hand-holding every request. <strong>Meanwhile, Anthropic's teams reduced research time by 80% and debug 3x faster</strong> because Claude Code works FOR them.</p>
<p><strong>The Reality Check:</strong> Your team bought the most powerful coding AI ever built, then turned themselves into its unpaid interns.</p>
<p><strong>The Transformation:</strong> Stop being Claude's employee. Make Claude Code your team's autonomous coding partner that knows your codebase better than your junior developers.</p>
<p><strong>Flip the Script: Make Claude Code Work FOR Your Team</strong></p>
<p>Transform your developers from AI babysitters into AI commanders:</p>
<ul>
<li class="">Setting up CLAUDE.md files that eliminate context re-explaining</li>
<li class="">Building verifiable workflows that turn debugging from hours to minutes</li>
<li class="">Token optimization strategies that double your effective usage</li>
<li class="">Advanced automation that makes Claude Code your team's autonomous teammate</li>
</ul>
<p><em>Read how <a href="https://www.anthropic.com/news/how-anthropic-teams-use-claude-code" target="_blank" rel="noopener noreferrer" class="">Anthropic's teams achieve these results</a> and learn to implement the same strategies for your startup.</em></p>
<div style="text-align:center;margin:2em 0;padding:1.5em;background:linear-gradient(135deg, #667eea 0%, #764ba2 100%);border-radius:12px;box-shadow:0 8px 32px rgba(102, 126, 234, 0.3);transform:translateY(0);transition:all 0.3s ease"><a href="https://calendly.com/abhishek-vertexcover/claude-code" target="_blank" rel="noopener noreferrer" style="display:inline-block;background:white;color:#4c51bf;padding:16px 32px;border-radius:8px;text-decoration:none;font-weight:bold;font-size:1.1em;box-shadow:0 4px 16px rgba(0,0,0,0.1);transition:all 0.2s ease">Book Your 30-Minute Consultation Call</a><p style="color:white;margin:1em 0 0 0;font-size:0.95em;opacity:0.9">Transform from Claude Code user to Claude Code teacher. Your future autonomous development workflow starts with one conversation.</p></div>]]></content:encoded>
            <category>Context Engineering</category>
        </item>
        <item>
            <title><![CDATA[AI for End-to-End Tests (Mobile too!) with Auto Healing]]></title>
            <link>https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile</link>
            <guid>https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile</guid>
            <pubDate>Thu, 10 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[AI for End-to-End Tests (Mobile too!)]]></description>
            <content:encoded><![CDATA[<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ai-agent-for-end-to-end-testing-to-deliver-flawless-digital-experiences">AI Agent for End-to-End Testing to Deliver Flawless Digital Experiences<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#ai-agent-for-end-to-end-testing-to-deliver-flawless-digital-experiences" class="hash-link" aria-label="Direct link to AI Agent for End-to-End Testing to Deliver Flawless Digital Experiences" title="Direct link to AI Agent for End-to-End Testing to Deliver Flawless Digital Experiences" translate="no">​</a></h3>
<hr>
<p>What if Ai Agent could write tests for your codebase? End-to-end? and for mobile too? and it auto heals / auto-adjusts when your codebase changes?</p>
<p>We share nuggets we learnt while building an AI Agent to solve one of the most persistent challenges in software development: making UI test automation accessible, reliable, and scalable across platforms and devices.</p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-problem">The Problem<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#the-problem" class="hash-link" aria-label="Direct link to The Problem" title="Direct link to The Problem" translate="no">​</a></h3>
<p>Test automation has historically been:</p>
<ul>
<li class=""><strong>Too technical</strong>: requiring code expertise</li>
<li class=""><strong>Time-consuming</strong>: for authoring and maintaining scripts</li>
<li class=""><strong>Platform-limited</strong>: with fragmented support for web vs. mobile</li>
<li class=""><strong>Fragile</strong>: breaking with minor UI changes or incomplete user flows</li>
</ul>
<p>Existing tools were not built for the demands of today's fast-moving, multi-platform development cycles. They struggled particularly with hybrid apps, dynamic interfaces, and gesture-driven experiences.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-solution-ai-agent">The Solution: AI Agent<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#the-solution-ai-agent" class="hash-link" aria-label="Direct link to The Solution: AI Agent" title="Direct link to The Solution: AI Agent" translate="no">​</a></h3>
<p>AI agent designed from the ground up as an intelligent, prompt-driven automation system with key capabilities:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="natural-language-to-automation-code">Natural Language to Automation Code<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#natural-language-to-automation-code" class="hash-link" aria-label="Direct link to Natural Language to Automation Code" title="Direct link to Natural Language to Automation Code" translate="no">​</a></h3>
<p>Users describe test scenarios in plain English. It translates them into precise, executable test scripts—including test data, validations, and edge cases.</p>
<p><img decoding="async" loading="lazy" alt="flow-diagram" src="https://blog.vertexcover.io/assets/images/flow-diagram-b9d7f678148f33fff9a88c8de46b1e3e.png" width="3840" height="1242" class="img_ev3q"></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="web--mobile-app-testing">Web &amp; Mobile App Testing<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#web--mobile-app-testing" class="hash-link" aria-label="Direct link to Web &amp; Mobile App Testing" title="Direct link to Web &amp; Mobile App Testing" translate="no">​</a></h3>
<p>Supports both web (Selenium, Playwright) and mobile (Appium) frameworks, making it one of the few solutions that bridges the gap between platforms seamlessly.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="multi-language-support">Multi-Language Support<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#multi-language-support" class="hash-link" aria-label="Direct link to Multi-Language Support" title="Direct link to Multi-Language Support" translate="no">​</a></h3>
<p>Generates scripts in Java, Python, JavaScript, and other frameworks—tailored to the team's existing tech stack.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="smart-debugging">Smart Debugging<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#smart-debugging" class="hash-link" aria-label="Direct link to Smart Debugging" title="Direct link to Smart Debugging" translate="no">​</a></h3>
<p>Executes each script line in real-time as it's generated, identifying and correcting issues on the fly.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cross-device-execution">Cross-Device Execution<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#cross-device-execution" class="hash-link" aria-label="Direct link to Cross-Device Execution" title="Direct link to Cross-Device Execution" translate="no">​</a></h3>
<p>Run tests instantly across 5,000+ combinations of real browsers and devices (when connected to cloud infrastructure).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="self-healing-automation">Self-Healing Automation<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#self-healing-automation" class="hash-link" aria-label="Direct link to Self-Healing Automation" title="Direct link to Self-Healing Automation" translate="no">​</a></h3>
<p>Detects and updates selectors and steps automatically as the application evolves, eliminating the need for manual maintenance.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-technical-challenges-solved">Core Technical Challenges Solved<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#core-technical-challenges-solved" class="hash-link" aria-label="Direct link to Core Technical Challenges Solved" title="Direct link to Core Technical Challenges Solved" translate="no">​</a></h3>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ui-automation-for-flutter-web-and-hybrid-mobile-apps">UI Automation for Flutter Web and Hybrid Mobile Apps<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#ui-automation-for-flutter-web-and-hybrid-mobile-apps" class="hash-link" aria-label="Direct link to UI Automation for Flutter Web and Hybrid Mobile Apps" title="Direct link to UI Automation for Flutter Web and Hybrid Mobile Apps" translate="no">​</a></h3>
<p>Most automation tools break down on platforms like Flutter Web, where the UI is rendered inside a <code>&lt;canvas&gt;</code> instead of standard HTML elements, and on hybrid apps without accessible DOM trees.</p>
<p><strong>Our agent solved this by enabling interaction with non-standard UIs using a combination of visual, contextual, and heuristic techniques</strong>—delivering true end-to-end automation where no other solution worked.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="accurate-and-reusable-script-generation">Accurate and Reusable Script Generation<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#accurate-and-reusable-script-generation" class="hash-link" aria-label="Direct link to Accurate and Reusable Script Generation" title="Direct link to Accurate and Reusable Script Generation" translate="no">​</a></h3>
<p>Running LLMs for every test execution is expensive and error-prone.</p>
<p>This AI Agent implemented a <strong>novel templating and generation system</strong> that decouples script generation from execution. This allowed:</p>
<ul>
<li class="">Complete and correct scripts on the first pass</li>
<li class="">Reusability across test runs and frameworks</li>
<li class="">Fast, low-cost, scalable test creation</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="complex-gestures-and-ui-behaviors">Complex Gestures and UI Behaviors<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#complex-gestures-and-ui-behaviors" class="hash-link" aria-label="Direct link to Complex Gestures and UI Behaviors" title="Direct link to Complex Gestures and UI Behaviors" translate="no">​</a></h3>
<p>Simulating gestures like pinch, zoom, drag-and-drop, or multi-touch is notoriously hard—especially in custom components.</p>
<p>This agent provided <strong>fine-grained control</strong> over gesture simulation, going beyond the abstractions of typical libraries, enabling accurate testing of sliders, carousels, maps, and more.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="mapping-natural-language-to-ui-actions-reliably">Mapping Natural Language to UI Actions Reliably<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#mapping-natural-language-to-ui-actions-reliably" class="hash-link" aria-label="Direct link to Mapping Natural Language to UI Actions Reliably" title="Direct link to Mapping Natural Language to UI Actions Reliably" translate="no">​</a></h3>
<p>Natural language like “Click the Pay button” can be ambiguous—especially in large, dynamic UIs.</p>
<p><strong>Being very smart, it combined multiple modalities—DOM structure, visual layout, and semantic cues</strong>—to reliably identify elements even when conventional locators failed. This enabled it to handle vague prompts and incomplete context with high precision.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="stability-in-dynamic--incomplete-user-flows">Stability in Dynamic &amp; Incomplete User Flows<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#stability-in-dynamic--incomplete-user-flows" class="hash-link" aria-label="Direct link to Stability in Dynamic &amp; Incomplete User Flows" title="Direct link to Stability in Dynamic &amp; Incomplete User Flows" translate="no">​</a></h3>
<p>In real-world apps, pop-ups appear unexpectedly, elements load asynchronously, and flows can be interrupted.</p>
<p>It was was designed to <strong>recover intelligently</strong> from such cases using retry logic, timeout strategies, and partial flow handling. This brought production-grade resilience to end-to-end test execution.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="scalable-evaluation--debugging-infrastructure">Scalable Evaluation &amp; Debugging Infrastructure<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#scalable-evaluation--debugging-infrastructure" class="hash-link" aria-label="Direct link to Scalable Evaluation &amp; Debugging Infrastructure" title="Direct link to Scalable Evaluation &amp; Debugging Infrastructure" translate="no">​</a></h3>
<p>A major limitation of LLM-based systems is the lack of robust evaluation.</p>
<p>AI Agent addressed this by building a <strong>custom evaluation framework</strong> that:</p>
<ul>
<li class="">Validated script correctness at each step</li>
<li class="">Enabled partial re-execution of scripts</li>
<li class="">Provided fine-grained feedback for model improvement</li>
</ul>
<p>This drastically accelerated iteration speed and allowed for deeper validation of system accuracy.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://blog.vertexcover.io/ai-agent-end-to-end-automated-tests-mobile#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h3>
<p>AI Agent redefines what's possible in test automation. By combining the reasoning power of LLMs with robust engineering for execution, gesture control, and UI resilience, it makes test automation accessible to non-engineers while retaining power for experts.</p>
<p>From tackling the hardest UI platforms like Flutter Web to enabling precise, reusable test generation and execution at scale, our custom AI agent is a leap forward in the world of quality engineering.</p>
<p>It's not just a tool—it's a full-stack AI agent that understands, adapts, and evolves with your application.</p>]]></content:encoded>
            <category>AI Agents</category>
            <category>End-to-End Test</category>
        </item>
    </channel>
</rss>